\documentclass[12pt, a4paper, headinclude, twoside, plainheadsepline, open=right, numbers=noenddot, hidelinks, toc=listof, toc=bibliography]{scrreprt}

%\usepackage{showframe}


% WICHTIG: Hier wird nicht BibTeX sondern BibLateX verwendet!!
% Deshalb nicht mit bibtex uebersetzen, sondern mit biber
% Das kann man in jedem Tool wie TexMaker oder TexShop als Option einstellen
%
%% Spezielle Einstellungen, insbesondere fuer das Literaturverzeichnis,
% aber auch Packages wie amsmath, Groessenanpassungen etc.
\input{Preferences.tex}
%

% Hier werden die Referenzen in einer separaten Datei gespeichert
\addbibresource{Thesis.bib}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%----------------------------------------------------------------------------------
%  Informationen
%----------------------------------------------------------------------------------
\author{Moritz Palm}
\title{Neural Networks vs. GRU in League of
Legends Match Outcome Prediction: A Data-Centric Perspective}

\date{\today}


\input{abbreviations} % Abkuerzungen
 
%----------------------------------------------------------------------------------
%  Anfang des Dokuments
%----------------------------------------------------------------------------------
\begin{document}
\pagenumbering{Roman} % grosse Roemische Seitenummerierung
\pagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ********************** Titelseite *********************** %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\makeatletter
\begin{titlepage}
\selectlanguage{ngerman}
\begin{figure}[thb]
       \includegraphics[height=2.3cm]{./images/logo/FakIM_Logo} 
\end{figure}
\begin{center}
\rule{0pt}{0pt}
\vfill
\vfill
\vfill
\vfill

\begin{huge}
\@title\\[0.75ex]
\end{huge}

\vfill
\vfill


Bachelorarbeit\\ von\\

\vspace*{.5cm}
\textbf{\@author}\\
Matrikelnummer: 3281253
\vspace{.5cm}

\vfill
\vfill
\textbf{\large Fakultät Informatik und Mathematik\\
Ostbayerische Technische Hochschule Regensburg\\
(OTH Regensburg)}
\vfill
\vfill

\begin{tabular}{rl}
Gutachter:   		& Prof. Dr. Brijnesh Jain\\
Zweitgutachter:   	& Prof. Dr. Timo Baumann\\
%Betreuer:   		& Dr. Max Mustermann\\
\\Abgabedatum:& \@date
\end{tabular}
\end{center}
\end{titlepage}

\selectlanguage{ngerman}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ****************** Erklärung zur Arbeit ***************** %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\text{~}
\vspace{11cm}

\noindent
Herr\\
\@author\\
Konrad-Adenauer-Allee 55\\
93051 Regensburg\\
\smallskip

\noindent
Studiengang: Künstliche Intelligenz \& Data Science
\bigskip

\begin{enumerate}
\item Mir ist bekannt, dass dieses Exemplar der Bachelorarbeit als Prüfungsleistung in das Eigentum des Freistaates Bayern übergeht.
\item Ich erkläre hiermit, dass ich diese Bachelorarbeit selbstständig verfasst, noch nicht anderweitig für Prüfungszwecke vorgelegt, keine anderen als die angegebenen Quellen und Hilfsmittel benutzt sowie wörtlich und sinngemäße Zitate als solche gekennzeichnet habe.
\end{enumerate}
\vspace{1cm}
Regensburg, den \@date\\
\medskip
\medskip

\noindent
\underline{~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~}\\
\@author

\makeatother



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ******************* Inhaltsverzeichnis ****************** %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\cleardoublepage
\pdfbookmark{\contentsname}{toc}\tableofcontents 										% Inhaltsverzeichnis




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ******************* Beginn des Textes ******************* %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagestyle{scrheadings} 																% normale Kopf- und Fusszeilen fuer den Rest
\cleardoublepage
\pagenumbering{arabic} 																	% ab jetzt arabische Nummerierung

\selectlanguage{english}
\chapter{Introduction}
\label{chap:intro}


\ac{lol}, developed by Riot Games, is a prominent \ac{moba} game, a sub genre of real-time strategy games characterized by two teams of five players, known as 'summoners', competing against each other \cite{mora-cantallopsMOBAGamesLiterature2018}. 
Each player controls a unique character, or 'champion', and the objective is to defeat the opposing team. 
\Ac{lol} stands out in the \ac{moba} genre for its global popularity, attracting millions of players and a significant viewership in professional esports tournaments \cite{goughLeagueLegendsChampionships}.
While sharing core gameplay elements and map layouts with other \ac{moba} games, \ac{lol} distinguishes itself through its diverse range of champions, abilities, and graphical styles. 
This thesis will therefore focus on League of Legends, given its influential status in the \ac{moba} genre. 


esports is highly relevant due to it being a huge and strongly growing market.
In 2019, the esports industry's market size was valued at approximately 25B USD \cite{ahnOneBillionDollar2020}.
Esports and mobas in particular are hard to understand and follow. A live game prediction view can help fans understand the action and decisions made better and help immerse the audience by detecting upsets and swings in win probability.
many games are hard to understand, due to lots of information being displayed with very little explanation
a win prediction graph can help viewers understand the action and the significance of certain plays better, thus increasing engagement and enjoyment.
riot games has already implemented their own proprietary win prediction
a win prediction model can also help players make more informed decisions about what the optimal path of actions is

the model should be able to answer the question, if team a is far enough ahead to win or if team b with their hyper scaling heroes can come back and win


\chapter{Related work}
\label{chap:related}

Utilizing machine learning methods to extract information from data generated by e-sport games is an area of ongoing research.
A lot of scientific research focuses on the similar \ac{moba} DotA 2, which has easier and more fine-grained data collection methods (see section \ref{sec:datacoll}).
Due to the high similarity between these two games, it is to be expected that any findings for one game can be replicated and used for the other game with minimal adaptations.
Nevertheless, to ensure a fair comparison, both games are presented separately below.

\begin{table}
\centering
\begin{tblr}{ccccccccc}
Author & Games & Features & Time & Accuracy \\
\hline
\citeauthor{shenMachineLearningApproach2022} \cite{shenMachineLearningApproach2022} & 10,000 & 5 & 10 min & 0.726 \\
\citeauthor{bahrololloomiESportsPlayerPerformance2023} \cite{bahrololloomiESportsPlayerPerformance2023} & 2,901 & 15 & pre-game & 0.86 \\
\citeauthor{silvaContinuousOutcomePrediction2018} \cite{silvaContinuousOutcomePrediction2018} & 7,621 & 52 & up to 25 min & 0.835 (25 min) \\
\citeauthor{mondalDoesSupportRole2022} \cite{mondalDoesSupportRole2022} & 296 & 5 & post game & - \\
\citeauthor{costaFeatureAnalysisLeague2021} \cite{costaFeatureAnalysisLeague2021} & 2,840 & 50 & pre-game & - \\
\citeauthor{hitar-garciaMachineLearningMethods2023} \cite{hitar-garciaMachineLearningMethods2023} & 7583 & 26 & pre-game & 0.683 \\
\citeauthor{zhangPredictionEsportsGame2021} \cite{zhangPredictionEsportsGame2021} & 10,000 & 38 & 10 min & 0.723 \\
\citeauthor{whiteScalablePsychologicalMomentum2020} \cite{whiteScalablePsychologicalMomentum2020} & 87,743 & ? & pre-game & 0.721 \\
\citeauthor{baileyStatisticalLearningEsports} \cite{baileyStatisticalLearningEsports} & 671 & 28 & 15 min & 0.76 \\
\citeauthor{doUsingMachineLearning2021} \cite{doUsingMachineLearning2021} & 5,000 & 44 & pre-game & 0.751 \\
\citeauthor{aniVictoryPredictionLeague2019} \cite{aniVictoryPredictionLeague2019} & 1,500 & 97 & pre-game & 0.955 \\
\end{tblr}
\caption{Comparison of different works on League of Legends win prediction}
\label{tblr:related_work_lol}
\end{table}



In DotA 2, a wide variety of algorithms have been used.  
\Citeauthor{yuMOBASliceTimeSlice2018} \cite{yuMOBASliceTimeSlice2018} trained a \ac{rnn} on 71,355 matches and achieved an accuracy of $0.7083$ at the half-way point of a match, which according to their analysis is on average at 20 minutes.
\Citeauthor{wangPredictingMultiplayerOnline2016} \cite{wangPredictingMultiplayerOnline2016} compared Logistic Regression with a \ac{fnn} trained on up to 911,468 matches, with \ac{lr} achieving a slightly better accuracy ($0.6104$) than the \ac{fnn} ($0.588$).


\Citeauthor{silvaContinuousOutcomePrediction2018} have used \acp{rnn} to predicting the winner using data of different time intervals. They achieved an accuracy of 75\% when using data from between the 10 and 15 minute mark.
An evaluation of LSTM resulted in lower accuracy, most likely due to the large amount of data required \cite{silvaContinuousOutcomePrediction2018}.

\chapter{Background}
\label{chap:background}

\section{League of Legends}
\label{sec:LoL}

\Ac{lol} is played with 5 players on each team on a map which is bifurcated into two bases, each linked by three lanes and housing a crucial structure called the 'nexus', which is protected by turrets. 
The game's primary goal is to destroy the opposing team's nexus.
The map includes a jungle area in between the lanes with neutral monsters and two significant creatures, Baron Nashor and the Dragon, offering team-wide benefits when defeated.
Players must accumulate gold and \ac{xp} through defeating minions, neutral monsters, or enemy champions. 
These in-game currencies are essential for purchasing items and levelling up, thereby augmenting a champion's capabilities.

Player roles in \ac{lol} are typically assigned with one player in the top lane, one in the mid lane, two in the bottom lane, and one in the jungle, facilitating strategic diversity and role specialization.
Players select from a roster of 165 champions, each with unique abilities and characteristics, to compete in matches.
Champion selection is a pivotal element of \ac{lol} gameplay, requiring players to consider team composition, damage types, assigned roles, and personal proficiency with specific champions. 
The theoretical number of possible champion combinations in a game is $\binom{165}{10} = \num{3.21e15}$.
Although this number is quite a bit smaller in reality as not every champion can play every role and most players are only proficient with 15-20 champions \cite{2022Recap}, this underscores the game's strategic depth.

Each year, \ac{lol} introduces a new 'season', bringing substantial changes, and Riot Games issues bi-weekly patches to adjust champion balance, influencing the prevailing game strategies, or 'meta'.
These patches can also include the release of a new champion or the rework of an old one.
Frequent changes force players to be able to quickly adapt and learn new champions and mechanics.

To evaluate player skill, \ac{lol} utilizes a proprietary rating system, probably a modified Elo system \cite{janssonNeuralNetworksStandardizing2022}.
This system ensures that players are matched with and against others of comparable skill levels, maintaining competitive balance and fairness in the game.


\section{Neural Networks}
\label{sec:nn}

\Acp{ann} are computational models that emulate the processing patterns of the human brain. The fundamental computational unit of an ANN is the neuron, a concept first proposed by \citeauthor{mccullochLogicalCalculusIdeas1943} \cite{mccullochLogicalCalculusIdeas1943}.

A neuron computes an output activation $a$ from a set of input values $\mathbf{x} = (x_1, x_2, \ldots, x_m)$, where $m$ denotes the number of inputs. 
The neuron's weighted input $z$ is calculated as the dot product of the input vector $\mathbf{x}$ and the weight vector $\mathbf{w} = (w_1, w_2, \ldots, w_m)$, plus a bias term $b$:
\begin{equation}
z = \sum_{i=1}^{m} w_i x_i + b = \mathbf{w}^\top \mathbf{x} + b.
\end{equation}
The weighted sum $z$ is then passed through an activation function $\phi$, such as a sigmoid or \ac{relu}, to introduce non-linearity:
\begin{equation}
a = \phi(z) = \phi(\mathbf{w}^\top \mathbf{x} + b).
\end{equation}

The \ac{mlp}, introduced by \citeauthor{rosenblattPerceptronProbabilisticModel1958} \cite{rosenblattPerceptronProbabilisticModel1958}, organizes neurons into layers. 
Data flows from the input layer, through one or more hidden layers, to the output layer. In a fully connected feed-forward network, the computation in each layer $l$ is:
\begin{equation}
\mathbf{z}^{(l)} = \phi (\mathbf{W}^{(l)} \mathbf{a}^{(l-1)} + \mathbf{b}^{(l)}),
\end{equation}
where $\mathbf{a}^{(l)}$ represents the activation of layer $l$, $\mathbf{W}^{(l)}$ is the weight matrix, and $\mathbf{b}^{(l)}$ the bias vector. 
The vector $\mathbf{z}^{(l)}$ is then passed through the activation function for layer $l$, which is applied elementwise:
\begin{equation}
\mathbf{a}^{(l)} = \phi (\mathbf{z}^{(l)}).
\end{equation}
The output layer $L$ produces the network's prediction $\hat{y}$.
To approximate any measurable function, an \ac{ann} requires at least one hidden layer \cite{hornikMultilayerFeedforwardNetworks1989}. 
The network's weights and biases are adjusted during training to minimize a loss function $E$.

Common loss functions include \ac{mse} for regression tasks:
\begin{equation}
E_N = \frac{1}{N} \sum_{k=1}^{N}(y_{k} - \hat{y}_{k})^2,
\end{equation}
and \ac{cel} for binary classification tasks:
\begin{equation}
E_N = -\frac{1}{N} \sum_{k=1}^{N} \left( y_k \ln{\hat{y}_k} + (1-y_k) \ln{(1-\hat{y}_k)} \right),
\end{equation}
where $N$ is the number of samples, $y_k$ is the true label, and $\hat{y}_k$ is the predicted value.

Backpropagation \cite{rumelhartLearningRepresentationsBackpropagating1986} is a key algorithm for training \acp{ann}, involving a forward pass to compute activations and a backward pass to compute gradients. 
The gradients of the loss function with respect to the weights and biases are computed using the chain rule of calculus. For a given layer $l$, the gradient of the loss $E$ with respect to the weights $\mathbf{W}^{(l)}$is
\begin{equation}
\Delta
\frac{\partial E}{\partial \mathbf{W}^{(l)}} = \frac{\partial E}{\partial \mathbf{a}^{(l)}} \cdot \frac{\partial \mathbf{a}^{(l)}}{\partial \mathbf{z}^{(l)}} \cdot \frac{\partial \mathbf{z}^{(l)}}{\partial \mathbf{W}^{(l)}},
\end{equation}
and with respect to the bias $\mathbf{b}^{(l)}$
\begin{equation}
\frac{\partial E}{\partial \mathbf{b}^{(l)}} = \frac{\partial E}{\partial \mathbf{z}^{(l)}} \cdot \frac{\partial \mathbf{z}^{(l)}}{\partial \mathbf{b}^{(l)}} = \frac{\partial E}{\partial \mathbf{z}^{(l)}}
\end{equation}
as 
\begin{equation}
\frac{\partial \mathbf{z}^{(l)}}{\partial \mathbf{b}^{(l)}} = 1
\end{equation}
where $\mathbf{z}^{(l)} = \mathbf{W}^{(l)} \mathbf{a}^{(l-1)} + \mathbf{b}^{(l)}$and $\mathbf{a}^{(l)} = \phi(\mathbf{z}^{(l)})$. 
The gradients are then used to update the weights and biases, typically using an optimization algorithm like gradient descent.
The weights are updated via:
\begin{equation}
\mathbf{W}^{(l)} = \mathbf{W}^{(l)} - \eta \frac{\partial E}{\partial \mathbf{W}^{(l)}}
\end{equation}
where $\eta$ is the learning rate.

Through iterative forward and backward propagation, the network gradually converges to a state where the loss is minimized, indicating successful learning of the patterns in the data.

\section{Recurrent Neural Networks}
\label{sec:rnn}

Recurrent Neural Networks (RNNs) extend the capabilities of feed-forward neural networks to handle sequential data by introducing the concept of recurrence. In an RNN, the output at each time step is influenced not only by the current input but also by the network's previous internal state, known as the hidden state. This design enables RNNs to capture temporal dependencies, making them particularly effective for tasks involving sequential data, such as speech recognition and natural language processing \cite{lecunDeepLearning2015}.
%\begin{figure}[h]
%\centering
%\begin{tikzpicture}
%[
%%Styles
%cell/.style={% For the main box
%        rectangle, 
%        rounded corners=5mm, 
%        draw,
%        very thick,
%        },
%state/.style={ %for internal States
%		rectangle,
%		rounded corners=3mm,
%		draw,
%		dashed,
%		minimum size=10mm,
%		},
%arrow/.style={ %for arrows
%		->,
%		thick,
%		-{Stealth[length=3mm]},
%		line width=0.5mm,
%		},
%]
%
%%Cell
%\node [cell, minimum height =4cm, minimum width=6cm] at (0,0){} ;
%
%%States
%
%\node[] (ht1) at (-4.5,0) {$h_{t-1}$};
%\node[state] (ht) [right=2.5cm of ht1]	{$h_t$};
%\node[state] 	(Zt) [right=1cm of ht] {$Z_t$};
%\node[] 	(xt) [below=2.5cm of ht] {$x_t$};
%\node[] (Zt2) [above=2.5cm of Zt] {$\hat{y}_t$};
%
%%Arrows
%\draw[arrow] (xt.north) to (ht.south);
%\draw[arrow] (ht1.east) to (ht.west);
%\draw[arrow] (ht.east) to (Zt.west);
%\draw[arrow] (Zt.north) to (Zt2.south);
%
%%Other
%%\node[]  [right=3cm of Zt] {}; % this is just to add some space on the right side to center the caption on the cell
%
%\end{tikzpicture}
%\caption{Elman Recurrent Unit \cite{hewamalageRecurrentNeuralNetworks2021}}
%\label{fig:elman}
%\end{figure}
The concept of a fully connected RNN was first proposed by \citeauthor{elmanFindingStructureTime1990} \cite{elmanFindingStructureTime1990}.

RNNs maintain a 'state vector' in their hidden units, which implicitly contains information extracted from all past elements of the sequence \cite{lecunDeepLearning2015}. 

In order to provide a simpler overview, we consider a single-layer \ac{rnn} with no bias and whose activation function is the identity function $\phi (x) = x$.
The output $\mathbf{\hat{y}}_t$ of an \ac{rnn} at time step $t$ can be calculated as:
\begin{equation}
\label{eq:rnn_output}
\mathbf{\hat{y}}_t = \mathbf{V} \cdot \mathbf{h}_t ,
\end{equation}
where $\mathbf{V}$ is the weight matrix associated with the cell output. 
The hidden state $\mathbf{h}_t$ at time step $t$ is updated as follows:
\begin{equation}
\label{eq:rnn_update} 
\mathbf{h}_t =
\begin{cases}
	0, & \text{if } t = 0, \\
	\tanh (\mathbf{W} \mathbf{x}_t + \mathbf{U} \mathbf{h}_{t-1})
	& \text{otherwise},
\end{cases}
\end{equation}
where $\mathbf{U}$ is the weight matrix for the hidden state and $\mathbf{W}$ is the weight matrix for the input. 
In a single-layer \ac{rnn}, all weight matrices $\mathbf{W}$, $\mathbf{U}$ and $\mathbf{V}$ (and biases) are shared across timesteps.
The loss over $T$ timesteps is defined by 
\begin{equation}
E_T = \frac{1}{T} \sum_{t=1}^{T} {l(\mathbf{\hat{y}}_t, \mathbf{y})}
\end{equation} 
%TODO: consider changing l to e
where $l(\mathbf{\hat{y}}_t, \mathbf{y})$ is the loss at timestep $t$.

\Ac{bptt} unfolds the \ac{rnn} across time steps (see Figure \ref{fig:rnn_unroll}) and applies the backpropagation algorithm. 
In order to train $U$, $V$ and $W$, we need their respective gradients $\frac{\delta E}{\delta \mathbf{U}}$, $\frac{\delta E}{\delta \mathbf{V}}$ and $\frac{\delta E}{\delta \mathbf{W}}$.



The gradients of the loss function $E$ with respect to the weights $\mathbf{W}$ are calculated for each timestep. 
As the weight matrices are shared across timesteps, we can sum the gradients from each timestep $t$ together:
\begin{equation}
\frac{\partial E_\tau}{\partial \mathbf{W}} = 
\sum_{\tau=1}^{t} 
\frac{\partial E}{\partial \mathbf{\hat{y}}_\tau} 
\cdot 
\frac{\partial \mathbf{\hat{y}}_\tau}{\partial \mathbf{h}_\tau} 
\cdot 
\frac{\partial \mathbf{h}_\tau}{\partial \mathbf{W}},
\end{equation}
where $\frac{\partial E}{\partial \mathbf{\hat{y}}_\tau}$ is the gradient of the loss with respect to the output at time $\tau$, $\frac{\partial \mathbf{\hat{y}}_\tau}{\partial \mathbf{h}_\tau}$ is the gradient of the output with respect to the hidden state, and $\frac{\partial \mathbf{h}_\tau}{\partial \mathbf{W}}$ is the gradient of the hidden state with respect to the weights. This process is repeated for all weights and biases in the network, allowing the RNN to learn from sequences by adjusting its parameters based on the temporal context.

However, as demonstrated by \citeauthor{bengioLearningLongtermDependencies1994} \cite{bengioLearningLongtermDependencies1994}, RNNs face challenges with exploding or vanishing gradients, particularly in long sequences. This issue hinders their ability to learn long-range dependencies \cite{sutskeverTrainingRecurrentNeural2013}. 

\begin{figure}
\centering
%TODO add U matrix between hidden states
\begin{tikzpicture}[
item/.style={circle,draw,thick,align=center, minimum size=1.2cm},
hidden/.style={item,on chain,join}]

 \begin{scope}[start chain=going right,nodes=hidden,every
 join/.style={-latex,very thick},local bounding box=chain]
 \draw node (A0) {$h_0$} node (A1) {$h_1$} node (A2) {$h_2$} node[xshift=2em] (At)
 {$h_t$};
 \end{scope}
 \node[left=1em of chain,scale=2] (eq) {$=$};
 \node[left=2em of eq,item] (AL) {$h$};
 \path (AL.west) ++ (-1em,2em) coordinate (aux);
 \draw[very thick,-latex,rounded corners] (AL.east) -| ++ (1em,2em) -- (aux)
 |- (AL.west) node[midway, left] {$U$};
 \foreach \X in {0,1,2,t}
 {\draw[very thick,-latex] (A\X.north) -- ++ (0,2em) node[midway, right] {$V$}
 node[above,item,fill=gray!10] (h\X) {$\hat{y}_\X$};
 \draw[very thick,latex-] (A\X.south) -- ++ (0,-2em) node[midway, right] {$W$}
 node[below,item,fill=gray!10] (x\X) {$x_\X$};
 \path (A\X.east) -- (A\X -| At.west) node[midway, above] {$U$};
}
 
 \draw[white,line width=0.8ex] (AL.north) -- ++ (0,1.9em);
 \draw[very thick,-latex] (AL.north) -- ++ (0,2em) node[midway, right] {$V$}
 node[above,item,fill=gray!10] {$\hat{y}_t$};
 \draw[very thick,latex-] (AL.south) -- ++ (0,-2em) node[midway, right] {$W$}
 node[below,item,fill=gray!10] {$x_t$};
 \path (x2) -- (xt) node[midway,scale=2,font=\bfseries] {\dots};
\end{tikzpicture}
\caption{Unrolling of a \ac{rnn} over time}
\label{fig:rnn_unroll}
\end{figure}

\section{GRU}
\label{sec:gru}
In order to overcome the exploding/vanishing gradient problem of vanilla \acp{rnn}, gated networks like the \ac{lstm} \cite{hochreiterLongShortTermMemory1997} and \ac{gru} \cite{choLearningPhraseRepresentations2014} have been developed \cite{vanhoudtReviewLongShortterm2020}.
As they introduce an increased number of parameters compared to traditional \acp{rnn}, gated networks like the \ac{lstm} and \ac{gru} demand greater computational power \cite{deyGatevariantsGatedRecurrent2017}.
Compared to the \ac{lstm} network, \ac{gru} reduces the number of gate networks to two, thus being simpler to implement and compute \cite{choLearningPhraseRepresentations2014}.
\Citeauthor{chungEmpiricalEvaluationGated2014} even found that \ac{gru} is at least comparable to \ac{lstm} most of the time \cite{chungEmpiricalEvaluationGated2014}.
The gates control the activation of each hidden unit.
The reset gate is calculated by
\begin{equation}
\label{eq:gru_reset}
r_t = \sigma (W_r x_t + U_r h_{t-1} + b_r)
\end{equation}
and the update gate $z_j$ by
\begin{equation}
\label{eq:gru_update}
z_t = \sigma (W_z x_t + U_z h_{t-1} + b_z)
\end{equation}
\cite{deyGatevariantsGatedRecurrent2017}.
The hidden state update is a linear interpolation between the previous activation $h_{t-1}$ and the candidate activation $\tilde{h}_t$, where the update gate $z_t$ influences how much the hidden state is changed \cite{chungEmpiricalEvaluationGated2014}:
\begin{equation}
\label{eq:gru_h}
h_t = (1-z_t) \odot h_{t-1} + z_t \odot \tilde{h}_t
\end{equation}
with
\begin{equation}
\label{eq_gru_h_tilde}
\tilde{h}_t = \tanh(W_h x_t + U_h (r_t \odot h_{t-1} + b_h)
\end{equation}
.
In equations (\ref{eq:gru_h}) and (\ref{eq_gru_h_tilde}) $\odot$ denotes the element-wise (Hadamard) multiplication.

\begin{figure}
\centering
\begin{tikzpicture}[
    % Styles
    cell/.style={% For the main box
        rectangle, 
        rounded corners=5mm, 
        draw,
        very thick,
        },
    operator/.style={%For operators like +  and  x
        circle,
        draw,
        inner sep=-0.5pt,
        minimum height =.2cm,
        },
    function/.style={%For functions
        ellipse,
        draw,
        inner sep=1pt
        },
    ct/.style={% For external inputs and outputs
        circle,
        draw,
        line width = .75pt,
        minimum width=1cm,
        inner sep=1pt,
        },
    gt/.style={% For internal inputs
        rectangle,
        draw,
        minimum width=4mm,
        minimum height=3mm,
        inner sep=1pt
        },
    ArrowC1/.style={% Arrows with rounded corners
        rounded corners=.25cm,
        thick,
        },
    ArrowC2/.style={% Arrows with big rounded corners
        rounded corners=.5cm,
        thick,
        },
    ]
    
   %Start drawing the thing...    
    % Draw the cell: 
    \node [cell, minimum height =4cm, minimum width=6cm] at (0,0){} ;

   % Draw inputs named ibox#
    \node [gt] (ibox1) at (-2,-0.75) {$\sigma$};
    \node [gt] (ibox2) at (-1.5,-0.75) {$\sigma$};
    \node [gt, minimum width=1cm] (ibox3) at (-0.5,-0.75) {Tanh};
	
	
	\node [operator] (mux1) at (-2,1.5) {$\times$};
    \node [operator] (add1) at (-0.5,1.5) {+};
    \node [operator] (mux2) at (-0.5,0) {$\times$};
    \node [operator] (mux3) at (1.5,0) {$\times$};
    /*
    
\end{tikzpicture}
\caption{Gated Recurrent Unit}
\label{fig:gru}
\end{figure}


\section{Feature Selection}
\label{sec:fs_algos}

Feature Selection is pivotal in machine learning, particularly when dealing with high-dimensional data. It serves the primary objectives of improving model performance by mitigating the 'curse of dimensionality,' enhancing predictive accuracy, and reducing overfitting. By eliminating irrelevant or redundant features, the model's generalization capacity is enhanced, contributing to model interpretability and potentially reducing training times.
Feature selection methods can be broadly categorized into three distinct types:
\begin{description}
\item[Filter Methods] These methods rely on model-invariant information, such as feature-class label correlation. They are computationally efficient but may not capture complex relationships within the data.
\item[Wrapper Methods] Wrapper methods train models iteratively on various feature subsets, incurring a higher computational cost but enabling the detection of interactions among variables.
\item[Embedded Methods] These methods perform inherent feature selection, often as an integral part of the modeling process. Tree-based models, such as Decision Trees and Gradient Boosted Trees, typically employ feature selection based on metrics like the Gini index or entropy.
\end{description}
Below, two different feature selection methods are discussed in detail.

\subsection{Pearson's Correlation Coefficient}
\label{ssec:pearsons}
\Ac{pcc} is a statistical measure widely used to evaluate the linear relationship between two variables. 
Specifically, we consider its application in the context of feature selection in machine learning, where it is used to assess the linear correlation between input features and the target variable. 
We regard the input vector $\mathbf{x}$ as a manifestation of an underlying, unknown distribution. 
Here, $X_i$ represents the random variable corresponding to the $i^{\text{th}}$ component of $\mathbf{x}$, and $y$ is the target value, viewed as a realization of the random variable $Y$ \cite{guyonIntroductionVariableFeature}. 
\Ac{pcc} is employed to quantify the linear correlation between these two random variables. It is defined by the formula:
\begin{equation}
R(i) = \frac{\text{cov}(X_i, Y)}{\sqrt{\text{var}(X_i) \cdot \text{var}(Y)}},
\end{equation}
where $\text{cov}(X_i, Y)$ is the covariance between $X_i$ and $Y$, and $\text{var}(X_i)$ and $\text{var}(Y)$ are the variances of $X_i$ and $Y$, respectively \cite{chandrashekarSurveyFeatureSelection2014}.
In order to ascertain the significance of the test results, a hypothesis test needs to be performed, with the null hypothesis being that there is no correlation between the feature and the target.
While simple and effective for identifying linear relationships, \ac{pcc} only captures linear dependencies and might miss non-linear relationships crucial for neural networks.


\subsection{Gradient Boosted Trees}
\label{ssec:gbt}

Gradient Boosted Trees (GBT) is an ensemble learning technique that can be used for feature selection. It builds the model in a stage-wise fashion, with each tree being added to correct the errors made by the previous ones. 
There are different types of importance, such as the average or total gain across all splits the feature is used in.
The simplest definition is the 'weight', defined as the number of times a feature is used to split the data across all trees \cite{chenXGBoostScalableTree2016}.



\chapter{Data}
\label{chap:data}

As two very different experiments are compared against each other, two different datasets need to be constructed: one dataset containing all relevant information prior to the start of the game and one dataset containing only the temporal information from the beginning of the game.


\section{Data Collection}
\label{sec:datacoll}

\paragraph{High-Rank Matches}
The focus of data acquisition was directed towards high-rank matches, in which a mix of excellent amateur and professional players play.
Lower rank matches are not considered due to their higher unpredictability as less skilled players make huge, game-changing mistakes way more often.
Pro matches, defined as professional players playing with their respective teams in an esport tournament or league, were not included as there are way less matches and they are not available through the official Riot Games API.
High rank matches in this context are defined as having at least one player holding the rank of Master, Grandmaster or Challenger.
Riot Games themselves considers any rank above Diamond 3 as 'Elite' \cite{riotgamesDevBalanceFramework2020}, but we raise this bar just slightly to only include any rank above Diamond 1.
Due to the fact that for a match to be included in the dataset, only one out of ten players needs to hold one of the aforementioned highest ranks, some slightly lower ranked players are also present in the dataset.
These ranks combined account for the top $0.2\%$ of all players \cite{riotgamesRankedTiersDivisions2023}.
\paragraph{Riot Games API}
The primary source of data stemmed from the Riot Games API \cite{RiotDeveloperPortal}, a comprehensive repository of information pertaining to League of Legends gameplay.
The Riot Games API provided access to a plethora of essential data points, including champion statistics, general match information, timeline details, and player-specific information.
These variables collectively form a comprehensive and multifaceted dataset crucial for the development of an effective predictive model.
\paragraph{Other Data Sources}
However, not all pertinent data were available directly from the Riot Games API.
These include the general winning chance of each champion and statistics on how each player performs on each relevant champion.
To address this limitation, a web-scraping approach was employed to gather additional relevant information. 
\paragraph{Regions}
Multiple regions were included in the data collection process, including Europe West (EUW), Europe Nordic \& East (EUN), Korea (KR), and North America (NA).
This regional diversity contributes to the model's generalizability across different player bases and playing styles.
\paragraph{Period of Time}
All matches included in the dataset were played in season 13 and on patch 20.
It is important that all matches are played on the same patch, as a patch may cause major shifts in the balance of the game, thus making certain strategies and champions way better than others.

In summary, the data collection process for this study involved a dual-pronged approach, leveraging the extensive resources provided by the Riot Games API alongside a targeted web-scraping strategy.
The resulting raw dataset containing $38,573$ and  $3,972$ matches in the pre-game and in-game datasets respectively, stored in a PostgreSQL Database, reflects a comprehensive compilation of high-rank amateur League of Legends matches.

\section{Dataset Properties}
\label{sec:dataprop}

The dataset under consideration encompasses a total of 38,573 matches drawn from various regions. 
A visual representation of the distribution of matches across these regions is provided in Figure \ref{fig:platformId}.
It is important to note that due to a lack of official data pertaining to the number of games played or the number of players in each region, we are unable to conclusively verify whether the distribution of matches within our dataset aligns with the true underlying distribution of games played per region.

The dataset primarily comprises matches from three major regions: North America, Western Europe, and South Korea, which collectively constitute the vast majority of matches in our dataset. 
Consequently, it is reasonable to assume that this composition approximately mirrors the real-world distribution of matches, with the exception of China, whose matches are not available.
This assumption is further reinforced by the distribution of spots in the world championship, where these four regions are the only ones to get guaranteed spots in the main event.
It is worth emphasizing, however, that while regional disparities may exist in terms of match characteristics, they are not expected to be substantial. Thus, the effect of drawing a uniform sample from the underlying distribution on the quality of our data is anticipated to be negligible.

\begin{figure}[ht]
\input{./images/platformId_distribution.pgf}
\caption{Region distribution of all matches in the dataset. Even though North America is most likely not the largest region, it has the largest number of games in the dataset.}
\label{fig:platformId}
\end{figure}

As only matches with a game length of at least 16 minutes are collected, the shortest match is 16 minutes long, while the longest game is $59.62$ minutes long.
The average match length is $27.50$ minutes.
Figure \ref{fig:gameDuration} graphically illustrates the distribution of game durations. 
Notably, the histogram reveals a prominent spike at the 16-minute mark.
This spike corresponds to the earliest possible conclusion time for a match, as League of Legends prohibits surrendering prior to the 15th minute of gameplay. In instances where an entire team collectively acknowledges the futility of their chances of victory, a surrender may be initiated at the 15-minute threshold.
If a simple majority of team members want to surrender, they have to wait until the 20th minute.
However, should a simple majority of team members decide to surrender, they must adhere to a 20-minute waiting period before being able to do so. 
Consequently, this unique feature of the game's mechanics clarifies the relatively diminished frequency of matches ending in the 17th to 19th-minute range within our dataset.

\begin{figure}[ht]
\input{./images/gameDuration_distribution.pgf}
\caption{Distribution of game duration with its kernel density estimation. The spike at 16 minutes is explained by the fact that this is the earliest possible surrender time.}
\label{fig:gameDuration}
\end{figure}


\begin{figure}
\resizebox{\textwidth}{!}{\input{./images/tier_distribution.pgf}}
\caption{Distribution of ranks in the dataset}
\label{fig:tier}
\end{figure}



\subsection{Pre-Game Dataset}
\label{ssec:pre_game_data}
The raw pre-game dataset contains $368$ columns which can be categorized into four distinct groups: General Match Information, Player Information, Champion Information and Player-Champion Information.
General match details, such as the patch number, are exclusively utilized for validation purposes and are excluded from the final dataset.
\paragraph{Player Information}
Player Information feature $x_p$ is a two-dimensional vector containing information about the player. This includes the account level, serving as an indicator of the player's accumulated gaming experience, and the player's rank, functioning as a metric for assessing the player's skill level.
transform rank info into a single float number
win rate calculation

\paragraph{Champion Information}
The Champion Information feature $\mathbf{x}_c$ is composed of 

However, it is noteworthy that a limitation inherent in these metrics lies in their aggregation across all player ranks, reducing their specificity to the ranks under analysis.
conversion of champion tier into integer

\paragraph{Player-Champion Information}
This feature vector contains information about the player on a specific champion.
It encompasses metrics such as the average amount of gold earned by the player across all matches played on the champion during Season 13. 
\Citeauthor{costaFeatureAnalysisLeague2021} \cite{costaFeatureAnalysisLeague2021} found that  the most pivotal feature within this category is the player's win rate while piloting this champion.
Unfortunately, this information is not readily available to be extracted by our web scraper,  necessitating its omission from the dataset.
Each feature category like 'average gold per match' is split into 10 features, one for each participant.
This is a very fine-grained approach, greatly increasing the dimensionality of the dataset.
For some features, a broader approach is sufficient, where statistics are averaged for each team, reducing 10 features per category to two.
champion number one hot encoded


\subsection{In-Game Dataset}
\label{ssec:in_game_data}

The raw in-game dataset contains $381$ features describing the current state of the game after every minute.
It primarily includes player-specific metrics such as damage dealt to opponents, champion level, and cumulative gold. These statistics, recorded per minute, create a discrete time series. Furthermore, key events like the number of turrets destroyed and each team's total gold are tracked to more precisely gauge the game's state. Gold, a critical indicator, underscores each victory milestone - be it destroying a turret or defeating an adversary. Often, the winning team can be predicted by analysing gold trends. As illustrated in Figure \ref{fig:totalGold}, members of the victorious team typically amass significantly more gold by the game's conclusion compared to their counterparts.

Destroying turrets is crucial in the game, offering significant gold rewards and map control. 
With a minimum of five turrets required for victory, their destruction serves as a key indicator of a team's likelihood to win.

\begin{figure}
\input{./images/totalGold.pgf}
\caption{Total gold accumulated by each player of the course of the match, separated into teams by color. 
A clear separation between the blue and red team is noticeable especially at the later stages of the game.}
\label{fig:totalGold}
\end{figure}


\section{Data Processing}
\label{sec:data_processing}


\paragraph{Scaling and Partitioning}
dataset is partitioned into train, validation and test set with a validation and test size of 4,000 samples corresponding to 10 percent respectively.
the validation set is used to optimize hyperparameters while the test set is used to evaluate the final performance of the model
in order to 



\chapter{Experiments}
\label{chap:experiments}

\subsection{Feature Selection Results}
\label{ssec:feature_selection_results}

As expected, the significance of the features does not differ much within a category, so the correlation coefficients are averaged per category.
This enables a clearer result on the importance of feature categories.

The results of the test are found in table \ref{tab:pearson_results}.
All $p$-values in the table are below the significance threshold of $0.05$, confirming the statistical significance of the correlation.
The highest correlation is $0.15$, belonging to the KDA feature.
This feature measures the average ratio of $\frac{\text{kills} + \text{assists}}{\text{deaths}}$ the player achieved on his champion.
This is a very low correlation, indicating that no single feature has a strong linear relationship with the target.
This illustrates the need for multivariate analysis.
\begin{table}
	\centering
	\begin{tblr}{ccc}
	Feature  & Correlation coefficient & \acs{gbt} Feature Importance\\
	\hline
	KDA & \textbf{0.133} & \textbf{726}\\
	Deaths & 0.092 & 284\\
	Assists & 0.081 & 403\\
	Gold & 0.063 & 393\\
	Kills & 0.060 & 310\\
	LP & 0.050 & 541\\
	Champion Level & 0.034 & 50\\
	CS Per Minute & 0.027 & 394\\
	Last Play Time & 0.026 & 349\\
	Win Rate & 0.022 & 301\\
	Champion Tier & 0.020 & 66\\
	Champion Points & 0.015 & 401\\
	
	\end{tblr}
	\caption{
	Average Pearson's correlation coefficient and average \ac{gbt} Feature Importance for the 12 features categories with the highest absolute average correlation.
	Notably, the KDA feature is not only by far the most important, but its components Kills, Deaths and Assists are in the top 5 correlation coefficients as well.
	}
	\label{tab:pearson_results}
\end{table}





\section{Pre-Game Classification}
\label{sec:pregame_class}
using neural network

\subsection{Hyperparameter Optimization}
\label{ssec:hyperparam_optim}



\section{Mid-Game Classification}
\label{sec:midgame_class}



\chapter{Results}
\label{chap:results}


\chapter{Discussion}
\label{chap:discussion}

retrain probably necessary for every patch


\chapter{Conclusion}
\label{chap:conclusion}

%\bibliographystyle{natdin}
%\bibliographystyle{naturemag}
%\bibliographystyle{geralpha}
\printbibliography


% Anhang
\include{appendix}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ********************* Verzeichnisse ********************* %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\listoffigures																			% Abbildungsverzeichnis
\listoftables																			% Tabellenverzeichnis
\cleardoublepage\phantomsection\addcontentsline{toc}{chapter}{List of Abbreviations}	% Abkürzungsverzeichnis
\printacronyms[heading={chapter*}, name={List of Abbreviations}]



\end{document}
