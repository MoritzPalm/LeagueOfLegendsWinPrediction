\documentclass[12pt, a4paper, headinclude, twoside, plainheadsepline, open=right, numbers=noenddot, hidelinks, toc=listof, toc=bibliography]{scrreprt}

%\usepackage{showframe}


% WICHTIG: Hier wird nicht BibTeX sondern BibLateX verwendet!!
% Deshalb nicht mit bibtex uebersetzen, sondern mit biber
% Das kann man in jedem Tool wie TexMaker oder TexShop als Option einstellen
%
%% Spezielle Einstellungen, insbesondere fuer das Literaturverzeichnis,
% aber auch Packages wie amsmath, Groessenanpassungen etc.
\input{Preferences.tex}
%

% Hier werden die Referenzen in einer separaten Datei gespeichert
\addbibresource{Thesis.bib}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%----------------------------------------------------------------------------------
%  Informationen
%----------------------------------------------------------------------------------
\author{Moritz Palm}
\title{Comparative Analysis of Predictive Performance: Neural Networks vs. GRU in League of
Legends Match Outcome Prediction}

\date{\today}


\input{abbreviations} % Abkuerzungen
 
%----------------------------------------------------------------------------------
%  Anfang des Dokuments
%----------------------------------------------------------------------------------
\begin{document}
\pagenumbering{Roman} % grosse Roemische Seitenummerierung
\pagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ********************** Titelseite *********************** %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\makeatletter
\begin{titlepage}
\selectlanguage{ngerman}
\begin{figure}[thb]
       \includegraphics[height=2.3cm]{./images/logo/FakIM_Logo} 
\end{figure}
\begin{center}
\rule{0pt}{0pt}
\vfill
\vfill
\vfill
\vfill

\begin{huge}
\@title\\[0.75ex]
\end{huge}

\vfill
\vfill


Bachelorarbeit\\ von\\

\vspace*{.5cm}
\textbf{\@author}\\
Matrikelnummer: 1234567
\vspace{.5cm}

\vfill
\vfill
\textbf{\large Fakultät Informatik und Mathematik\\
Ostbayerische Technische Hochschule Regensburg\\
(OTH Regensburg)}
\vfill
\vfill

\begin{tabular}{rl}
Gutachter:   		& Prof. Dr. Brijnesh Jain\\
Zweitgutachter:   	& Prof. Dr. Timo Baumann\\
%Betreuer:   		& Dr. Max Mustermann\\
\\Abgabedatum:& \@date
\end{tabular}
\end{center}
\end{titlepage}

\selectlanguage{ngerman}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ****************** Erklärung zur Arbeit ***************** %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\text{~}
\vspace{11cm}

\noindent
Herr\\
\@author\\
Konrad-Adenauer-Allee 55\\
93051 Regensburg\\
\smallskip

\noindent
Studiengang: Künstliche Intelligenz \& Data Science
\bigskip

\begin{enumerate}
\item Mir ist bekannt, dass dieses Exemplar der Bachelorarbeit als Prüfungsleistung in das Eigentum des Freistaates Bayern übergeht.
\item Ich erkläre hiermit, dass ich diese Bachelorarbeit selbstständig verfasst, noch nicht anderweitig für Prüfungszwecke vorgelegt, keine anderen als die angegebenen Quellen und Hilfsmittel benutzt sowie wörtlich und sinngemäße Zitate als solche gekennzeichnet habe.
\end{enumerate}
\vspace{1cm}
Regensburg, den \@date\\
\medskip
\medskip

\noindent
\underline{~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~}\\
\@author

\makeatother



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ******************* Inhaltsverzeichnis ****************** %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\cleardoublepage
\pdfbookmark{\contentsname}{toc}\tableofcontents 										% Inhaltsverzeichnis




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ******************* Beginn des Textes ******************* %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagestyle{scrheadings} 																% normale Kopf- und Fusszeilen fuer den Rest
\cleardoublepage
\pagenumbering{arabic} 																	% ab jetzt arabische Nummerierung

\selectlanguage{english}
\chapter{Introduction}
\label{chap:intro}


esports is highly relevant due to it being a huge and strongly growing market.
Esports and mobas in particular are hard to understand and follow. A live game prediction view can help fans understand the action and decisions made better and help immerse the audience by detecting upsets and swings in win probability.
many games are hard to understand, due to lots of information being displayed with very little explanation
a win predicition graph can help viewers understand the action and the significance of certain plays better, thus increasing engagement and enjoyment.
riot games has already implemented their own proprietary win prediction
a win prediction model can also help players make more informed decisions about what the optimal path of actions is

the model should be able to answer the question, if team a is far enough ahead to win or if team b with their hyperscaling heroes can come back and win

\chapter{Background}
\label{chap:background}

\section{League of Legends}
\label{sec:LoL}

\ac{lol} is a \ac{moba} game developed by Riot Games. 
\Ac{moba} games, a subgenre of real-time strategy games, typically feature two teams, each consisting of five players known as 'summoners'. 
These players compete against each other, with each controlling a unique character, referred to as a 'champion' \cite{mora-cantallopsMOBAGamesLiterature2018}. 
\ac{lol} is among the most popular video games in this genre, drawing millions of players worldwide and a substantial viewership in professional esports tournaments [CITATION NEEDED].

While most \ac{moba} games share similar basic gameplay elements and map layouts, they differ in aspects such as available champions, abilities, and graphical styles. 
Given its prominence in the \ac{moba} genre, this thesis will primarily focus on League of Legends. 
In \ac{lol}, players begin each match by selecting a champion from a roster of 165, each with distinct abilities and characteristics. 
The game map is divided into two bases connected by three lanes, with each base housing a critical structure called the 'nexus', defended by turrets. 
The primary objective is to destroy the opposing team's nexus.

The game's map also features a jungle area, which contains neutral monsters and two significant creatures, Baron Nashor and the Dragon. 
These monsters provide team-wide benefits upon defeat. The game's strategic complexity is heightened by the need for players to earn gold and \ac{xp} by defeating minions, neutral monsters, or opposing champions. 
This currency is used to purchase items and level up, enhancing a champion's capabilities.

Player roles are traditionally distributed with one player in the top lane, one in the mid lane, two in the bottom lane, and one in the jungle. This distribution allows for strategic diversity and specialization. 
Each year, \ac{lol} enters a new 'season', introducing significant changes. Additionally, Riot Games releases bi-weekly patches to adjust champion balance, potentially altering the prevailing game strategies, or 'meta'.

Champion selection is a critical aspect of \ac{lol} gameplay. 
Players must consider various factors such as team composition, damage types, assigned roles, and personal proficiency with specific champions. 
Theoretically, the number of possible champion combinations in a game is $\binom{165}{10} = \frac{165!}{10! \cdot (165-10)!}$, highlighting the game's strategic depth.

To assess individual player skill, \ac{lol} employs a modified Elo rating system. This system is crucial for matchmaking, ensuring players are paired with and against others of similar skill levels.


\section{Neural Networks}
\label{sec:nn}

\Acp{ann} are computational models that emulate the processing patterns of the human brain. The fundamental computational unit of an ANN is the neuron, a concept first proposed by \citeauthor{mccullochLogicalCalculusIdeas1943} \cite{mccullochLogicalCalculusIdeas1943}. 
A neuron computes an output activation $a$ from a set of input values $\mathbf{x} = (x_1, x_2, \ldots, x_m)$, where $m$ denotes the number of inputs. 
The neuron's weighted input $z$ is calculated as the dot product of the input vector $\mathbf{x}$ and the weight vector $\mathbf{w} = (w_1, w_2, \ldots, w_m)$, plus a bias term $b$:
\begin{equation}
z = \sum_{i=1}^{m} w_i x_i + b = \mathbf{w}^\top \mathbf{x} + b.
\end{equation}
The weighted sum $z$ is then passed through an activation function $\phi$, such as a sigmoid or \ac{relu}, to introduce non-linearity:
\begin{equation}
a = \phi(z) = \phi(\mathbf{w}^\top \mathbf{x} + b).
\end{equation}

The \ac{mlp} introduced by \citeauthor{rosenblattPerceptronProbabilisticModel1958} \cite{rosenblattPerceptronProbabilisticModel1958}, organizes neurons into layers. 
Data flows from the input layer, through one or more hidden layers, to the output layer. In a fully connected feed-forward network, the computation in each layer $l$ is:
\begin{equation}
\mathbf{a}^{(l)} = \phi (\mathbf{W}^{(l)} \mathbf{a}^{(l-1)} + \mathbf{b}^{(l)}),
\end{equation}
where $\mathbf{a}^{(l)}$ represents the activation of layer $l$, $\mathbf{W}^{(l)}$ is the weight matrix, and $\mathbf{b}^{(l)}$ is the bias vector. 
The output layer $L$ produces the network's prediction $\hat{y}$.

To approximate any measurable function, an \ac{ann} requires at least one hidden layer \cite{hornikMultilayerFeedforwardNetworks1989}. 
The network's weights and biases are adjusted during training to minimize a loss function $E$. Common loss functions include \ac{mse} for regression tasks:
\begin{equation}
E_N = \frac{1}{N} \sum_{k=1}^{N}(y_{k} - \hat{y}_{k})^2,
\end{equation}
and \ac{cel} for binary classification tasks:
\begin{equation}
E_N = -\frac{1}{N} \sum_{k=1}^{N} \left( y_k \ln{\hat{y}_k} + (1-y_k) \ln{(1-\hat{y}_k)} \right),
\end{equation}
where $N$ is the number of samples, $y_k$ is the true label, and $\hat{y}_i$ or $\hat{y}_k$ is the predicted value or probability.

Backpropagation is a key algorithm for training \acp{ann}, involving a forward pass to compute activations and a backward pass to compute gradients. 
The gradients of the loss function with respect to the weights and biases are computed using the chain rule of calculus. For a given layer $l$, the gradient of the loss $E$ with respect to the weights $\mathbf{W}^{(l)}$is:
\begin{equation}
\frac{\partial E}{\partial \mathbf{W}^{(l)}} = \frac{\partial E}{\partial \mathbf{a}^{(l)}} \cdot \frac{\partial \mathbf{a}^{(l)}}{\partial \mathbf{z}^{(l)}} \cdot \frac{\partial \mathbf{z}^{(l)}}{\partial \mathbf{W}^{(l)}},
\end{equation}
where $\mathbf{z}^{(l)} = \mathbf{W}^{(l)} \mathbf{a}^{(l-1)} + \mathbf{b}^{(l)}$and $\mathbf{a}^{(l)} = \phi(\mathbf{z}^{(l)})$. 
The gradients are then used to update the weights and biases, typically using an optimization algorithm like gradient descent.

Through iterative forward and backward propagation, the network gradually converges to a state where the loss is minimized, indicating successful learning of the patterns in the data.

\section{Recurrent Neural Networks}
\label{sec:rnn}

Recurrent Neural Networks (RNNs) extend the capabilities of feed-forward neural networks to handle sequential data by introducing the concept of recurrence. In an RNN, the output at each time step is influenced not only by the current input but also by the network's previous internal state, known as the hidden state. This design enables RNNs to capture temporal dependencies, making them particularly effective for tasks involving sequential data, such as speech recognition and natural language processing \cite{lecunDeepLearning2015}.

The concept of a fully connected RNN was first proposed by \citeauthor{elmanFindingStructureTime1990} \cite{elmanFindingStructureTime1990}. 
RNNs maintain a 'state vector' in their hidden units, which implicitly contains information extracted from all past elements of the sequence \cite{lecunDeepLearning2015}. The output \( \hat{y}_t \) of an RNN at time step \( t \) can be calculated as:
\begin{equation}
\label{eq:rnn_output}
\hat{y}_t = \tanh(V h_t + b_o),
\end{equation}
where \( V \) is the weight matrix and \( b_o \) is the bias vector associated with the cell output. The hidden state \( h_t \) at each time step \( t \) is updated as follows:
\begin{equation}
\label{eq:rnn_update}
h_t =
\begin{cases}
	0, & \text{if } t = 0, \\
	\sigma (W x_t + U h_{t-1} + b_h), & \text{otherwise},
\end{cases}
\end{equation}
where \( \sigma \) is the sigmoid activation function, \( U \) and \( b_h \) are the weight matrix and bias vector for the hidden state, and \( W \) is the weight matrix for the input. In a single-layer RNN, one hidden weight matrix \( W_h \) is shared across all timesteps.


BPTT unfolds the RNN across time steps (see figure \ref{fig:rnn_unroll}) and applies the backpropagation algorithm. The gradients of the loss function with respect to the weights are calculated for each time step. For a given time step \( t \), the gradient of the loss \( E \) with respect to the weights \( W \) is:
\begin{equation}
\frac{\partial E}{\partial W} = \sum_{\tau=1}^{t} \frac{\partial E}{\partial \hat{y}_\tau} \cdot \frac{\partial \hat{y}_\tau}{\partial h_\tau} \cdot \frac{\partial h_\tau}{\partial W},
\end{equation}
where \( \frac{\partial E}{\partial \hat{y}_\tau} \) is the gradient of the loss with respect to the output at time \( \tau \), \( \frac{\partial \hat{y}_\tau}{\partial h_\tau} \) is the gradient of the output with respect to the hidden state, and \( \frac{\partial h_\tau}{\partial W} \) is the gradient of the hidden state with respect to the weights. This process is repeated for all weights and biases in the network, allowing the RNN to learn from sequences by adjusting its parameters based on the temporal context.

However, as demonstrated by \citeauthor{bengioLearningLongtermDependencies1994} \cite{bengioLearningLongtermDependencies1994}, RNNs face challenges with exploding or vanishing gradients, particularly in long sequences. This issue hinders their ability to learn long-range dependencies \cite{sutskeverTrainingRecurrentNeural2013}. 
\begin{figure}
\centering
\begin{tikzpicture}
[
%Styles
cell/.style={% For the main box
        rectangle, 
        rounded corners=5mm, 
        draw,
        very thick,
        },
state/.style={ %for internal States
		rectangle,
		rounded corners=3mm,
		draw,
		dashed,
		minimum size=10mm,
		},
arrow/.style={ %for arrows
		->,
		thick,
		-{Stealth[length=3mm]},
		line width=0.5mm,
		},
]

%Cell
\node [cell, minimum height =4cm, minimum width=6cm] at (0,0){} ;

%States

\node[] (ht1) at (-4.5,0) {$h_{t-1}$};
\node[state] (ht) [right=2.5cm of ht1]	{$h_t$};
\node[state] 	(Zt) [right=1cm of ht] {$Z_t$};
\node[] 	(xt) [below=2.5cm of ht] {$x_t$};
\node[] (Zt2) [above=2.5cm of Zt] {$Z_t$};

%Arrows
\draw[arrow] (xt.north) to (ht.south);
\draw[arrow] (ht1.east) to (ht.west);
\draw[arrow] (ht.east) to (Zt.west);
\draw[arrow] (Zt.north) to (Zt2.south);

%Other
\node[]  [right=3cm of Zt] {}; % this is just to add some space on the right side to center the caption on the cell

\end{tikzpicture}
\caption{Elman Recurrent Unit}
\label{fig:elman}
\end{figure}
\begin{figure}
\centering
%TODO add U matrix between hidden states
\begin{tikzpicture}[
item/.style={circle,draw,thick,align=center, minimum size=1.2cm},
hidden/.style={item,on chain,join}]

 \begin{scope}[start chain=going right,nodes=hidden,every
 join/.style={-latex,very thick},local bounding box=chain]
 \draw node (A0) {$h_0$} node (A1) {$h_1$} node (A2) {$h_2$} node[xshift=2em] (At)
 {$h_t$};
 \end{scope}
 \node[left=1em of chain,scale=2] (eq) {$=$};
 \node[left=2em of eq,item] (AL) {$h$};
 \path (AL.west) ++ (-1em,2em) coordinate (aux);
 \draw[very thick,-latex,rounded corners] (AL.east) -| ++ (1em,2em) -- (aux)
 |- (AL.west) node[midway, left] {$U$};
 \foreach \X in {0,1,2,t}
 {\draw[very thick,-latex] (A\X.north) -- ++ (0,2em) node[midway, right] {$V$}
 node[above,item,fill=gray!10] (h\X) {$y_\X$};
 \draw[very thick,latex-] (A\X.south) -- ++ (0,-2em) node[midway, right] {$W$}
 node[below,item,fill=gray!10] (x\X) {$x_\X$};}
 
 \draw[white,line width=0.8ex] (AL.north) -- ++ (0,1.9em);
 \draw[very thick,-latex] (AL.north) -- ++ (0,2em) node[midway, right] {$V$}
 node[above,item,fill=gray!10] {$y_t$};
 \draw[very thick,latex-] (AL.south) -- ++ (0,-2em) node[midway, right] {$W$}
 node[below,item,fill=gray!10] {$x_t$};
 \path (x2) -- (xt) node[midway,scale=2,font=\bfseries] {\dots};
\end{tikzpicture}
\caption{Unrolling of an \ac{rnn} over time}
\label{fig:rnn_unroll}
\end{figure}




\section{GRU}
\label{sec:gru}
In order to overcome the exploding/vanishing gradient problem of vanilla \acp{rnn}, gated networks like the \ac{lstm} \cite{hochreiterLongShortTermMemory1997} and \ac{gru} \cite{choLearningPhraseRepresentations2014} have been developed \cite{vanhoudtReviewLongShortterm2020}.
As they introduce an increased number of parameters compared to traditional \acp{rnn}, gated networks like the \ac{lstm} and \ac{gru} demand greater computational power \cite{deyGatevariantsGatedRecurrent2017}.
Compared to the \ac{lstm} network, \ac{gru} reduces the number of gate networks to two, thus being simpler to implement and compute \cite{choLearningPhraseRepresentations2014}.
\Citeauthor{chungEmpiricalEvaluationGated2014} even found that \ac{gru} is at least comparable to \ac{lstm} most of the time \cite{chungEmpiricalEvaluationGated2014}.
The gates control the activation of each hidden unit.
The reset gate is calculated by
\begin{equation}
\label{eq:gru_reset}
r_t = \sigma (W_r x_t + U_r h_{t-1} + b_r)
\end{equation}
and the update gate $z_j$ by
\begin{equation}
\label{eq:gru_update}
z_t = \sigma (W_z x_t + U_z h_{t-1} + b_z)
\end{equation}
\cite{deyGatevariantsGatedRecurrent2017}.
The hidden state update is a linear interpolation between the previous activation $h_{t-1}$ and the candidate activation $\tilde{h}_t$, where the update gate $z_t$ influences how much the hidden state is changed \cite{chungEmpiricalEvaluationGated2014}:
\begin{equation}
\label{eq:gru_h}
h_t = (1-z_t) \odot h_t + z_t \odot \tilde{h}_t
\end{equation}
with
\begin{equation}
\label{eq_gru_h_tilde}
\tilde{h}_t = g(W_h x_t + U_h (r_t \odot h_{t-1} + b_h)
\end{equation}
.
In equations \ref{eq:gru_h} and \ref{eq_gru_h_tilde} $\odot$ denotes the elementwise (Hadamard) multiplication and the function $g$ in equation \ref{eq_gru_h_tilde} is the activation function.


\begin{figure}
\centering
\begin{tikzpicture}[
    % Styles
    cell/.style={% For the main box
        rectangle, 
        rounded corners=5mm, 
        draw,
        very thick,
        },
    operator/.style={%For operators like +  and  x
        circle,
        draw,
        inner sep=-0.5pt,
        minimum height =.2cm,
        },
    function/.style={%For functions
        ellipse,
        draw,
        inner sep=1pt
        },
    ct/.style={% For external inputs and outputs
        circle,
        draw,
        line width = .75pt,
        minimum width=1cm,
        inner sep=1pt,
        },
    gt/.style={% For internal inputs
        rectangle,
        draw,
        minimum width=4mm,
        minimum height=3mm,
        inner sep=1pt
        },
    ArrowC1/.style={% Arrows with rounded corners
        rounded corners=.25cm,
        thick,
        },
    ArrowC2/.style={% Arrows with big rounded corners
        rounded corners=.5cm,
        thick,
        },
    ]
    
   %Start drawing the thing...    
    % Draw the cell: 
    \node [cell, minimum height =4cm, minimum width=6cm] at (0,0){} ;

   % Draw inputs named ibox#
    \node [gt] (ibox1) at (-2,-0.75) {$\sigma$};
    \node [gt] (ibox2) at (-1.5,-0.75) {$\sigma$};
    \node [gt, minimum width=1cm] (ibox3) at (-0.5,-0.75) {Tanh};
	
	
	\node [operator] (mux1) at (-2,1.5) {$\times$};
    \node [operator] (add1) at (-0.5,1.5) {+};
    \node [operator] (mux2) at (-0.5,0) {$\times$};
    \node [operator] (mux3) at (1.5,0) {$\times$};
    
    
\end{tikzpicture}
\caption{Gated Recurrent Unit}
\label{fig:gru}
\end{figure}

\section{Related work}
\label{sec:related}

Utilizing machine learning methods to extract information from data generated by e-sport games is an area of ongoing research.
A lot of scientific research focuses on the similar \ac{moba} DotA 2, which has easier and more fine-grained data collection methods (see section \ref{sec:datacoll}).
Due to the high similarity between these two games, it is to be expected that any findings for one game can be replicated and used for the other game with minimal adaptations.
Nevertheless, to ensure a fair comparison, both games are presented separately below.

In DotA 2, a wide variety of algorithms have been used.  
\Citeauthor{yuMOBASliceTimeSlice2018} \cite{yuMOBASliceTimeSlice2018} trained a \ac{rnn} on 71,355 matches and achieved an accuracy of $0.7083$ at the half-way point of a match, which according to their analysis is on average at 20 minutes.
\Citeauthor{wangPredictingMultiplayerOnline2016} \cite{wangPredictingMultiplayerOnline2016} compared Logistic Regression with a \ac{fnn} trained on up to 911,468 matches, with \ac{lr} achieving a slightly better accuracy ($0.6104$) than the \ac{fnn} ($0.588$).


\Citeauthor{silvaContinuousOutcomePrediction2018} have used \acp{rnn} to predicting the winner using data of different time intervals. They achieved an accuracy of 75\% when using data from between the 10 and 15 minute mark.
An evaluation of LSTM resulted in lower accuracy, most likely due to the large amount of data required \cite{silvaContinuousOutcomePrediction2018}.



\chapter{Data}
\label{chap:data}

As two very different experiments are compared against each other, two different datasets need to be constructed: one dataset containing all relevant information prior to the start of the game and one dataset containing only the temporal information from the beginning of the game.


\section{Data Collection}
\label{sec:datacoll}

\paragraph{High-Rank Matches}
The focus of data acquisition was directed towards high-rank matches, in which a mix of excellent amateur and professional players play.
Lower rank matches are not considered due to their higher unpredictability as less skilled players make huge, game-changing mistakes way more often.
Pro matches, defined as professional players playing with their respective teams in an esport tournament or league, were not included as there are way less matches and they are not available through the official Riot Games API.
High rank matches in this context are defined as having at least one player holding the rank of Master, Grandmaster or Challenger.
Riot Games themselves considers any rank above Diamond 3 as 'Elite' \cite{riotgamesDevBalanceFramework2020}, but we raise this bar just slightly to only include any rank above Diamond 1.
Due to the fact that for a match to be included in the dataset, only one out of ten players needs to hold one of the aforementioned highest ranks, some slightly lower ranked players are also present in the dataset.
These ranks combined account for the top $0.2\%$ of all players \cite{riotgamesRankedTiersDivisions2023}.
\paragraph{Riot Games API}
The primary source of data stemmed from the Riot Games API, a comprehensive repository of information pertaining to League of Legends gameplay.
The Riot Games API provided access to a plethora of essential data points, including champion statistics, general match information, timeline details, and player-specific information.
These variables collectively form a comprehensive and multifaceted dataset crucial for the development of an effective predictive model.
\paragraph{Other Data Sources}
However, not all pertinent data were available directly from the Riot Games API.
These include the winning chance of each champion and statistics on how each player performs on each relevant champion.
To address this limitation, a web-scraping approach was employed to gather additional relevant information. The amalgamation of Riot Games API data and web-scraped data was meticulously organized and stored in a Database.
This central repository served as the foundational storehouse from which distinct datasets were constructed, ensuring an organized and structured approach to data management.
\paragraph{Regions}
Multiple regions were included in the data collection process, including Europe West (EUW), Europe Nordic \& East (EUN), Korea (KR), and North America (NA).
This regional diversity contributes to the model's generalizability across different player bases and playing styles.
\paragraph{Period of Time}
All matches included in the dataset were played in season 13 and on patch 20.
It is important that all matches are played on the same patch, as a patch may cause major shifts in the balance of the game, thus making certain strategies and champions way better than others.

In summary, the data collection process for this study involved a dual-pronged approach, leveraging the extensive resources provided by the Riot Games API alongside a targeted web-scraping strategy.
The resulting raw dataset containing $20,513$ and  $3,972$ matches in the pre-game and in-game datasets respectively, stored in a PostgreSQL Database, reflects a comprehensive compilation of high-rank amateur League of Legends matches.

\section{Dataset Properties}
\label{sec:dataprop}

\begin{figure}
\input{./images/platformId_distribution.pgf}
\caption{Region distribution of all matches in the dataset}
\label{fig:platformId}
\end{figure}

\begin{figure}
\input{./images/gameDuration_distribution.pgf}
\caption{Distribution of game duration with its kernel density estimation. The spike at 16 minutes is explained by the fact that this is the earliest possible surrender time.}
\label{fig:gameDuration}
\end{figure}


\begin{figure}
\resizebox{\textwidth}{!}{\input{./images/tier_distribution.pgf}}
\caption{Distribution of ranks in the dataset}
\label{fig:tier}
\end{figure}

The matches collected have the following properties: 
As only matches with a game length of at least 16 minutes are collected, the shortest match is 16 minutes long, while the longest game is $59.62$ minutes long.
The average match length is $26.88$ minutes.


\section{Data Processing}
\label{sec:data_processing}

\subsection{Pre-Game Dataset}
\label{ssec:pre_game_data}
The raw pre-game dataset contains $368$ columns which can be categorized into four distinct groups: General Match Information, Player Information, Champion Information and Player-Champion Information.
General match details, such as the patch number, are exclusively utilized for validation purposes and are excluded from the final dataset.
\paragraph{Player Information}
Player Information feature $x_p$ is a two-dimensional vector containing information about the player. This includes the account level, serving as an indicator of the player's accumulated gaming experience, and the player's rank, functioning as a metric for assessing the player's skill level.
\paragraph{Champion Information}
The Champion Information feature $\mathbf{x}_c$ is composed of 

However, it is noteworthy that a limitation inherent in these metrics lies in their aggregation across all player ranks, reducing their specificity to the ranks under analysis.
\paragraph{Player-Champion Information}
This feature vector contains information about the player on a specific champion.
It encompasses metrics such as the average amount of gold earned by the player across all matches played on the champion during Season 13. 
\Citeauthor{costaFeatureAnalysisLeague2021} \cite{costaFeatureAnalysisLeague2021} found that  the most pivotal feature within this category is the player's win rate while piloting this champion.
Unfortunately, this information is not readily available to be extracted by our web scraper,  necessitating its omission from the dataset.



\subsection{In-Game Dataset}
\label{ssec:in_game_data}

The raw in-game dataset contains $381$ features describing the current state of the game after every minute.
It primarily includes player-specific metrics such as damage dealt to opponents, champion level, and cumulative gold. These statistics, recorded per minute, create a discrete time series. Furthermore, key events like the number of turrets destroyed and each team's total gold are tracked to more precisely gauge the game's state. Gold, a critical indicator, underscores each victory milestone - be it destroying a turret or defeating an adversary. Often, the winning team can be predicted by analyzing gold trends. As illustrated in Figure \ref{fig:totalGold}, members of the victorious team typically amass significantly more gold by the game's conclusion compared to their counterparts.

Destroying turrets is crucial in the game, offering significant gold rewards and map control. 
With a minimum of five turrets required for victory, their destruction serves as a key indicator of a team's likelihood to win.

\begin{figure}
\input{./images/totalGold.pgf}
\caption{Total gold accumulated by each player of the course of the match, separated into teams by color. 
A clear separation between the blue and red team is noticeable especially at the later stages of the game.}
\label{fig:totalGold}
\end{figure}



\chapter{Experiments}
\label{chap:experiments}

\section{Feature Selection}
\label{sec:feature_selection}

Both datasets initially have a very high dimensionality, which can lead to the prevalence of noisy or irrelevant data \cite{venkateshReviewFeatureSelection2019}.
In order to facilitate the learning of the \ac{ann}, all such data should be removed.
This process of finding the best subset of features used for training is called Feature Selection.
Different methods of selecting a subset of features have been tried:
\begin{itemize}
\item Pearson's correlation coefficient
\item Gradient Boosted Trees
\end{itemize}

\subsection{Pearsons' correlation coefficient}
\label{ssec:pearsons}

We regard the input vector $\mathbf{x}$ as a manifestation of an underlying, unknown distribution. 
Here, $X_i$ represents the random variable corresponding to the $i^{\text{th}}$ component of $\mathbf{x}$, and $\mathbf{y}$ is the target value vector, viewed as a realization of the random variable $Y$ \cite{guyonIntroductionVariableFeature}. 
The Pearson correlation coefficient is employed to quantify the linear correlation between these two random variables. It is defined by the formula:
\begin{equation}
R(i) = \frac{\text{cov}(X_i, Y)}{\sqrt{\text{var}(X_i) \cdot \text{var}(Y)}},
\end{equation}
where $\text{cov}(X_i, Y)$ is the covariance between $X_i$ and $Y$, and $\text{var}(X_i)$ and $\text{var}(Y)$ are the variances of $X_i$ and $Y$, respectively \cite{chandrashekarSurveyFeatureSelection2014a}.
In order to ascertain the significance of the test results, a hypothesis test is performed, with the null hypothesis being that there is no correlation between the feature and the target.

The results of the test are found in table \ref{tab:pearson_results}.
All $p$-values in the table are below the significance threshold of $0.05$, confirming the statistical significance of the correlation.
The highest correlation is $0.15$, belonging to the KDA feature.
This feature measures the average ratio of $\frac{\text{kills} + \text{assists}}{\text{deaths}}$ the player achieved on his champion.
This is a very low correlation, indicating that no single feature has a strong linear relationship with the target.
This illustrates the need for multivariate analysis.
\begin{table}
	\centering
	\begin{tblr}{cc}
	Feature  & Correlation coefficient & \acs{gbt} Feature Importance\\
	\hline
	participant\textunderscore 9\textunderscore champion\textunderscore kda & 0.148 & \\
	participant\textunderscore 5\textunderscore champion\textunderscore kda & -0.148 & \\
	participant\textunderscore 4\textunderscore champion\textunderscore kda & -0.137 & \\
	participant\textunderscore 7\textunderscore champion\textunderscore kda & 0.136 & \\
	participant\textunderscore 3\textunderscore champion\textunderscore kda & -0.133 & \\
	participant\textunderscore 10\textunderscore champion\textunderscore kda & 0.132 & \\
	participant\textunderscore 2\textunderscore champion\textunderscore kda & -0.131 & \\
	participant\textunderscore 8\textunderscore champion\textunderscore kda & 0.129 & \\ 
	
	\end{tblr}
	\caption{Pearson's correlation coefficient for the 15 features with the highest absolute correlation}
	\label{tab:pearson_results}

\end{table}


\subsection{Gradient Boosted Trees}
\label{ssec:gbt}

\Acp{gbt} like all tree-based methods have an embedded method of selecting the most important feature.
There are different types of importance, such as the average or total gain across all splits the feature is used in.
The simplest definition is the 'weight', defined as the number of times a feature is used to split the data across all trees \cite{chenXGBoostScalableTree2016}.
30 features have not been used in any split and thus have a feature importance of 0.


\chapter{Results}
\label{chap:results}


\chapter{Discussion}
\label{chap:discussion}


\chapter{Conclusion}
\label{chap:conclusion}

%\bibliographystyle{natdin}
%\bibliographystyle{naturemag}
%\bibliographystyle{geralpha}
\printbibliography


% Anhang
\include{appendix}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ********************* Verzeichnisse ********************* %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\listoffigures																			% Abbildungsverzeichnis
\listoftables																			% Tabellenverzeichnis
\cleardoublepage\phantomsection\addcontentsline{toc}{chapter}{List of Abbreviations}	% Abkürzungsverzeichnis
\printacronyms[heading={chapter*}, name={List of Abbreviations}]



\end{document}
