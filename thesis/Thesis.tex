\documentclass[12pt, a4paper, headinclude, twoside, plainheadsepline, open=right, numbers=noenddot, hidelinks, toc=listof, toc=bibliography]{scrreprt}

%\usepackage{showframe}


% WICHTIG: Hier wird nicht BibTeX sondern BibLateX verwendet!!
% Deshalb nicht mit bibtex uebersetzen, sondern mit biber
% Das kann man in jedem Tool wie TexMaker oder TexShop als Option einstellen
%
%% Spezielle Einstellungen, insbesondere fuer das Literaturverzeichnis,
% aber auch Packages wie amsmath, Groessenanpassungen etc.
\input{Preferences.tex}
%

% Hier werden die Referenzen in einer separaten Datei gespeichert
\addbibresource{Thesis.bib}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%----------------------------------------------------------------------------------
%  Informationen
%----------------------------------------------------------------------------------
\author{Moritz Palm}
\title{Neural Network vs. GRU in League of
Legends Match Outcome Prediction: A Data-Centric Perspective}

\date{\today}


\input{abbreviations} % Abkuerzungen
 
%----------------------------------------------------------------------------------
%  Anfang des Dokuments
%----------------------------------------------------------------------------------
\begin{document}
\pagenumbering{Roman} % grosse Roemische Seitenummerierung
\pagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ********************** Titelseite *********************** %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\makeatletter
\begin{titlepage}
\selectlanguage{ngerman}
\begin{figure}[thb]
       \includegraphics[height=2.3cm]{./images/logo/FakIM_Logo} 
\end{figure}
\begin{center}
\rule{0pt}{0pt}
\vfill
\vfill
\vfill
\vfill

\begin{huge}
\@title\\[0.75ex]
\end{huge}

\vfill
\vfill


Bachelorarbeit\\ von\\

\vspace*{.5cm}
\textbf{\@author}\\
Matrikelnummer: 3281253
\vspace{.5cm}

\vfill
\vfill
\textbf{\large Fakultät Informatik und Mathematik\\
Ostbayerische Technische Hochschule Regensburg\\
(OTH Regensburg)}
\vfill
\vfill

\begin{tabular}{rl}
Gutachter:   		& Prof. Dr. Brijnesh Jain\\
Zweitgutachter:   	& Prof. Dr. Timo Baumann\\
%Betreuer:   		& Dr. Max Mustermann\\
\\Abgabedatum:& \@date
\end{tabular}
\end{center}
\end{titlepage}

\selectlanguage{ngerman}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ****************** Erklärung zur Arbeit ***************** %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\text{~}
\vspace{11cm}

\noindent
Herr\\
\@author\\
Konrad-Adenauer-Allee 55\\
93051 Regensburg\\
\smallskip

\noindent
Studiengang: Künstliche Intelligenz \& Data Science
\bigskip

\begin{enumerate}
\item Mir ist bekannt, dass dieses Exemplar der Bachelorarbeit als Prüfungsleistung in das Eigentum des Freistaates Bayern übergeht.
\item Ich erkläre hiermit, dass ich diese Bachelorarbeit selbstständig verfasst, noch nicht anderweitig für Prüfungszwecke vorgelegt, keine anderen als die angegebenen Quellen und Hilfsmittel benutzt sowie wörtlich und sinngemäße Zitate als solche gekennzeichnet habe.
\end{enumerate}
\vspace{1cm}
Regensburg, den \@date\\
\medskip
\medskip

\noindent
\underline{~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~}\\
\@author

\makeatother



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ******************* Inhaltsverzeichnis ****************** %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\cleardoublepage
\selectlanguage{english}

\pdfbookmark{\contentsname}{toc}\tableofcontents 										% Inhaltsverzeichnis




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ******************* Beginn des Textes ******************* %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagestyle{scrheadings} 																% normale Kopf- und Fusszeilen fuer den Rest
\cleardoublepage
\pagenumbering{arabic} 																	% ab jetzt arabische Nummerierung




\chapter{Introduction}
\label{chap:intro}

Esports has emerged as a highly relevant and influential sector in the gaming industry, experiencing substantial growth and popularity in recent years. 
In 2019, the esports industry's market size was valued at approximately 25B USD \cite{ahnOneBillionDollar2020}.
Within this domain, the genre of \ac{moba} games has risen to the forefront, becoming one of the most popular categories in esports. 
At the pinnacle of this genre is \ac{lol}, developed by Riot Games, which has not only attracted a massive global player base but also a significant viewership in professional esports tournaments \cite{goughLeagueLegendsChampionships}. 
The \acl{lol} World Championship Finals 2021 reached an impressive average minute audience of over 30 million people according to Riot Games \cite{riotgamesHowRiotEsports2022} even when compared to the estimated 150 million average minute audience for the 2021 UEFA Champions League Final \cite{dalmiaChampionsLeagueFinal2023}.

Despite its popularity, \ac{lol} presents a notable challenge: it can be hard to follow for newer audiences due to its complex gameplay and strategic depth \cite{campbell2021sports}. 
Even for regular viewers, it can be hard to follow the action on screen, as in certain moments, there are a plethora of things happening at the same time.
Figure \ref{fig:screenshot} shows how the game looks during a smaller fight from the players perspective.
This issue is worsened by the higher unpredictability of outcomes in esports compared to traditional sports, as lead changes are frequent and less indicative of final results \cite{campbell2021sports}.

\begin{figure}[htbp]
\includegraphics[width=\textwidth]{./images/LolScreenshot1.jpg}
\caption[Screenshot of a \ac{lol} game, showing the players perspective.]{Screenshot of a \ac{lol} game, showing the players perspective \cite{fearless-ad5644HighlightMyLOL2024}.}
\label{fig:screenshot}
\end{figure}

This accessibility issue parallels that of chess, where the subtleties and strategic shifts are often lost on less experienced viewers. 
In response, chess broadcasts have employed engine evaluation graphs to depict major swings in the game, thereby enhancing viewer understanding and engagement \cite{zangAutomatedChessCommentator2019}.
The evaluation indicates whether the game is a win, loss or a draw, assuming perfect play from both sides.
Such an evaluation helps viewers get the most important information at a glance, without having to have a lot of in-depth knowledge.
It is also a starting point for different kinds of analysis, for example whether a room's air quality affects the player's decision making (see \cite{kunnIndoorAirQuality2023}).

Similarly, \ac{lol} has introduced a proprietary win prediction graph during its World Championship broadcasts (see Figure \ref{fig:riot_win_pred_graph}), helping fans understand the action and decisions made better and help immerse the audience by detecting upsets and swings in win probability.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{./images/win_prob_worlds.png}
\caption[Official win probability graph from World Championship 2022.]{Output of the proprietary win prediction model developed by Riot Games from the final game of the 2022 World championships. It shows the winning probability for each team on the y-axis from 100\% for the first team to 100\% for the second team. The icons at the top of the graph are important events during the game and the icons on the left side are the team logos \cite{LoLEsports}.}
\label{fig:riot_win_pred_graph}
\end{figure}

Despite a viewer survey by \citeauthor{claytorRiotGamesAWS2023} \cite{claytorRiotGamesAWS2023}, indicating that 94 percent of participants found the visualization useful, there remains a notable lack of publicly available data concerning the graph's methodology and effectiveness.
Other works have worked on this topic (see Chapter \ref{chap:related}), but may be limited by a potential lack of data or a narrow focus on the professional scene.

Addressing this gap, the goal of this thesis is to develop a win prediction model using machine learning techniques for \acl{lol} both for pre-game and real-time win prediction, training on a greater number of non-professional games.
The pre-game model uses an \acl{ann}, while the in-game model seeks to exploit the temporal structure of the data by using a \acl{gru}.
These models aim to provide a deeper understanding of the game for audiences, enhancing their viewing experience by predicting outcomes based on the ongoing gameplay. 
They could also offer valuable insights for players and coaches in formulating strategies and making informed decisions during matches.

\chapter{Related work}
\label{chap:related}

The application of machine learning techniques in interpreting data from esports games represents a dynamic field of research. 
A critical factor in win prediction is the timing of data collection, as outlined in Table \ref{tab:related_work_lol}.
It can be categorized into three distinct phases: pre-game, in-game, and post-game, each offering unique insights and benefits.

\paragraph{Pre-Game Win Prediction}
A variety of different methods were used to predict the winner prior to the game's commencement.
A notable study by \citeauthor{whiteScalablePsychologicalMomentum2020} \cite{whiteScalablePsychologicalMomentum2020} incorporated a broad spectrum of pre-game features, including the concept of psychological momentum, and attained an accuracy of 0.721 using logistic regression.
In comparison, \citeauthor{doUsingMachineLearning2021} \cite{doUsingMachineLearning2021} 
limited their feature set to player-champion win rates and champion mastery points, further extracting statistical features such as the team's average player-champion win rate.
Applying an \ac{ann} to this data yielded an accuracy of 0.751, which is significant given the relatively small dataset used. 
Especially considering the results of the paper on feature selection by  \citeauthor{costaFeatureAnalysisLeague2021} \cite{costaFeatureAnalysisLeague2021}, which identified not only player-champion win rate but also the kill-to-death ratio for the chosen champion as the most critical features.


\paragraph{In-Game Win Prediction}
\Citeauthor{silvaContinuousOutcomePrediction2018} \cite{silvaContinuousOutcomePrediction2018} trained a \acf{rnn} on 7621 professional games  utilizing data from varying time intervals, ranging from the initial 0-5 minutes to 20-25 minutes.
Their findings revealed an accuracy of 0.752 when using data from between the 10 and 15 minute mark and a maximum accuracy of 0.835 when using data from the 20-25th minute.
Additionally, their research comparing \ac{lstm} networks against \acp{rnn} indicated superior performance of the latter, possibly attributable to the less complex nature of the problem or limited data availability.
Unfortunately, the work done by Riot Games themselves \cite{claytorRiotGamesAWS2023} did not report any metrics, so no direct comparison to other methods is possible.
\citeauthor{baileyStatisticalLearningEsports} \cite{baileyStatisticalLearningEsports} have achieved an accuracy of 0.77 by applying logistic regression to 671 professional matches with data from the 15th minute mark.
These results lead to the assumption that lower rated games are harder to predict accurately, as more mistakes happen and thus increase randomness and volatility.

This work builds upon the methodology used by  \Citeauthor{silvaContinuousOutcomePrediction2018} \cite{silvaContinuousOutcomePrediction2018}, but uses a much larger amount of non-professional games in order to overcome any limitations related to the amount of data used.

\paragraph{Post-Game Win Prediction}
\citeauthor{bahrololloomiESportsPlayerPerformance2023} \cite{bahrololloomiESportsPlayerPerformance2023} have built a predictor using post-game data from professional matches achieving 86\% accuracy, while \citeauthor{aniVictoryPredictionLeague2019} \cite{aniVictoryPredictionLeague2019} trained a Random Forest model on a mixture of pre-, in- and post-game data for a maximum accuracy of 0.998.
These results suggest that using post-game data leads to perfect predictions, where the value does not lie in the accuracy, but in the relevant features which can lead to new insights about winning strategies.



\begin{longtblr}[
caption = {Comparison of different works on League of Legends win prediction},
label = {tab:related_work_lol},
note{a} = {No accuracy reported.},
note{b} = {The exact number of features is unclear.},
note{c} = {The exact timestamp where the last in-game data was obtained is unclear.},
note{d} = {The skill group(s) from which the games stem is unclear.},
note{e} = {All professional \ac{lol} games since early 2020 \cite{LoLEsports}.}
]
{
colspec = {l*{5}{c}},
rowhead = 1,
}

Author & Games & Features & Time & Skill Group & Accuracy \\
\hline
\citeauthor{doUsingMachineLearning2021} \cite{doUsingMachineLearning2021} & 5,000 & 44 & pre-game & \TblrNote{d} & 0.751 \\
\citeauthor{costaFeatureAnalysisLeague2021} \cite{costaFeatureAnalysisLeague2021} & 2,840 & 50 & pre-game & professional & \TblrNote{a} \\
\citeauthor{whiteScalablePsychologicalMomentum2020} \cite{whiteScalablePsychologicalMomentum2020}&87,743&\TblrNote{b}&pre-game &equidistributed&0.721\\
\citeauthor{hitar-garciaMachineLearningMethods2023} \cite{hitar-garciaMachineLearningMethods2023} & 7583 & 26 & pre-game & professional & 0.683 \\
\citeauthor{linLeagueLegendsMatch2016} \cite{linLeagueLegendsMatch2016} & 588 & 2231 & pre-game & low-skilled & 0.567 \\

\citeauthor{kimConfidenceCalibratedMOBAGame2020} \cite{kimConfidenceCalibratedMOBAGame2020} & 93875 & 295 & in-game\TblrNote{c} & \TblrNote{d} & 0.738 \\
\citeauthor{shenMachineLearningApproach2022} \cite{shenMachineLearningApproach2022} & 10,000 & 5 & 10 min & \TblrNote{d} & 0.726 & \\
\citeauthor{zhangPredictionEsportsGame2021} \cite{zhangPredictionEsportsGame2021} & 10,000 & 38 & 10 min & high-skilled & 0.723 \\
\citeauthor{baileyStatisticalLearningEsports} \cite{baileyStatisticalLearningEsports} & 671 & 28 & 15 min & professional & 0.76 \\
\citeauthor{silvaContinuousOutcomePrediction2018} \cite{silvaContinuousOutcomePrediction2018} & 7,621 & 52 & 25 min & professional & 0.835 \\
\citeauthor{claytorRiotGamesAWS2023} \cite{claytorRiotGamesAWS2023}  & \TblrNote{e} & 24 & in-game\TblrNote{c} & professional & \TblrNote{a} \\ 

\citeauthor{mondalDoesSupportRole2022} \cite{mondalDoesSupportRole2022} & 296 & 5 & post game & \TblrNote{d} & \TblrNote{a} \\
\citeauthor{bahrololloomiESportsPlayerPerformance2023} \cite{bahrololloomiESportsPlayerPerformance2023} & 2,901 & 15 & post-game & \TblrNote{d} &0.86 \\
\citeauthor{aniVictoryPredictionLeague2019} \cite{aniVictoryPredictionLeague2019} & 1,500 & 97 & post-game & professional & 0.955 \\
\citeauthor{linLeagueLegendsMatch2016} \cite{linLeagueLegendsMatch2016} & 3000 &  \TblrNote{b} & post-game & Gold & 0.936 \\
\hline
\end{longtblr}


\chapter{Background}
\label{chap:background}

This work utilizes a variety of different methods, including \ac{gbt} for feature selection and \ac{rnn}/\ac{gru} for win prediction.
These methods are presented in this chapter, following a general description of \ac{lol}.

\section{League of Legends}
\label{sec:LoL}

\Ac{lol} is played with 5 players on each team on a map which is bifurcated into two bases, each linked by three lanes and housing a crucial structure called the \textit{nexus}, which is protected by turrets. 
The game's primary goal is to destroy the opposing team's nexus.
The map includes a jungle area in between the lanes with neutral monsters and two significant creatures, Baron Nashor and the Dragon, offering team-wide benefits when defeated.
A schematic overview of the map is provided in Figure \ref{fig:map}.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.5\textwidth]{./images/Map_of_MOBA.png}
\caption[Schematic visualization of the map \ac{lol} is played on.]{Schematic visualization of the map \ac{lol} is played on \cite{raizinFileMapMOBA2013}. }
\label{fig:map}
\end{figure}
Players must accumulate gold and \ac{xp} through defeating minions, neutral monsters, or enemy champions. 
These in-game currencies are essential for purchasing items and levelling up, thereby augmenting a champion's capabilities.

Player roles in \ac{lol} are typically assigned with one player in the top lane, one in the mid lane, two in the bottom lane, and one in the jungle, facilitating strategic diversity and role specialization.
Players select from a roster of 165 champions, each with unique abilities and characteristics, to compete in matches.
Champion selection is a pivotal element of \ac{lol} gameplay, requiring players to consider team composition, damage types, assigned roles, and personal proficiency with specific champions. 
The theoretical number of possible champion combinations in a game is $\binom{165}{10} = \num{3.21e15}$.
Although this number is quite a bit smaller in reality as not every champion can play every role and most players are only really proficient with a handful of champions, this underscores the game's strategic depth.

Each year, \ac{lol} introduces a new 'season', bringing substantial changes, and Riot Games issues bi-weekly patches to adjust champion balance, influencing the prevailing game strategies, or 'meta'.
These patches can also include the release of a new champion or the rework of an old one.
Frequent changes force players to be able to quickly adapt and learn new champions and mechanics.

To evaluate player skill, \ac{lol} utilizes a proprietary rating system, commonly assumed to be a modified Elo system \cite{janssonNeuralNetworksStandardizing2022}.
This system ensures that players are matched with and against others of comparable skill levels, maintaining competitive balance and fairness in the game.

\section{Neural Networks}
\label{sec:nn}

\Acp{ann} are computational models that emulate the processing patterns of the human brain. The fundamental computational unit of an ANN is the neuron, a concept first proposed by \citeauthor{mccullochLogicalCalculusIdeas1943} \cite{mccullochLogicalCalculusIdeas1943}.
A neuron computes an output activation $a$ from a set of input values $\mathbf{x} = (x_1, x_2, \ldots, x_m)$, where $m$ denotes the number of inputs. 
The neuron's weighted input $z$ is calculated as the dot product of the input vector $\mathbf{x}$ and the weight vector $\mathbf{w} = (w_1, w_2, \ldots, w_m)$, plus a bias term $b$:
\begin{equation}
z = \sum_{i=1}^{m} w_i x_i + b = \mathbf{w}^\top \mathbf{x} + b.
\end{equation}
The weighted sum $z$ is then passed through an activation function $\phi$, such as a sigmoid or \ac{relu}, to introduce non-linearity:
\begin{equation}
a = \phi(z) = \phi(\mathbf{w}^\top \mathbf{x} + b).
\end{equation}

The \ac{mlp}, introduced by \citeauthor{rosenblattPerceptronProbabilisticModel1958} \cite{rosenblattPerceptronProbabilisticModel1958}, organizes neurons into layers. 
Data flows from the input layer, through one or more hidden layers, to the output layer. In a fully connected feed-forward network, the computation in each layer $l$ is:
\begin{equation}
\mathbf{z}^{(l)} = \mathbf{W}^{(l)} \mathbf{a}^{(l-1)} + \mathbf{b}^{(l)},
\label{eq:ann_zl}
\end{equation}
where $\mathbf{a}^{(l-1)}$ represents the activation of the previous layer, $\mathbf{W}^{(l)}$ the weight matrix, and $\mathbf{b}^{(l)}$ the bias vector of layer $l$.
The vector $\mathbf{z}^{(l)}$ is then passed through the activation function for layer $l$, which is applied elementwise:
\begin{equation}
\mathbf{a}^{(l)} = \phi (\mathbf{z}^{(l)}).
\label{eq:ann_yhat}
\end{equation}
The output layer $L$ produces the network's prediction $\mathbf{\hat{y}}$.
The choice of activation function is dependent on the task, a common choice for classification is the softmax function \cite{bridleProbabilisticInterpretationFeedforward1990}:
\begin{equation}
\label{eq:softmax}
 S(\mathbf{x}_i) = \frac{e^{x_i}}{\sum_{k=1}^{K} e^{x_k}},
\end{equation}
where $K$ is the number of classes and $i = 1, ..., K$.
The softmax function returns a probability distribution over the predicted output classes.

To approximate any measurable function, an \ac{ann} requires at least one hidden layer \cite{hornikMultilayerFeedforwardNetworks1989}. 
The network's weights and biases are adjusted during training to minimize a loss function $E$.
Common loss functions include \ac{mse} for regression tasks:
\begin{equation}
E_N = \frac{1}{N} \sum_{k=1}^{N}(y_{k} - \hat{y}_{k})^2,
\end{equation}
and \ac{cel} for multi-class classification tasks:
\begin{equation}
E_N = -\frac{1}{N} \sum_{n=1}^{N} \sum_{k=1}^{K} y_{nk} \log (\hat{y}_{nk}),
\end{equation}
where $N$ is the number of samples, $y_{nk}$ is the (one-hot encoded) ground truth and $\hat{y}_{nk}$ is the softmax output of sample $n$ and class $k$.

Backpropagation \cite{rumelhartLearningRepresentationsBackpropagating1986} is a key algorithm for training \acp{ann}, involving a forward pass to compute activations and a backward pass to compute gradients. 
The gradients of the loss function with respect to the weights and biases are computed using the chain rule of calculus. For a given layer $l$, the gradient of the loss $E$ with respect to the weights $\mathbf{W}^{(l)}$ is
\begin{equation}
\Delta
\frac{\partial E}{\partial \mathbf{W}^{(l)}} = \frac{\partial E}{\partial \mathbf{a}^{(l)}} \cdot \frac{\partial \mathbf{a}^{(l)}}{\partial \mathbf{z}^{(l)}} \cdot \frac{\partial \mathbf{z}^{(l)}}{\partial \mathbf{W}^{(l)}},
\end{equation}
and with respect to the bias $\mathbf{b}^{(l)}$
\begin{equation}
\frac{\partial E}{\partial \mathbf{b}^{(l)}} = \frac{\partial E}{\partial \mathbf{z}^{(l)}} \cdot \frac{\partial \mathbf{z}^{(l)}}{\partial \mathbf{b}^{(l)}} = \frac{\partial E}{\partial \mathbf{z}^{(l)}}
\end{equation}
as 
\begin{equation}
\frac{\partial \mathbf{z}^{(l)}}{\partial \mathbf{b}^{(l)}} = 1.
\end{equation}
The gradients are then used to update the weights and biases, typically using an optimization algorithm like gradient descent, where the weights are updated via:
\begin{equation}
\mathbf{W}^{(l)} = \mathbf{W}^{(l)} - \eta \frac{\partial E}{\partial \mathbf{W}^{(l)}}
\end{equation}
with $\eta$ being the learning rate.

Through iterative forward and backward propagation, the network gradually converges to a state where the loss is minimized, indicating successful learning of the patterns in the data.

\section{Recurrent Neural Networks}
\label{sec:rnn}

\Ac{rnn} extend the capabilities of feed-forward neural networks to handle sequential data by introducing the concept of recurrence. 
In an \ac{rnn}, the output at each time step is influenced not only by the current input but also by the network's previous internal state, known as the hidden state. 
This design enables \acp{rnn} to capture temporal dependencies, making them particularly effective for tasks involving sequential data, such as speech recognition and natural language processing \cite{lecunDeepLearning2015}.
The concept of a fully connected \ac{rnn} was first proposed by \citeauthor{elmanFindingStructureTime1990} \cite{elmanFindingStructureTime1990}.

\Acp{rnn} maintain a 'state vector' in their hidden units, which implicitly contains information extracted from all past elements of the sequence \cite{lecunDeepLearning2015}.
Compared to vanilla \acp{ann}, the \ac{rnn} has three weight matrices $\mathbf{W}$, $\mathbf{V}$ and $\mathbf{U}$, which represent input-to-hidden, hidden-to-output and temporal connections (see Figure \ref{fig:rnn_unroll}).
These matrices are shared across timesteps.
The hidden state $\mathbf{h}_t$ at time step $t$ is updated as follows:
\begin{equation}
\label{eq:rnn_update} 
\mathbf{h}_t =
\begin{cases}
	0, & \text{if } t = 0, \\
	\sigma_h (\mathbf{W} \mathbf{x}_t + \mathbf{U} \mathbf{h}_{t-1} + \mathbf{b}_h)
	& \text{otherwise},
\end{cases}
\end{equation}
where $\mathbf{U}$ is the weight matrix for the hidden state, $\mathbf{W}$ is the weight matrix for the input and $\mathbf{b}_h$ is the bias.
A common choice for $\sigma_h$ is the tanh function.
The output $\mathbf{\hat{y}}_t$ of an \ac{rnn} at time step $t$ can be calculated similar to (\ref{eq:ann_zl}) and (\ref{eq:ann_yhat}) with:
\begin{equation}
\label{eq:rnn_output}
\begin{split}
\mathbf{o}_t &= \mathbf{V} \cdot \mathbf{h}_t + \mathbf{b}_h \\
\mathbf{\hat{y}}_t &= S(\mathbf{o}_t)
\end{split}
\end{equation}
where $\mathbf{V}$ is the weight matrix associated with the cell output and $S$ the softmax function defined in (\ref{eq:softmax}). 
The loss over $T$ timesteps is defined by 
\begin{equation}
E_T = \frac{1}{T} \sum_{t=1}^{T} {E(\mathbf{\hat{y}}_t, \mathbf{y})}
\end{equation} 
where $E(\mathbf{\hat{y}}_t, \mathbf{y})$ is the loss at timestep $t$.

\Ac{bptt} unfolds the \ac{rnn} across time steps (see Figure \ref{fig:rnn_unroll}) and applies the backpropagation algorithm. 
\begin{figure}[htbp]
\centering
\begin{tikzpicture}[
item/.style={circle,draw,thick,align=center, minimum size=1.2cm},
hidden/.style={item,on chain,join}]

 \begin{scope}[start chain=going right,nodes=hidden,every
 join/.style={-latex,very thick},local bounding box=chain]
 \draw node (A0) {$\mathbf{h}_0$} node (A1) {$\mathbf{h}_1$} node (A2) {$\mathbf{h}_2$} node[xshift=2em] (At)
 {$\mathbf{h}_t$};
 \end{scope}
 \node[left=1em of chain,scale=2] (eq) {$=$};
 \node[left=2em of eq,item] (AL) {$\mathbf{h}$};
 \path (AL.west) ++ (-1em,2em) coordinate (aux);
 \draw[very thick,-latex,rounded corners] (AL.east) -| ++ (1em,2em) -- (aux) --++(0em,-2em) node[midway, left] {$\mathbf{U}$} -- (AL.west); 
 \foreach \X in {0,1,2,t}
 {\draw[very thick,-latex] (A\X.north) -- ++ (0,2em) node[midway, right] {$\mathbf{V}$}
 node[above,item,fill=gray!10] (h\X) {$\mathbf{\hat{y}}_\X$};
 \draw[very thick,latex-] (A\X.south) -- ++ (0,-2em) node[midway, right] {$\mathbf{W}$}
 node[below,item,fill=gray!10] (x\X) {$\mathbf{x}_\X$};
 \path (A0.east) -- (A1.west) node[midway, above] {$\mathbf{U}$};
 \path (A1.east) -- (A2.west) node[midway, above] {$\mathbf{U}$};
 \path (A2.east) -- (At.west) node[midway, above] {$\mathbf{U}$};
}
 
 \draw[white,line width=0.8ex] (AL.north) -- ++ (0,1.9em);
 \draw[very thick,-latex] (AL.north) -- ++ (0,2em) node[midway, right] {$\mathbf{V}$}
 node[above,item,fill=gray!10] {$\mathbf{\hat{y}}_t$};
 \draw[very thick,latex-] (AL.south) -- ++ (0,-2em) node[midway, right] {$\mathbf{W}$}
 node[below,item,fill=gray!10] {$\mathbf{x}_t$};
 \path (x2) -- (xt) node[midway,scale=2,font=\bfseries] {\dots};
\end{tikzpicture}
\caption[Unrolling of an \ac{rnn} over time.]{Unrolling of an \ac{rnn} over time by creating a copy of the model for each time step $t$ with shared weight matrices, where $\mathbf{U}$ is the matrix representing the recurrent connection and the grey nodes containing $\mathbf{x}_t$ and $\mathbf{\hat{y}}_t$ are the input and output at timestep $t$.}
\label{fig:rnn_unroll}
\end{figure}
In order to train the weight matrices, we need the partial derivatives of $E_T$ with respect to $\mathbf{U}$, $\mathbf{V}$ and $\mathbf{W}$.

As the weight matrices are shared across timesteps, we can generally sum up the gradients from each timestep $t$.
The gradient of the loss function with regards to the output matrix $\mathbf{V}$ does not depend on the hidden state $\mathbf{h}_t$ and can thus be calculated easily:
\begin{equation}
\label{eq:bptt_V}
\begin{split}
\frac{\partial E_T}{\partial \mathbf{V}} 
& = 
\sum_{t}^{T} \frac{\partial E_t}{\partial \mathbf{V}} \\
& =
\sum_{t}^{T} 
\frac{\partial E_t}{\partial \mathbf{\hat{y}}_t} 
\cdot 
\frac{\partial \mathbf{\hat{y}}_t}{\partial \mathbf{o}_t} 
\cdot 
\frac{\partial \mathbf{o}_t}{\partial \mathbf{V}}.
\end{split}
\end{equation}
Now we consider the gradient with respect to the weight matrix for the hidden state $U$ at the time step $t+1$:
\begin{equation}
\frac{\partial E_{t+1}}{\partial \mathbf{U}} = 
\frac{\partial E_{t+1}}{\partial \mathbf{\hat{y}}_{t+1}}
\frac{\partial \mathbf{\hat{y}}_{t+1}}{\partial \mathbf{h}_{t+1}}
\frac{\partial \mathbf{h}_{t+1}}{\partial \mathbf{U}}.
\end{equation}
As the hidden state $\mathbf{h}_{t+1}$ depends on the hidden state of the previous timestep $\mathbf{h}_t$, we need to recursively calculate the partial derivatives of all the previous timesteps, yielding the following formula:
\begin{equation}
\frac{\partial E_{t+1}}{\partial \mathbf{U}} = \sum_{k=1}^{t+1}
\frac{\partial E_{t+1}}{\partial \mathbf{\hat{y}}_{t+1}}
\frac{\partial \mathbf{\hat{y}}_{t+1}}{\partial \mathbf{h}_{t+1}}
\frac{\partial \mathbf{h}_{t+1}}{\partial \mathbf{h}_k}
\frac{\partial \mathbf{h}_k}{\partial \mathbf{U}}.
\end{equation}
Applying the chain rule to $\frac{\partial \mathbf{h}_{t+1}}{\partial \mathbf{h}_k}$ yields
\begin{equation}
\frac{\partial E_{t+1}}{\partial \mathbf{U}} = \sum_{k=1}^{t+1}
\frac{\partial E_{t+1}}{\partial \mathbf{\hat{y}}_{t+1}}
\frac{\partial \mathbf{\hat{y}}_{t+1}}{\partial \mathbf{h}_{t+1}}
\left(\prod_{j=k}^{t}\frac{\partial \mathbf{h}_{j+1}}{\partial \mathbf{h}_j}\right)
\frac{\partial \mathbf{h}_k}{\partial \mathbf{U}}
\end{equation}\cite{aratBackpropagationTimeRecurrent2019}.
Summing the partial derivatives over timesteps similar to (\ref{eq:bptt_V}) yields the full equation
\begin{equation}
\label{eq:bptt_U}
\frac{\partial E_T}{\partial \mathbf{U}} = 
\sum_{t=1}^{T}
\sum_{k=1}^{t}
\frac{\partial E_{t+1}}{\partial \mathbf{\hat{y}}_{t+1}}
\frac{\partial \mathbf{\hat{y}}_{t+1}}{\partial \mathbf{h}_{t+1}}
\frac{\partial \mathbf{h}_{t+1}}{\partial \mathbf{h}_k}
\frac{\partial \mathbf{h}_k}{\partial \mathbf{U}},
\end{equation}
where
\begin{equation}
\label{eq:bptt_ht+1}
\frac{\partial \mathbf{h}_{t+1}}{\partial \mathbf{h}_k} 
= 
\left(\prod_{j=k}^{t}\frac{\partial \mathbf{h}_{j+1}}{\partial \mathbf{h}_j}\right)
=
\frac{\partial \mathbf{h}_{t+1}}{\partial \mathbf{h}_t}
\frac{\partial \mathbf{h}_{t}}{\partial \mathbf{h}_{t-1}}
 . . . 
\frac{\partial \mathbf{h}_{k+1}}{\partial \mathbf{h}_k}.
\end{equation}
The gradient with respect to $\mathbf{W}$ follows similarly.

As first demonstrated by \citeauthor{bengioLearningLongtermDependencies1994} \cite{bengioLearningLongtermDependencies1994}, \acp{rnn} face challenges with exploding or vanishing gradients, particularly in long sequences.
The underlying mechanics of this issue can be illustrated by analysing the gradient flow within the network, specifically through the Jacobian matrix representing the transition from one hidden state, $\mathbf{h}_t$, to the next, $\mathbf{h}_{t+1}$:
\begin{equation}
\label{eq:bptt_jacobian}
\frac{\partial \mathbf{h}_{j+1}}{\partial \mathbf{h}_j} = \text{diag}(\sigma_h' (\mathbf{U} \mathbf{h}_j + \mathbf{b}_h)) \mathbf{U},
\end{equation}
where diag() converts a vector into a diagonal matrix and $\sigma '$ computes the element-wise derivative of $\sigma$
\cite{pascanuDifficultyTrainingRecurrent2013}.
Eigendecomposition of this Jacobian matrix yields the eigenvalues $ \lambda_1, \lambda_2, ..., \lambda_n$ with their magnitudes indicating the gradient's behaviour over time: $|\lambda_1| > |\lambda_2| > ... > |\lambda_n|$.
The corresponding eigenvectors, $v_1, v_2, ..., v_n$, determine the directions in which these changes occur.
The change in hidden state $\Delta h_{j+1}$ in direction of a vector $v_i$ is multiplied with the corresponding eigenvalue $\lambda_i \Delta h_{j+1}$, leading to the multiplication factor $\lambda_i^t$ over timesteps $t$.
This scaling factor is pivotal, as when $\lambda_1 < 1$, gradients vanish, and when $\lambda_1 > 1$ gradients explode as $t \to \infty$ \cite{pascanuDifficultyTrainingRecurrent2013}.

The presence of exploding or vanishing gradients not only complicates the training process but also severely limits the network's capacity to capture dependencies over extended sequences. \cite{sutskeverTrainingRecurrentNeural2013}. 
This issue has prompted the development of alternative architectures, such as \ac{lstm} networks and \acp{gru}, which incorporate mechanisms to regulate the flow of information and gradients, thereby mitigating the adverse effects of this phenomenon.



\section{Gated Recurrent Unit}
\label{sec:gru}

\begin{figure}[htbp]
\centering
\begin{tikzpicture}[
    % Styles
    cell/.style={% For the main box
        rectangle, 
        rounded corners=5mm, 
        draw,
        very thick,
        },
    operator/.style={%For operators like +  and  x
        circle,
        draw,
        inner sep=0.5pt,
        minimum height =.2cm,
        },
    function/.style={%For functions
        ellipse,
        draw,
        inner sep=3pt
        },
    ct/.style={% For external inputs and outputs
        circle,
        draw,
        line width = .75pt,
        minimum width=1cm,
        inner sep=1pt,
        },
    gt/.style={% For internal inputs
        rectangle,
        draw,
        minimum width=4mm,
        minimum height=3mm,
        inner sep=3pt
        },
    ArrowC1/.style={% Arrows with rounded corners
        rounded corners=.25cm,
        thick,
        },
    ArrowC2/.style={% Arrows with big rounded corners
        rounded corners=.5cm,
        thick,
        },
    ]
    
   %Start drawing the thing...    
    % Draw the cell: 
    \node [cell, minimum height =4cm, minimum width=6cm] at (0,0){} ;
    
    
	%Draw operators	
	%top row
	\node [operator] (mux1) at (0,1.5) {$\odot$};
    \node [operator] (add1) at (2,1.5) {$+$};
    %second row
    \node [operator] (mux2) at (-2, 0.5) {$\odot$};
    \node [operator] (mux3) at (2,  0.5) {$\odot$};
    \node [operator, inner sep=0pt] (minus) at (1, 0.5) {
    \begin{scriptsize}
    $1-$
    \end{scriptsize}
    };
    %bottom row
    \node [gt] (sigma1) at (-1.5, -0.5) {$\sigma$};
    \node [gt] (sigma2) at (0, -0.5) {$\sigma$};
    \node [gt] (tanh) at (2, -0.5) {$\tanh$};
    
    %draw node to show location of gates
    \node[] (zt) at (1, -0.5) {$\mathbf{z}_t$};
    \node[]  (rt) at (-1, 0) {$\mathbf{r}_t$};
    
  % Draw External inputs
    \node[] (ht-1) at (-4,1.5) {$\mathbf{h}_{t-1}$};
    \node[outer sep=1] (xt) at (-2.5,-3) {$\mathbf{x}_t$};

    % Draw External outputs
    \node[] (out) at (4,1.5) {$\mathbf{h}_t$};
    \node[] (ht) at (2.5,3) {$\mathbf{\hat{y}}_t$};
    
   % Draw Arrows
   % input
	\draw [ArrowC2] (ht-1) -- (mux1) ;
	\draw [->, ArrowC1] (ht-1) -| (mux2);
	\draw[->, ArrowC1] (ht-1) -| (-2.5, -1) -| (sigma1);
	\draw[->, ArrowC1] (xt.north) -| (-2.5, -1) -| (sigma1);
	\draw[->, ArrowC1] (xt.north) |- (-1.5, -1.5) -|(tanh);
	\draw[->, ArrowC1] (xt.north) -| (-2.5, -1) -| (sigma2);
   
	% Internal   
	\draw[->, ArrowC1] (mux1) -- (add1) -- (out);
	\draw[ArrowC1] (mux2) |- (-1,-1.5); 
	\draw[->, ArrowC1] (sigma1) |- (mux2);
	\draw[->, ArrowC1] (sigma2) -- (mux1);
	\draw[->, ArrowC1] (sigma2) |- (minus);
	\draw[->, ArrowC1] (minus) -- (mux3);
	\draw[->, ArrowC1] (tanh) -- (mux3);
	\draw[->, ArrowC1] (mux3) -- (add1);
   
   %Output
   \draw[->, ArrowC1] (add1) -| (ht);
    
\end{tikzpicture}
\caption{Gated Recurrent Unit, where round operators denote elementwise operators and rectangular boxes denote fully connected layers with the shown activation function (adapted from \cite{zhaoMachineHealthMonitoring2018}).}
\label{fig:gru}
\end{figure}

In order to overcome the exploding/vanishing gradient problem of vanilla \acp{rnn}, gated networks like the \ac{lstm} \cite{hochreiterLongShortTermMemory1997} and \ac{gru} \cite{choLearningPhraseRepresentations2014} have been developed \cite{vanhoudtReviewLongShortterm2020}.
As they introduce an increased number of parameters compared to traditional \acp{rnn}, gated networks like the \ac{lstm} and \ac{gru} demand greater computational power \cite{deyGatevariantsGatedRecurrent2017}.
Gating mechanisms mitigate the exploding/vanishing gradient problem by regulating how much the hidden state is updated each step.
Compared to the \ac{lstm} network, \ac{gru} reduces the number of gate networks to two, thus being simpler to implement and compute \cite{choLearningPhraseRepresentations2014} (see Figure \ref{fig:gru}).
\Citeauthor{chungEmpiricalEvaluationGated2014} even found that \ac{gru} is at least comparable to \ac{lstm} in most cases \cite{chungEmpiricalEvaluationGated2014}.
The gates control the activation of each hidden unit.
The reset gate $\mathbf{r}_t$ is calculated by
\begin{equation}
\label{eq:gru_reset}
\mathbf{r}_t = \sigma (\mathbf{W}_r \mathbf{x}_t + \mathbf{U}_r \mathbf{h}_{t-1})
\end{equation}
and the update gate $\mathbf{z}_t$ by
\begin{equation}
\label{eq:gru_update}
\mathbf{z}_t = \sigma (\mathbf{W}_z \mathbf{x}_t + \mathbf{U}_z \mathbf{h}_{t-1})
\end{equation}
\cite{deyGatevariantsGatedRecurrent2017}.
The hidden state update is a linear interpolation between the previous activation $\mathbf{h}_{t-1}$ and the candidate activation $\mathbf{\tilde{h}}_t$, where the update gate $\mathbf{z}_t$ influences how much the hidden state is changed \cite{chungEmpiricalEvaluationGated2014}:
\begin{equation}
\label{eq:gru_h}
\mathbf{h}_t = (1-\mathbf{z}_t) \odot \mathbf{\tilde{h}}_t + \mathbf{z}_t \odot \mathbf{h}_{t-1} 
\end{equation}
with
\begin{equation}
\label{eq:gru_h_tilde}
\mathbf{\tilde{h}}_t = \tanh(\mathbf{W}_h \mathbf{x}_t + \mathbf{U}_h (\mathbf{r}_t \odot \mathbf{h}_{t-1})).
\end{equation}
In equations (\ref{eq:gru_h}) and (\ref{eq:gru_h_tilde}) $\odot$ denotes the element-wise (Hadamard) multiplication.
Equation \ref{eq:gru_h} shows that if $\mathbf{z}_t$ is close to one, previous memory in $\mathbf{h}_{t-1}$ is propagated to $\mathbf{h}_t$ and the model learns long-term dependencies.
Conversely, if $\mathbf{r}_t$ is active and $\mathbf{z}_t$ is not, the hidden state gets updated with information from the last step, thus learning short-term dependencies.
This selective inclusion of new information and the ability to skip a timestep completely can help mitigate the exploding / vanishing gradient problem described in Section \ref{sec:rnn}.



\section{Feature Selection}
\label{sec:fs_algos}

Feature Selection is pivotal in machine learning, particularly when dealing with high-dimensional data. It serves the primary objectives of improving model performance by mitigating the 'curse of dimensionality' \cite{bellman1961adaptive}, enhancing predictive accuracy, and reducing overfitting. By eliminating irrelevant or redundant features, the model's generalization capacity is enhanced, contributing to model interpretability and potentially reducing training times.
Feature selection methods can be broadly categorized into three distinct types \cite{jovicReviewFeatureSelection2015}:
\begin{description}

\item[Filter Methods] These methods rely on model-invariant information, such as feature-class label correlation. They are computationally efficient and typically do not require user input in form of hyperparameters, but may not capture complex relationships within the data.

\item[Wrapper Methods] Models are trained iteratively on various feature subsets, incurring a higher computational cost but enabling the detection of interactions among variables \cite{venkateshReviewFeatureSelection2019}.

\item[Embedded Methods] These methods perform inherent feature selection, often as an integral part of the modelling process. Tree-based models, such as Decision Trees and \ac{gbt}, typically employ feature selection based on metrics like the Gini index or entropy.
\end{description}

The two methods used in this work are a filter method (\ac{pcc}) and an embedded method (\ac{gbt}) and are presented in more detail below.


\subsection*{Pearson's Correlation Coefficient}
\label{ssec:pearsons}
\Ac{pcc} is a statistical measure widely used to evaluate the linear relationship between two variables. 
Specifically, we consider its application in the context of feature selection in machine learning, where it is used to assess the linear correlation between input features and the target variable. 
We regard the input vector $\mathbf{x}$ as a manifestation of an underlying, unknown distribution. 
Here, $X_i$ represents the random variable corresponding to the $i^{\text{th}}$ component of $\mathbf{x}$, and $y$ is the target value, viewed as a realization of the random variable $Y$ \cite{guyonIntroductionVariableFeature2003}. 
\Ac{pcc} is employed to quantify the linear correlation between these two random variables. It is defined by the formula:
\begin{equation}
R(i) = \frac{\text{cov}(X_i, Y)}{\sqrt{\text{var}(X_i) \cdot \text{var}(Y)}},
\end{equation}
where $\text{cov}(X_i, Y)$ is the covariance between $X_i$ and $Y$, and $\text{var}(X_i)$ and $\text{var}(Y)$ are the variances of $X_i$ and $Y$, respectively \cite{chandrashekarSurveyFeatureSelection2014}.
$R(i) \in [-1; +1]$ where -1 and +1 are strong negative or positive correlations and 0 indicates no correlation. 
A hypothesis test should be performed in order to ascertain the significance of the test results, with the null hypothesis that there is no correlation between the feature and the target.
As it is a non-parametric model, there is no need to tune hyperparameters or risk of overfitting.
While simple and effective for identifying linear relationships, \ac{pcc} only captures linear dependencies and might miss non-linear relationships crucial for neural networks.
Despite these limitations, \ac{pcc} is a valuable tool in feature selection for its simplicity and efficiency in revealing linear correlations.

\subsection*{Gradient Boosted Trees}
\label{ssec:gbt}

\Acf{gbt} \cite{friedmanGreedyFunctionApproximation2001} is an ensemble learning technique that can be used for feature selection. 
The core idea of \ac{gbt} is to build a model in a stage-wise fashion, where each tree incrementally improves upon the previous ones by correcting their errors. 
This process involves training trees sequentially, with each new tree learning to predict the residuals or errors of the previous ensemble of trees.

The mathematical foundation of \ac{gbt} can be described through the framework of additive models. 
Given a dataset with $n$ instances $(\mathbf{x}_i, y_i)$, where $\mathbf{x}_i$ represents the feature vector of the $i$-th instance and $y_i$ is its corresponding target value, the goal of \ac{gbt} is to find an approximation $\hat{F}(\mathbf{x})$ to the true function $F^{*}: \mathbf{x} \rightarrow y$ that minimizes the expected value of the loss function $L(y, F(\mathbf{x}))$. 
\Ac{gbt} models build an approximation of $F(\mathbf{x})$ as the weighted sum of the functions
\begin{equation}
F_m(\mathbf{x}) = F_{m-1}(\mathbf{x}) + \phi_m h_m(\mathbf{x})
\end{equation}
where $\phi_m$ is the weight of the $m^{th}$ function $h_m(\mathbf{x})$ \cite{bentejacComparativeAnalysisGradient2021}.
This function $h_m(\mathbf{x})$ is usually a classification tree and called a \textit{weak learner}.
The iterative construction starts with a constant model 
\begin{equation}
F_0(\mathbf{x}) = \arg\min_{\gamma} \sum_{i=1}^{n} L(y_i, \gamma)
\end{equation}
 and incrementally adds weak learners $h_m(\mathbf{x})$ to minimize the loss function. 
Each subsequent tree models the residual errors made by the previous ensemble of trees. Specifically, at each stage $m$, a tree $h_m(\mathbf{x})$ is fitted to the negative gradient of the loss function
\begin{equation}
-\left[\frac{\partial L(y_i, F(\mathbf{x}))}{\partial F(\mathbf{x})}\right]_{F(\mathbf{x})=F_{m-1}(\mathbf{x})},
\end{equation}
evaluated at the predictions $F_{m-1}(\mathbf{x})$ of the current model.

Different types of feature importance can be calculated from a \ac{gbt} model, such as the average or total gain across all splits the feature is used in.
The simplest definition is the 'weight', defined as the number of times a feature is used to split the data across all trees \cite{chenXGBoostScalableTree2016}.

\chapter{Experiments}
\label{chap:experiments}
This section introduces two distinct experiments designed to evaluate the effectiveness of predictive models in \ac{lol}. The initial experiment centers on pre-game win prediction through a neural network, utilizing historical and statistical data before the game starts. In contrast, the subsequent experiment explores real-time prediction using a \ac{gru} model, aiming to dynamically determine winning probabilities as the game unfolds.
Figure \ref{fig:flowchart} shows the different steps both for pre-game and in-game win prediction.

\begin{figure}[htbp]
\centering
\begin{tikzpicture}[%
   % >=triangle 60,              % Nice arrows; your taste may be different
    start chain=going below,    % General flow is top-to-bottom
    node distance=6mm and 60mm, % Global setup of box spacing
    every join/.style={norm},   % Default linetype for connecting boxes
    ]

\tikzstyle{startstop} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm,text centered, draw=black]
\tikzstyle{io} = [trapezium, trapezium left angle=70, trapezium right angle=110, minimum width=3cm, minimum height=1cm, text centered, draw=black]
\tikzstyle{process} = [rectangle, minimum width=3cm, minimum height=1cm, text centered, draw=black, text width=3cm,]
\tikzstyle{decision} = [diamond, minimum width=3cm, minimum height=1cm, text centered, draw=black]
\tikzstyle{arrow} = [thick,->,>=stealth]

\node [process] (t0){Data Collection \ref{ssec:datacoll}};
\node [process, below=of t0] (t1) {Pre-Game Dataset}; 
\node [process, below=of t1] (t2){Dataset Properties \ref{ssec:dataprop}}; 

\node [process, right=of t1] (t3) {In-Game Dataset};
\node [process, below=of t2] (t4) {Feature Engineering \ref{sec:data_processing}}; 
\node [process, right=of t4] (t5) {Feature Engineering \ref{sec:data_processing}};
\node [process, below=of t4] (t6) {Partitioning};
\node [process, right=of t6] (t7) {Partitioning};
\node [process, below=of t6] (t8) {Algorithmic Feature Selection \ref{ssec:fs_setup}};
\node [process, right=of t8] (t9) {Manual Feature Selection};
\node [process, below=of t8] (t10) {Hyperparameter Optimization \ref{ssec:hyperparam_optim}};
\node [process, right=of t10] (t11) {Hyperparameter Optimization \ref{ssec:hyperparam_optim}};
\node [process, below=of t10] (t12) {Training and Evaluation \ref{sec:results}};
\node [process, right=of t12] (t13) {Training and Evaluation \ref{sec:results}};


% arrows

\draw [arrow] (t0) -- (t1);
\draw [arrow] (t1) -- (t2);
\draw [arrow] (t1) -- (t3)node[midway, above] {Random Sample};
\draw [arrow] (t2) -- (t4);
\draw [arrow] (t3) -- (t5);
\draw [arrow] (t4) -- (t6);
\draw [arrow] (t5) -- (t7);
\draw [arrow] (t6) -- (t8);
\draw [arrow] (t7) -- (t9);
\draw [arrow] (t8) -- (t10);
\draw [arrow] (t9) -- (t11);
\draw [arrow] (t10) -- (t12);
\draw [arrow] (t11) -- (t13);


\end{tikzpicture}
\caption{Flowchart of the data processing and model training steps with their corresponding sections.}
\label{fig:flowchart}
\end{figure}

\section{Data}
\label{sec:data}

Building upon the aforementioned approach, two different datasets are used: one dataset containing all relevant information prior to the start of the game and one dataset containing only the temporal information from the beginning of the game.


\subsection{Data Collection}
\label{ssec:datacoll}

The data collection process for this study involved a dual-pronged approach, leveraging the resources provided by the Riot Games API alongside a targeted web-scraping strategy.
The resulting raw dataset reflects a comprehensive compilation of high-rank amateur \acl{lol} matches.
The important parameters for data collection are presented below.

\paragraph{High-Rank Matches}
The rating system in \ac{lol} groups players into different skill groups, where the lowest is 'Iron' and the highest 'Challenger'.
The two highest ranks,'Grandmaster' and 'Challenger' contain the best 300 or 700 players on each server.
The exact number of players in these tiers depend on the player number in each region (see \cite{riotgamesMasterGrandmasterChallenger2023}).

Similar to the methodology of \citeauthor{zhangPredictionEsportsGame2021} \cite{zhangPredictionEsportsGame2021}, the focus of data acquisition was directed towards high-rank matches, in which a mix of excellent amateur and professional players play.
High rank matches in this context are defined as having at least one player holding the rank of Master, Grandmaster or Challenger.
These ranks combined account for the top $0.2\%$ of all players \cite{riotgamesRankedTiersDivisions2023}.
Riot Games themselves considers any rank above Diamond 3 as 'Elite' \cite{riotgamesDevBalanceFramework2020}, but we raise this bar just slightly to only include any rank at Master or above.
Due to the fact that for a match to be included in the dataset, only one out of ten players needs to hold one of the aforementioned highest ranks, some slightly lower ranked players are also present in the dataset.

Lower rank matches are not considered due to their higher unpredictability as less skilled players are assumed to make huge, game-changing mistakes more often.
This higher unpredictability could make it harder for the model to learn.

Pro matches, defined as professional players playing with their respective teams in an esports tournament or league, are not included as they are not available through the official Riot Games API.
Professional players are still included in the dataset, but only if they played regular, non-tournament games.

\paragraph{Riot Games API}
The primary source of data stems from the Riot Games API \cite{RiotDeveloperPortal}, a comprehensive repository of information pertaining to \ac{lol} gameplay.
The Riot Games API provides access to a plethora of essential data points, including champion statistics, general match information, timeline details, and player-specific information.

\paragraph{Other Data Sources}
However, not all pertinent data were available directly from the Riot Games API.
These include the general winning chance of each champion and statistics on how each player performs on each relevant champion.
To address this limitation, additional relevant information was gathered by using web scraping on a website for aggregation of player and game statistics, specifically www.u.gg \cite{GGBestLeague}.
\paragraph{Regions}
Multiple regions were included in the data collection process, including Europe West (EUW), Europe Nordic \& East (EUN), Korea (KR), and North America (NA).
This regional diversity contributes to the model's generalizability across different player bases and playing styles.
It is important to note that due to a lack of official data pertaining to the number of games played or the number of players in each region, it is currently not feasible to conclusively verify whether the distribution of matches within our dataset aligns with the true underlying distribution of games played per region.
The major regions in the dataset are the same regions getting guaranteed spots at the world championship \cite{2023LeagueLegends2023} with the exception of China, whose matches are not available through the Riot Games API.
Consequently, it is reasonable to assume that this composition approximately mirrors the real-world distribution of matches, with the exception of chinese games.
A visual representation of the distribution of matches across regions is provided in Figure \ref{fig:platformId}.

\begin{figure}[htbp]
\input{./images/platformId_distribution.pgf}
\caption{Region distribution of \ac{lol} games included in the pre-game dataset.}
\label{fig:platformId}
\end{figure}

\paragraph{Period of Time}
All matches included in the dataset were played in season 13 and on patch 20.
It is important that all matches are played on the same patch, as a patch may cause major shifts in the balance of the game, thus potentially making certain strategies and champions way better than others.

\paragraph{Game length}
As only matches with a game length of at least 16 minutes are collected, the shortest match is 16 minutes long, while the longest game is $59.62$ minutes long.
This minimum game length is chosen to guarantee the game's duration extends at least one additional minute following the win prediction, thereby ensuring the prediction's non-trivial nature.
The average match length is $27.50$ minutes.
Figure \ref{fig:gameDuration} graphically illustrates the distribution of game durations. 
Notably, the histogram reveals a prominent spike at the 16-minute mark.
This spike corresponds to the earliest possible conclusion time for a match, as \ac{lol} prohibits surrendering prior to the 15th minute of gameplay. 
In instances where an entire team collectively acknowledges the futility of their chances of victory, a surrender may be initiated at the 15-minute threshold.
However, should a simple majority of team members decide to surrender, they must adhere to a 20-minute waiting period before being able to do so. 
Consequently, this unique feature of the game's mechanics clarifies the relatively diminished frequency of matches ending in the 17th to 19th-minute range within the dataset.

\begin{figure}[htbp]
\input{./images/gameDuration_distribution.pgf}
\caption{Distribution of game duration with its kernel density estimation.}
\label{fig:gameDuration}
\end{figure}

\paragraph{Rank Distribution}
As only games with at least one player ranked Master or above are considered, this distribution does not match the real distribution of ranks.
This does introduce a bias and makes the findings less applicable to games in lower ranks.
As argued in \ref{ssec:datacoll}, lower ranked games could make the learning harder due to higher unpredictability.
\\\\
The pre-game dataset encompasses a total of 38,957 matches, while the in-game dataset contains 28,809 matches.
In \ref{ssec:dataprop}, the pre-game dataset characteristics are presented in more detail, as the smaller in-game dataset is a random sampling from the pre-game dataset. 
As it is a random sample, the dataset characteristics are shared. 
The sampling is necessary due to the long processing time of in-game data, necessitating a smaller dataset compared to pre-game data.

\begin{figure}[htbp]
\centering
\resizebox{\textwidth}{!}
{
\input{./images/tier_distribution.pgf}
}
\caption{Distribution of ranks in the dataset}
\label{fig:tier}
\end{figure}


\subsection{Pre-Game Dataset Properties}
\label{ssec:dataprop}

The raw pre-game dataset contains $368$ columns which can be categorized into four distinct groups: General Match Information, Player Information, Champion Information and Player-Champion Information.
General match information, such as the patch number, are exclusively utilized for validation purposes and are excluded from the final dataset.

\paragraph{Player Information.}
This feature $\mathbf{X}_p$ is a matrix with two elements, including the account level, serving as an indicator of the player's accumulated gaming experience, and the player's rank, functioning as a metric for assessing the player's skill level.

\paragraph{Champion Information.}
The Champion Information feature matrix $\mathbf{X}_c$ is composed of different metrics describing the success the players have with a particular champion over all games in all ranks (e.g. win rate).
Additionally, it contains more subjective information (e.g. difficulty) which is provided by Riot Games as a general guide to the champion.
However, it is noteworthy that a limitation inherent in these metrics lies in their aggregation across all player ranks, reducing their specificity to the ranks under analysis.

\paragraph{Player-Champion Information.}
This feature matrix $\mathbf{X}_f$ contains information about the player on a specific champion.
It encompasses metrics such as the average amount of gold earned by the player across all matches played on the champion during season 13. 
\Citeauthor{costaFeatureAnalysisLeague2021} \cite{costaFeatureAnalysisLeague2021} found that  the most pivotal feature within this category is the player's win rate while piloting this champion.
Unfortunately, this information is not readily available to be extracted by our web scraper,  necessitating its omission from the dataset.
Each feature category (e.g.  average gold per match) consists of 10 features, one for each participant.

\subsection{In-Game Dataset Properties}
\label{ssec:in_game_data}

The in-game dataset comprises 28,809 matches, representing a random subset extracted from the broader pre-game dataset.
$473$ features are used to describe the current state of the game at every minute, each forming a discrete time series.
These features encompass a range of player-specific metrics, including but not limited to damage inflicted on opponents, individual champion levels, and the accumulation of gold.
Furthermore, key events like the number of turrets destroyed and each team's total gold are tracked to more precisely gauge the game's state. 
Gold, a critical indicator, underscores each victory milestone - be it destroying a turret or defeating an adversary. 
As illustrated in Figure \ref{fig:totalGold}, members of the victorious team typically amass significantly more gold by the game's conclusion compared to their counterparts.
This is more prominent in the later stages of the game, making the win prediction earlier more difficult and showing that the total amount of gold is not very meaningful at earlier stages of the game.

\begin{figure}[htbp]
\input{./images/totalGold.pgf}
\caption[Total gold accumulated by each player of the course of an exemplary match]{Total gold accumulated by each player of the course of an exemplary match, separated into teams by color. The gold lead of the red team is increasing towards the end of the game, but at the 15th minute mark is not yet apparent.}
\label{fig:totalGold}
\end{figure}

Destroying turrets is crucial in the game, offering significant gold rewards and map control. 
With a minimum of five turrets required for victory, their destruction serves as a key indicator of a team's likelihood to win.
Both the number of destroyed turrets and the cumulative amount of gold is tracked for each team.

\section{Data Processing}
\label{sec:data_processing}

\paragraph{Missing Values}
There are no missing values in the data obtained directly from Riot Games.
On the rare occasion that the web scraper could not find the relevant information, missing values occur for a total of 813 rows.
As this is a technical error, the missing data can be assumed as being \ac{mcar} distributed \cite{acockWorkingMissingValues2005} and thus deleted row-wise without introducing a bias.
Even if this assumption should be false, due to the low number of affected samples the introduced bias would be very small.
As missing values are caused by the web scraper, the in-game dataset has no missing values.

\paragraph{Individual Feature Processing Pre-Game Dataset.}
The rank is converted from the rank-tier system into a single floating point number where the integer part denotes the tier (Master, Grandmaster, etc.) and the floating point part denotes the rank (ranges from 1-5, but only in Diamond and below).
The win rate is calculated by averaging over the number of wins and losses the player has accumulated over the season.
The champion tier is converted from D - S ranking into integer values and the champion number is one-hot encoded.
The one-hot encoding results in two vectors of size $n$ -- one for each team -- where $n$ is the number of champions and 
\begin{equation*}
x_i = 
\begin{cases}
	1 & \text{if a member of the team plays champion } i, \\
	0 & \text{otherwise}.
\end{cases}
\end{equation*}
It is only possible to represent the whole team composition in one vector because no two players can pick the same champion.
Ten features per category in $\mathbf{X}_f$ is a very fine-grained approach.
In order to get more meaningful features and reduce the dimensionality of the dataset, statistics are averaged for each team, reducing ten features per category to two.

\paragraph{Individual Feature Processing In-Game Dataset.}
The raw in-game dataset contains 474 features, 47 per participant and 2 columns per team containing the number of destroyed turrets and cumulative gold.
Utilizing domain expertise, 9 features per participant have been deemed extraneous and subsequently excluded, effectively reducing the feature count to 384. 
To further streamline the dataset, a dimensionality reduction strategy is employed whereby individual player metrics are averaged across their respective teams.
This method significantly decreases the total number of features, albeit at the expense of individual player variability and unique performance traits.
Such a reduction inherently shifts the analytical emphasis from individual prowess to overall team dynamics. 
Given that \ac{lol} is intrinsically a team-oriented game, this refocused perspective is anticipated to enhance the generalizability of a predictive model as the model is trained on team-level trends rather than individual fluctuations, which can be more noisy and less predictive of outcomes.

\paragraph{Scaling and Partitioning}
The pre-game dataset is partitioned into train, validation and test set with a validation and test size of 4,000 samples $ \approx 10\%$ respectively.
In order to have a more comparable training dataset size, the test and validation sets from the in-game dataset contain just 1,000 matches.
The validation set is used to optimize hyperparameters while the test set is used to evaluate the final performance of the model.
In order to allow proper training of the model, the data has to either be transformed into range $[1;-1]$ or standardized \cite{shankerEffectDataStandardization1996}.
The standardization is performed on each feature individually by calculating the mean $\mu$ and standard deviation $\sigma$ of the training set and applying the standardization $\mathbf{z} = (\mathbf{x} - \mu) / \sigma$ where $\mathbf{x}$ is the original data and $\mathbf{z}$ the transformed data.


\section{Experimental Setup}
\label{sec:exper_setup}

\subsection{General Setup}
\label{ssec:general_setup}
First, a separate feature selection process is conducted for each dataset, and the results are then applied to the respective datasets. 
Next, the pre-game and in-game classification models are trained on their respective datasets for comparison.

\subsection{Feature Selection}
\label{ssec:fs_setup}
In order to assess the linear relationship between features and the target variable for the pre-game dataset, \acl{pcc} is employed.
The correlation coefficients are calculated separately for each team and category and subsequently averaged over teams.
Only the absolute values of the \acp{pcc} are considered, as the direction of the relationship is of no concern when assessing its strength.

\Aclp{gbt} are used to include non-linear relationships in the analysis.
The model was configured with the following hyperparameters: number of estimators set to 100, maximum depth at 3, a learning rate of 0.1, and the objective function as binary logistic.
The Feature Importance Score is the number of times a feature was used to split the data across all trees.

\subsection{\Ac{ann} Parameters}
The fixed parameters can be seen in Table \ref{tab:static_hyperparam_optim}.
The \ac{ann} model architecture includes a series of fully connected layers, each followed by 1-dimensional batch normalization.
The exact number of layers is one of the parameters determined by the hyperparameter optimization (see \ref{ssec:hyperparam_optim}), while the BatchNorm is used to stabilize the learning process, as initial experiments have shown highly fluctuating training loss.
Exponential Linear Unit is used as the activation function, as the preliminary experiments and \citeauthor{doUsingMachineLearning2021} \cite{doUsingMachineLearning2021} have shown some improvement with it.
In order to avoid overfitting, the training is stopped when the validation loss does not decline for 30 epochs.

\subsection{\Ac{gru} Parameters}
As \citeauthor{silvaContinuousOutcomePrediction2018} \cite{silvaContinuousOutcomePrediction2018} achieved better results using a straight \ac{rnn},  the type of recurrent unit is optimized as a hyperparameter.
One recurrent layer is determined experimentally to be sufficient with a number of fully connected, non recurrent layers following.
The number of layers in Table \ref{tab:static_hyperparam_optim} references the number of fully connected layers.
The early stopping patience is set to 100 epochs, as the training converges much slower than the \ac{ann} training.

\subsection{Hyperparameter Optimization}
\label{ssec:hyperparam_optim}
The evaluation of model quality centered on validation accuracy, deemed a suitable metric given the balance of the dataset and the equivalent cost of false positives and negatives in predictions.
The search space, shown in Table \ref{tab:static_hyperparam_optim} is randomly searched for 2,000 and 850 trials for the \ac{ann} and \ac{gru} models respectively.
The number of trials is only limited by the computation capacity.

\begin{table}
\centering
\caption{Overview of the hyperparameter search for the pre-game classification}
\label{tab:static_hyperparam_optim}
\begin{tblr}{c|ccc}
& Hyperparameter & Pre-game Model & In-Game Model & Distribution \\
\hline
\hline
\SetCell[r=5]{} \rotatebox[origin=c]{90}{fixed} &
Normalization & 1-D BatchNorm & - \\
& Loss Function & Binary \ac{cel} & Binary \ac{cel} \\
& Optimizer & Adam & Adam\\
& Stopping Patience & 30 & 100\\
& Model & \ac{ann} & - \\ 
\hline
\SetCell[r=6]{c} \rotatebox[origin=c]{90}{optimized} &
Hidden Size & [128, 256, 512] & [64, 128, 256] & Selection \\
& Learning Rate & [$\num{1e-5}$, $\num{1e-2}$] & [$\num{1e-15}, \num{1e-5}$] & log uniform \\
& Number of Layers & [2,12] & [1, 3] & discrete \\
& Dropout Probability & [0, 0.3] & [0, 0.1, 0.2, 0.3] & Selection \\
& Model & - & [\ac{rnn}, \ac{gru}] & Selection \\
& Batch Size & [64, 128, 256] & [64, 128, 256] & Selection\\
\end{tblr}
\end{table}

\section{Results and Discussion}
\label{sec:results}

The goal of the experiments is to compare both pre- and in-game win prediction against the state-of-the-art for win prediction in \acl{lol} for amateur players.

\subsection{Results}
\label{ssec:results}


\paragraph{Feature Selection Results}

\begin{figure}[htbp]
\centering
\resizebox{\textwidth}{!}{%
	\input{./images/feature_importance.pgf}
}
\caption{\ac{gbt} Feature Importance Scores and \acp{pcc} normalized into range $[0, 1]$.}
\label{fig:fs_norm}
\end{figure}
Figure \ref{fig:fs_norm} presents the ten features with the highest correlation on the pre-game dataset, along with their respective Feature Importance Scores as determined by \ac{gbt}.
It is important to note that all $p$-values associated with these correlations are below the significance threshold of $0.01$, thereby confirming their high statistical relevance.

\Ac{gbt} achieved an accuracy of 0.69.
As depicted in Figure \ref{fig:fs_norm}, both methods have identified the same 13 features as the most important, albeit in differing orders.
For a more effective comparison between the \ac{pcc} and \ac{gbt} results, both sets of scores have been normalized to the range [0, 1].
The original values have been placed in Table \ref{tab:fs_results} for verification purposes.




\paragraph{Win Prediction Performance}
\begin{table}[H]
\centering
\caption{Win Prediction Results.}
\label{tab:win_pred_results}
\begin{tblr}{ccc}
Model & Accuracy & ROC-AUC Score \\
\hline
ANN & 0.710 & 0.787 \\
GRU & 0.741 & 0.807 \\
\end{tblr}
\end{table}
As shown in Table \ref{tab:win_pred_results}, the \ac{ann} shows a test accuracy of 0.710 and a ROC-AUC Score of 0.787.
\begin{figure}[htbp]
\centering
\input{./images/roc.pgf}
\caption{ROC Curve from both Models.}
\label{fig:roc}
\end{figure}
The \ac{gru} model achieves an accuracy of 0.741 and a ROC-AUC Score of 0.807.
Figure \ref{fig:roc} shows the ROC curves for both models and Figure \ref{fig:cm_static} shows the confusion matrices.

\begin{figure}[htbp]
\centering
\input{./images/staticcm.pgf}
\caption{Confusion matrix of pre-game and in-game classification results with error rates in percent.}
\label{fig:cm_static}
\end{figure}

\subsection{Discussion}
\label{ssec:discussion}
\paragraph{Feature Selection}
A key observation is that the highest \ac{pcc} and Feature Importance is associated with the \acs{kda} feature. 
This metric, which calculates the average \acl{kda} achieved by a player on their champion, still demonstrates a relatively low linear correlation with the target variable of only $0.287$.
Notably, the three next highest correlations are Assists, Deaths and Kills, all of which are combined to calculate the KDA.
This is different to the \ac{gbt} results, as the three features with the next highest score are Gold, League Points and Assists.
This suggests that KDA encapsulates the essential information from Kills, Deaths and Assists, leading to \ac{gbt} assigning higher importance to KDA and lower importance to these related features.

In contrast to the analysis performed by \citeauthor{costaFeatureAnalysisLeague2021} \cite{costaFeatureAnalysisLeague2021}, the win rate is not the most important factor.
However, the general trend of placing the highest importance on statistics of individual players instead of general champion statistics is similar.
As all of the most important features are related to player statistics, it can be assumed that the pre-game model generalizes fairly well over multiple game versions, thus potentially mitigating the need of frequent retraining due to game changes.

\paragraph{Win Prediction}
The accuracies of 0.710 and 0.741 achieved by the pre-game and in-game models respectively (see Table \ref{tab:win_pred_results}) indicate that incorporating real-time data significantly enhances predictive performance. 
This result is reflected in Figure \ref{fig:roc}, showing that the in-game model is better or equal to the pre-game model for all decision thresholds.
The confusion matrices in Figure \ref{fig:cm_static} show that while the in-game model has very similar rates for both false positives and false negatives, the pre-game model's errors are relatively one-sided.
A pre-game win prediction accuracy of 0.71 aligns closely with previous findings in Chapter \ref{chap:related}, suggesting that while professional games may be predicted more accurately, lower-rated games are more unpredictable and challenging.
This is consistent with \Citeauthor{whiteScalablePsychologicalMomentum2020}'s  \cite{whiteScalablePsychologicalMomentum2020} findings, who, despite a more complex methodology and larger dataset, achieved similar accuracy in the harder task of predicting lower-rated games.

The significantly higher in-game classification accuracy of 0.741 shows that real-time data is better suited for win prediction.
It also suggests that modelling this data as time series is an effective technique, as only \citeauthor{baileyStatisticalLearningEsports} \cite{baileyStatisticalLearningEsports} have achieved a higher accuracy without modelling time series data, who worked on professional games.
\Citeauthor{silvaContinuousOutcomePrediction2018} \cite{silvaContinuousOutcomePrediction2018} have employed an \ac{rnn} with an accuracy of 0.752 at the 15th minute and found that \ac{gru} performed worse. 
They hypothesized that the underperformance of \ac{gru} compared to a regular \ac{rnn} might be due to a lack of data.
With a much larger dataset, \ac{gru} did in fact perform slightly better than a vanilla \ac{rnn}, but the difference is marginal, as the best performing \ac{rnn} achieved an accuracy of 0.730.
The small difference in accuracy suggests that due to the comparatively short time series the \ac{rnn} does not have a big issue with exploding or vanishing gradients.
These results also show that a simple increase in data does not always lead to better predictions.
Here, it can be assumed that the data does not encompass all relevant information needed to make a highly accurate prediction or that a significant portion of the game's outcome might remain beyond the predictive capacity of algorithms due to the intrinsic randomness and complexity of human-led interactions.

The applicability of both models is diminished for lower-rated players, as the models were exclusively trained on very good players.
This limitation is more pronounced for the pre-game prediction model, as it could benefit all players, unlike the in-game prediction model, which is more relevant for professional game audiences.
The fact that the model only predicts the winning chances once severely limits its applicability to viewer experience enhancement.
The performance of the model when continuously predicting is not evaluated, which is a necessary step before it could be used in a broadcasted tournament.
Currently, the main beneficiaries are good players wishing to see if they should continue playing the game or if a surrender is more time-efficient.

\chapter{Conclusion}
\label{chap:conclusion}
In conclusion, the pre-game model can predict the outcome of the game with good accuracy, but the in-game model successfully uses the additional information to improve the accuracy.
The increased amount of data did not increase the predictive performance as much as expected compared to the previous works, indicating that different approaches are needed in order to achieve further improvements.

It is unlikely that a much higher accuracy is achievable using just player statistics, as this approach does not model the probability of human errors, which introduce a large amount of randomness into the game.
Further directions of work could instead include gauging the likelihood of errors by assessing the mental state of players or using a more advanced champion composition analysis.
Another potential enhancement could involve integrating pre-game data, which has shown reasonable accuracy in winner prediction, into the \ac{gru} model. 


%\bibliographystyle{natdin}
%\bibliographystyle{naturemag}
%\bibliographystyle{geralpha}
\printbibliography

\appendix
\chapter{Appendix}
\setcounter{table}{0}
\renewcommand\thetable{A\arabic{table}}
\begin{table}[!h]
\centering
\caption{\acl{gbt} Feature Importance Scores and \aclp{pcc} on the pre-game dataset, averaged per category}
\label{tab:fs_results}
\begin{tblr}{ccc}
	Category & \ac{gbt} Importance Score & \ac{pcc}\\
	\hline
	KDA & 88.5 & 0.287 \\
	Gold & 45.0 & 0.124 \\
	League Points & 37.5 & 0.030 \\
	Assists & 27.0 & 0.190 \\
	Deaths & 21.5 & 0.183 \\
	Max Kills & 19.0 & 0.021 \\
	Last Play Time & 16.0 & 0.023 \\
	Winrate & 12.5 & 0.058 \\
	Kills & 11.5 & 0.134 \\
	Championlevel & 8.5 & 0.069 \\
	Hot Streak & 8.5 & 0.066 \\
	Damage & 6.5 & 0.084 \\
	Creep Score & 3.5 & 0.058 \\
\end{tblr}
\end{table}
\setcounter{figure}{0}
\renewcommand\thefigure{A\arabic{figure}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ********************* Verzeichnisse ********************* %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\listoffigures																			% Abbildungsverzeichnis
%\listoftables																			% Tabellenverzeichnis
\cleardoublepage\phantomsection\addcontentsline{toc}{chapter}{List of Abbreviations}	% Abkürzungsverzeichnis
\printacronyms[heading={chapter*}, name={List of Abbreviations}]



\end{document}
