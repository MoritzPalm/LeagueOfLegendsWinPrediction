\documentclass[12pt, a4paper, headinclude, twoside, plainheadsepline, open=right, numbers=noenddot, hidelinks, toc=listof, toc=bibliography]{scrreprt}

%\usepackage{showframe}


% WICHTIG: Hier wird nicht BibTeX sondern BibLateX verwendet!!
% Deshalb nicht mit bibtex uebersetzen, sondern mit biber
% Das kann man in jedem Tool wie TexMaker oder TexShop als Option einstellen
%
%% Spezielle Einstellungen, insbesondere fuer das Literaturverzeichnis,
% aber auch Packages wie amsmath, Groessenanpassungen etc.
\input{Preferences.tex}
%

% Hier werden die Referenzen in einer separaten Datei gespeichert
\addbibresource{Thesis.bib}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%----------------------------------------------------------------------------------
%  Informationen
%----------------------------------------------------------------------------------
\author{Moritz Palm}
\title{Neural Network vs. GRU in League of
Legends Match Outcome Prediction: A Data-Centric Perspective}

\date{\today}


\input{abbreviations} % Abkuerzungen
 
%----------------------------------------------------------------------------------
%  Anfang des Dokuments
%----------------------------------------------------------------------------------
\begin{document}
\pagenumbering{Roman} % grosse Roemische Seitenummerierung
\pagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ********************** Titelseite *********************** %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\makeatletter
\begin{titlepage}
\selectlanguage{ngerman}
\begin{figure}[thb]
       \includegraphics[height=2.3cm]{./images/logo/FakIM_Logo} 
\end{figure}
\begin{center}
\rule{0pt}{0pt}
\vfill
\vfill
\vfill
\vfill

\begin{huge}
\@title\\[0.75ex]
\end{huge}

\vfill
\vfill


Bachelorarbeit\\ von\\

\vspace*{.5cm}
\textbf{\@author}\\
Matrikelnummer: 3281253
\vspace{.5cm}

\vfill
\vfill
\textbf{\large Fakultät Informatik und Mathematik\\
Ostbayerische Technische Hochschule Regensburg\\
(OTH Regensburg)}
\vfill
\vfill

\begin{tabular}{rl}
Gutachter:   		& Prof. Dr. Brijnesh Jain\\
Zweitgutachter:   	& Prof. Dr. Timo Baumann\\
%Betreuer:   		& Dr. Max Mustermann\\
\\Abgabedatum:& \@date
\end{tabular}
\end{center}
\end{titlepage}

\selectlanguage{ngerman}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ****************** Erklärung zur Arbeit ***************** %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\text{~}
\vspace{11cm}

\noindent
Herr\\
\@author\\
Konrad-Adenauer-Allee 55\\
93051 Regensburg\\
\smallskip

\noindent
Studiengang: Künstliche Intelligenz \& Data Science
\bigskip

\begin{enumerate}
\item Mir ist bekannt, dass dieses Exemplar der Bachelorarbeit als Prüfungsleistung in das Eigentum des Freistaates Bayern übergeht.
\item Ich erkläre hiermit, dass ich diese Bachelorarbeit selbstständig verfasst, noch nicht anderweitig für Prüfungszwecke vorgelegt, keine anderen als die angegebenen Quellen und Hilfsmittel benutzt sowie wörtlich und sinngemäße Zitate als solche gekennzeichnet habe.
\end{enumerate}
\vspace{1cm}
Regensburg, den \@date\\
\medskip
\medskip

\noindent
\underline{~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~}\\
\@author

\makeatother



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ******************* Inhaltsverzeichnis ****************** %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\cleardoublepage
\pdfbookmark{\contentsname}{toc}\tableofcontents 										% Inhaltsverzeichnis




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ******************* Beginn des Textes ******************* %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagestyle{scrheadings} 																% normale Kopf- und Fusszeilen fuer den Rest
\cleardoublepage
\pagenumbering{arabic} 																	% ab jetzt arabische Nummerierung

\selectlanguage{english}
\chapter{Introduction}
\label{chap:intro}


\ac{lol}, developed by Riot Games, is a prominent \ac{moba} game, a sub genre of real-time strategy games characterized by two teams of five players, known as 'summoners', competing against each other \cite{mora-cantallopsMOBAGamesLiterature2018}. 
Each player controls a unique character, or 'champion', and the objective is to defeat the opposing team. 
\Ac{lol} stands out in the \ac{moba} genre for its global popularity, attracting millions of players and a significant viewership in professional esports tournaments \cite{goughLeagueLegendsChampionships}.
While sharing core gameplay elements and map layouts with other \ac{moba} games, \ac{lol} distinguishes itself through its diverse range of champions, abilities, and graphical styles. 
This thesis will therefore focus on League of Legends, given its influential status in the \ac{moba} genre. 


esports is highly relevant due to it being a huge and strongly growing market.
In 2019, the esports industry's market size was valued at approximately 25B USD \cite{ahnOneBillionDollar2020}.
Esports and mobas in particular are hard to understand and follow. A live game prediction view can help fans understand the action and decisions made better and help immerse the audience by detecting upsets and swings in win probability.
many games are hard to understand, due to lots of information being displayed with very little explanation
a win prediction graph can help viewers understand the action and the significance of certain plays better, thus increasing engagement and enjoyment.
riot games has already implemented their own proprietary win prediction
a win prediction model can also help players make more informed decisions about what the optimal path of actions is

the model should be able to answer the question, if team a is far enough ahead to win or if team b with their hyper scaling heroes can come back and win

It can be divided into three distinct categories: pre-game win prediction can support players in choosing the champion that increases their chance of winning the most, in-game win prediction can guide players focus on their way to victory and help viewers to better understand the action. 
Post-game analysis does not benefit a specific game, but helps players, particularly professional players examine their strengths and weaknesses.
\chapter{Related work}
\label{chap:related}

The application of machine learning techniques in interpreting data from e-sports games represents a dynamic field of research. 
Among the various games studied, DotA 2 and League of Legends have garnered the most attention.
\section{Win Prediction in League of Legends}
A critical factor in win prediction is the timing of data collection, as outlined in Table \ref{tab:related_work_lol}.
It can be categorized into three distinct phases: pre-game, in-game, and post-game, each offering unique insights and benefits.

\paragraph{Pre-Game Win Prediction}
A variety of different methods were used to predict the winner prior to the game's commencement.
A notable study by \citeauthor{whiteScalablePsychologicalMomentum2020} \cite{whiteScalablePsychologicalMomentum2020} incorporated a broad spectrum of pre-game features, including the concept of psychological momentum, and attained an accuracy of 0.721 using logistic regression.
In comparison, \citeauthor{doUsingMachineLearning2021} \cite{doUsingMachineLearning2021} 
limited their feature set to player-champion win rates and champion mastery points, further extracting statistical features such as the team's average player-champion win rate
Applying an \ac{ann} to this data yielded a notable accuracy of 0.751, which is significant given the relatively small dataset used, especially considering the results of the paper on feature selection by 
A dedicated feature selection study by \citeauthor{costaFeatureAnalysisLeague2021} \cite{costaFeatureAnalysisLeague2021}.
They identified not only player-champion win rate but also the kill-to-death ratio for the chosen champion as the most critical features.

\paragraph{In-Game Win Prediction}
\Citeauthor{silvaContinuousOutcomePrediction2018} \cite{silvaContinuousOutcomePrediction2018} trained a \acf{rnn} on 7621 professional games  utilizing data from varying intervals, ranging from the initial 0-5 minutes to 20-25 minutes.
Their findings revealed an accuracy of 75.23\% when using data from between the 10 and 15 minute mark and a maximum accuracy of 83.54\% when using data from the 20-25th minute.
Additionally, their research comparing \ac{lstm} networks against \acp{rnn} indicated superior performance of the latter, possibly attributable to the less complex nature of the problem or limited data availability.
\citeauthor{baileyStatisticalLearningEsports} \cite{baileyStatisticalLearningEsports} have achieved an accuracy of 0.77 by applying logistic regression to 671 professional matches.

\paragraph{Post-Game Win Prediction}
\citeauthor{bahrololloomiESportsPlayerPerformance2023} \cite{bahrololloomiESportsPlayerPerformance2023} have built a predictor using post-game data from professional matches achieving 86\% accuracy, while \citeauthor{aniVictoryPredictionLeague2019} \cite{aniVictoryPredictionLeague2019} trained a Random Forest model on a mixture of pre-, in- and post-game data for a maximum accuracy of 0.998.

\begin{longtblr}[
caption = {Comparison of different works on League of Legends win prediction},
label = {tab:related_work_lol},
note{a} = {This work did not build a predictor, thus no accuracy was obtained.},
note{b} = {The exact number of features is unclear.},
note{c} = {The exact timestamp where the last in-game data was obtained is unclear.},
note{d} = {The skill group(s) from which the games stem is unclear.}
]
{
colspec = {*{6}{c}},
rowhead = 1,
}

Author & Games & Features & Time & Skill Group & Accuracy \\
\hline
\citeauthor{doUsingMachineLearning2021} \cite{doUsingMachineLearning2021} & 5,000 & 44 & pre-game & \TblrNote{d} & 0.751 \\
\citeauthor{costaFeatureAnalysisLeague2021} \cite{costaFeatureAnalysisLeague2021} & 2,840 & 50 & pre-game & professional & \TblrNote{a} \\
\citeauthor{whiteScalablePsychologicalMomentum2020} \cite{whiteScalablePsychologicalMomentum2020}&87,743&\TblrNote{b}&pre-game &equidistributed&0.721\\
\citeauthor{hitar-garciaMachineLearningMethods2023} \cite{hitar-garciaMachineLearningMethods2023} & 7583 & 26 & pre-game & professional & 0.683 \\
\citeauthor{linLeagueLegendsMatch} \cite{linLeagueLegendsMatch} & 588 & 2231 & pre-game & Gold & 0.567 \\

\citeauthor{kimConfidenceCalibratedMOBAGame2020} \cite{kimConfidenceCalibratedMOBAGame2020} & 93875 & 295 & in-game\TblrNote{c} & \TblrNote{d} & 0.738 \\
\citeauthor{shenMachineLearningApproach2022} \cite{shenMachineLearningApproach2022} & 10,000 & 5 & 10 min & \TblrNote{d} & 0.726 & \\
\citeauthor{zhangPredictionEsportsGame2021} \cite{zhangPredictionEsportsGame2021} & 10,000 & 38 & 10 min & high-skilled & 0.723 \\
\citeauthor{baileyStatisticalLearningEsports} \cite{baileyStatisticalLearningEsports} & 671 & 28 & 15 min & professional & 0.76 \\
\citeauthor{silvaContinuousOutcomePrediction2018} \cite{silvaContinuousOutcomePrediction2018} & 7,621 & 52 & 25 min & professional & 0.835 \\

\citeauthor{mondalDoesSupportRole2022} \cite{mondalDoesSupportRole2022} & 296 & 5 & post game & \TblrNote{d} & \TblrNote{a} \\
\citeauthor{bahrololloomiESportsPlayerPerformance2023} \cite{bahrololloomiESportsPlayerPerformance2023} & 2,901 & 15 & post-game & \TblrNote{d} &0.86 \\
\citeauthor{aniVictoryPredictionLeague2019} \cite{aniVictoryPredictionLeague2019} & 1,500 & 97 & post-game & professional & 0.955 \\
\citeauthor{linLeagueLegendsMatch} \cite{linLeagueLegendsMatch} & 3000 &  \TblrNote{b} & post-game & Gold & 0.936 \\
\hline
\end{longtblr}


\section{Win Prediction in DotA 2}
\label{sec:dota}
is this advisable? no real new insights in my opinion
maybe win prediction in sports?
%A lot of scientific research focuses on the similar \ac{moba} DotA 2, which has easier and more fine-grained data collection methods (see section \ref{sec:datacoll}).
%Due to the high similarity between these two games, it is to be expected that any findings for one game can be replicated and used for the other game with minimal adaptations.
%Nevertheless, to ensure a fair comparison, both games are presented separately below.
%


%
%
%In DotA 2, a wide variety of algorithms have been used.  
%\Citeauthor{yuMOBASliceTimeSlice2018} \cite{yuMOBASliceTimeSlice2018} trained a \ac{rnn} on 71,355 matches and achieved an accuracy of $0.7083$ at the half-way point of a match, which according to their analysis is on average at 20 minutes.
%\Citeauthor{wangPredictingMultiplayerOnline2016} \cite{wangPredictingMultiplayerOnline2016} compared Logistic Regression with a \ac{fnn} trained on up to 911,468 matches, with \ac{lr} achieving a slightly better accuracy ($0.6104$) than the \ac{fnn} ($0.588$).
%

\section{Win prediction in other sports}
\label{sec:other_sports}
and/or this?

\chapter{Background}
\label{chap:background}

\section{League of Legends}
\label{sec:LoL}

\Ac{lol} is played with 5 players on each team on a map which is bifurcated into two bases, each linked by three lanes and housing a crucial structure called the 'nexus', which is protected by turrets. 
The game's primary goal is to destroy the opposing team's nexus.
The map includes a jungle area in between the lanes with neutral monsters and two significant creatures, Baron Nashor and the Dragon, offering team-wide benefits when defeated.
Players must accumulate gold and \ac{xp} through defeating minions, neutral monsters, or enemy champions. 
These in-game currencies are essential for purchasing items and levelling up, thereby augmenting a champion's capabilities.

Player roles in \ac{lol} are typically assigned with one player in the top lane, one in the mid lane, two in the bottom lane, and one in the jungle, facilitating strategic diversity and role specialization.
Players select from a roster of 165 champions, each with unique abilities and characteristics, to compete in matches.
Champion selection is a pivotal element of \ac{lol} gameplay, requiring players to consider team composition, damage types, assigned roles, and personal proficiency with specific champions. 
The theoretical number of possible champion combinations in a game is $\binom{165}{10} = \num{3.21e15}$.
Although this number is quite a bit smaller in reality as not every champion can play every role and most players are only proficient with 15-20 champions \cite{2022Recap}, this underscores the game's strategic depth.

Each year, \ac{lol} introduces a new 'season', bringing substantial changes, and Riot Games issues bi-weekly patches to adjust champion balance, influencing the prevailing game strategies, or 'meta'.
These patches can also include the release of a new champion or the rework of an old one.
Frequent changes force players to be able to quickly adapt and learn new champions and mechanics.

To evaluate player skill, \ac{lol} utilizes a proprietary rating system, probably a modified Elo system \cite{janssonNeuralNetworksStandardizing2022}.
This system ensures that players are matched with and against others of comparable skill levels, maintaining competitive balance and fairness in the game.


\section{Neural Networks}
\label{sec:nn}

\Acp{ann} are computational models that emulate the processing patterns of the human brain. The fundamental computational unit of an ANN is the neuron, a concept first proposed by \citeauthor{mccullochLogicalCalculusIdeas1943} \cite{mccullochLogicalCalculusIdeas1943}.
A neuron computes an output activation $a$ from a set of input values $\mathbf{x} = (x_1, x_2, \ldots, x_m)$, where $m$ denotes the number of inputs. 
The neuron's weighted input $z$ is calculated as the dot product of the input vector $\mathbf{x}$ and the weight vector $\mathbf{w} = (w_1, w_2, \ldots, w_m)$, plus a bias term $b$:
\begin{equation}
z = \sum_{i=1}^{m} w_i x_i + b = \mathbf{w}^\top \mathbf{x} + b.
\end{equation}
The weighted sum $z$ is then passed through an activation function $\phi$, such as a sigmoid or \ac{relu}, to introduce non-linearity:
\begin{equation}
a = \phi(z) = \phi(\mathbf{w}^\top \mathbf{x} + b).
\end{equation}

The \ac{mlp}, introduced by \citeauthor{rosenblattPerceptronProbabilisticModel1958} \cite{rosenblattPerceptronProbabilisticModel1958}, organizes neurons into layers. 
Data flows from the input layer, through one or more hidden layers, to the output layer. In a fully connected feed-forward network, the computation in each layer $l$ is:
\begin{equation}
\mathbf{z}^{(l)} = \mathbf{W}^{(l)} \mathbf{a}^{(l-1)} + \mathbf{b}^{(l)},
\end{equation}
where $\mathbf{a}^{(l)}$ represents the activation of layer $l$, $\mathbf{W}^{(l)}$ is the weight matrix, and $\mathbf{b}^{(l)}$ the bias vector. 
The vector $\mathbf{z}^{(l)}$ is then passed through the activation function for layer $l$, which is applied elementwise:
\begin{equation}
\mathbf{a}^{(l)} = \phi (\mathbf{z}^{(l)}).
\end{equation}
The output layer $L$ produces the network's prediction $\mathbf{\hat{y}}$.
The choice of activation function is dependent on the task, a common choice for classification is the softmax function \cite{bridleProbabilisticInterpretationFeedforward1990}
\begin{equation}
\label{eq:softmax}
 S(\mathbf{x}_i) = \frac{e^{x_i}}{\sum_{k=1}^{K} e^{x_k}}
\end{equation}
where $K$ is the number of classes and $i = 1, ..., K$.
The softmax function returns a probability distribution over the predicted output classes.

To approximate any measurable function, an \ac{ann} requires at least one hidden layer \cite{hornikMultilayerFeedforwardNetworks1989}. 
The network's weights and biases are adjusted during training to minimize a loss function $E$.
Common loss functions include \ac{mse} for regression tasks:
\begin{equation}
E_N = \frac{1}{N} \sum_{k=1}^{N}(y_{k} - \hat{y}_{k})^2,
\end{equation}
and \ac{cel} for multi-class classification tasks:
\begin{equation}
E_N = -\frac{1}{N} \sum_{n=1}^{N} \sum_{k=1}^{K} y_{nk} \log (\hat{y}_{nk})
\end{equation}
where $N$ is the number of samples, $y_{nk}$ is the (one-hot encoded) ground truth and $\hat{y}_{nk}$ is the softmax output.

Backpropagation \cite{rumelhartLearningRepresentationsBackpropagating1986} is a key algorithm for training \acp{ann}, involving a forward pass to compute activations and a backward pass to compute gradients. 
The gradients of the loss function with respect to the weights and biases are computed using the chain rule of calculus. For a given layer $l$, the gradient of the loss $E$ with respect to the weights $\mathbf{W}^{(l)}$is
\begin{equation}
\Delta
\frac{\partial E}{\partial \mathbf{W}^{(l)}} = \frac{\partial E}{\partial \mathbf{a}^{(l)}} \cdot \frac{\partial \mathbf{a}^{(l)}}{\partial \mathbf{z}^{(l)}} \cdot \frac{\partial \mathbf{z}^{(l)}}{\partial \mathbf{W}^{(l)}},
\end{equation}
and with respect to the bias $\mathbf{b}^{(l)}$
\begin{equation}
\frac{\partial E}{\partial \mathbf{b}^{(l)}} = \frac{\partial E}{\partial \mathbf{z}^{(l)}} \cdot \frac{\partial \mathbf{z}^{(l)}}{\partial \mathbf{b}^{(l)}} = \frac{\partial E}{\partial \mathbf{z}^{(l)}}
\end{equation}
as 
\begin{equation}
\frac{\partial \mathbf{z}^{(l)}}{\partial \mathbf{b}^{(l)}} = 1
\end{equation}
where $\mathbf{z}^{(l)} = \mathbf{W}^{(l)} \mathbf{a}^{(l-1)} + \mathbf{b}^{(l)}$and $\mathbf{a}^{(l)} = \phi(\mathbf{z}^{(l)})$.
The gradients are then used to update the weights and biases, typically using an optimization algorithm like gradient descent.
The weights are updated via:
\begin{equation}
\mathbf{W}^{(l)} = \mathbf{W}^{(l)} - \eta \frac{\partial E}{\partial \mathbf{W}^{(l)}}
\end{equation}
where $\eta$ is the learning rate.

Through iterative forward and backward propagation, the network gradually converges to a state where the loss is minimized, indicating successful learning of the patterns in the data.

\section{Recurrent Neural Networks}
\label{sec:rnn}

Recurrent Neural Networks (RNNs) extend the capabilities of feed-forward neural networks to handle sequential data by introducing the concept of recurrence. In an RNN, the output at each time step is influenced not only by the current input but also by the network's previous internal state, known as the hidden state. This design enables RNNs to capture temporal dependencies, making them particularly effective for tasks involving sequential data, such as speech recognition and natural language processing \cite{lecunDeepLearning2015}.
%\begin{figure}[h]
%\centering
%\begin{tikzpicture}
%[
%%Styles
%cell/.style={% For the main box
%        rectangle, 
%        rounded corners=5mm, 
%        draw,
%        very thick,
%        },
%state/.style={ %for internal States
%		rectangle,
%		rounded corners=3mm,
%		draw,
%		dashed,
%		minimum size=10mm,
%		},
%arrow/.style={ %for arrows
%		->,
%		thick,
%		-{Stealth[length=3mm]},
%		line width=0.5mm,
%		},
%]
%
%%Cell
%\node [cell, minimum height =4cm, minimum width=6cm] at (0,0){} ;
%
%%States
%
%\node[] (ht1) at (-4.5,0) {$h_{t-1}$};
%\node[state] (ht) [right=2.5cm of ht1]	{$h_t$};
%\node[state] 	(Zt) [right=1cm of ht] {$Z_t$};
%\node[] 	(xt) [below=2.5cm of ht] {$x_t$};
%\node[] (Zt2) [above=2.5cm of Zt] {$\hat{y}_t$};
%
%%Arrows
%\draw[arrow] (xt.north) to (ht.south);
%\draw[arrow] (ht1.east) to (ht.west);
%\draw[arrow] (ht.east) to (Zt.west);
%\draw[arrow] (Zt.north) to (Zt2.south);
%
%%Other
%%\node[]  [right=3cm of Zt] {}; % this is just to add some space on the right side to center the caption on the cell
%
%\end{tikzpicture}
%\caption{Elman Recurrent Unit \cite{hewamalageRecurrentNeuralNetworks2021}}
%\label{fig:elman}
%\end{figure}
The concept of a fully connected RNN was first proposed by \citeauthor{elmanFindingStructureTime1990} \cite{elmanFindingStructureTime1990}.

RNNs maintain a 'state vector' in their hidden units, which implicitly contains information extracted from all past elements of the sequence \cite{lecunDeepLearning2015}.
The hidden state $\mathbf{h}_t$ at time step $t$ is updated as follows:
\begin{equation}
\label{eq:rnn_update} 
\mathbf{h}_t =
\begin{cases}
	0, & \text{if } t = 0, \\
	\sigma_h (\mathbf{W} \mathbf{x}_t + \mathbf{U} \mathbf{h}_{t-1} + \mathbf{b}_h)
	& \text{otherwise},
\end{cases}
\end{equation}
where $\mathbf{U}$ is the weight matrix for the hidden state and $\mathbf{W}$ is the weight matrix for the input.
A common choice for $\sigma_h$ is the tanh function.
In a single-layer \ac{rnn}, all weight matrices $\mathbf{W}$, $\mathbf{U}$ and $\mathbf{V}$ (and biases) are shared across timesteps.
The output $\mathbf{\hat{y}}_t$ of an \ac{rnn} at time step $t$ can be calculated as:
\begin{equation}
\label{eq:rnn_output}
\begin{split}
\mathbf{o}_t &= \mathbf{V} \cdot \mathbf{h}_t + \mathbf{b_h} \\
\mathbf{\hat{y}}_t &= \text{softmax}(\mathbf{o}_t)
\end{split}
\end{equation}
where $\mathbf{V}$ is the weight matrix associated with the cell output. 

The loss over $T$ timesteps is defined by 
\begin{equation}
E_T = \frac{1}{T} \sum_{t=1}^{T} {l(\mathbf{\hat{y}}_t, \mathbf{y})}
\end{equation} 
%TODO: consider changing l to e
where $l(\mathbf{\hat{y}}_t, \mathbf{y})$ is the loss at timestep $t$.

\Ac{bptt} unfolds the \ac{rnn} across time steps (see Figure \ref{fig:rnn_unroll}) and applies the backpropagation algorithm. 
In order to train $U$, $V$ and $W$, we need their respective gradients $\frac{\delta E}{\delta \mathbf{U}}$, $\frac{\delta E}{\delta \mathbf{V}}$ and $\frac{\delta E}{\delta \mathbf{W}}$.

As the weight matrices are shared across timesteps, we can generally sum the gradients from each timestep $t$ together.
The gradient of the loss function with regards to the output matrix $V$ does not depend on the hidden state $h_t$ and can thus be calculated easily.
\begin{equation}
\label{eq:bptt_V}
\begin{split}
\frac{\partial E}{\partial \mathbf{V}} 
& = 
\sum_{t}^{T} \frac{\partial E_t}{\partial \mathbf{V}} \\
& =
\sum_{t}^{T} 
\frac{\partial E_t}{\partial \mathbf{\hat{y}}_t} 
\cdot 
\frac{\partial \mathbf{\hat{y}}_t}{\partial \mathbf{o}_t} 
\cdot 
\frac{\partial \mathbf{o}_t}{\partial \mathbf{V}}
\end{split}
\end{equation}
Now we consider the gradient with respect to the weight matrix for the hidden state $U$ at the time step $t+1$:
\begin{equation}
\frac{\partial E_{t+1}}{\partial \mathbf{U}} = 
\frac{\partial E_{t+1}}{\partial \mathbf{\hat{y}}_{t+1}}
\frac{\partial \mathbf{\hat{y}}_{t+1}}{\partial \mathbf{h}_{t+1}}
\frac{\partial \mathbf{h}_{t+1}}{\partial \mathbf{U}}
\end{equation}
As the hidden state $h_{t+1}$ depends on the hidden state of the previous timestep $h_t$, we need to recursively calculate the partial derivatives of all the previous timesteps, yielding the following formula:
\begin{equation}
\frac{\partial E_{t+1}}{\partial \mathbf{U}} = \sum_{k=1}^{t+1}
\frac{\partial E_{t+1}}{\partial \mathbf{\hat{y}}_{t+1}}
\frac{\partial \mathbf{\hat{y}}_{t+1}}{\partial \mathbf{h}_{t+1}}
\frac{\partial \mathbf{h}_{t+1}}{\partial \mathbf{h}_k}
\frac{\partial \mathbf{h}_k}{\partial \mathbf{U}}
\end{equation}
Applying the chain rule to $\frac{\partial \mathbf{h}_{t+1}}{\partial \mathbf{h}_k}$ yields
\begin{equation}
\frac{\partial E_{t+1}}{\partial \mathbf{U}} = \sum_{k=1}^{t+1}
\frac{\partial E_{t+1}}{\partial \mathbf{\hat{y}}_{t+1}}
\frac{\partial \mathbf{\hat{y}}_{t+1}}{\partial \mathbf{h}_{t+1}}
\left(\prod_{j=k}^{t}\frac{\partial \mathbf{h}_{j+1}}{\partial \mathbf{h}_j}\right)
\frac{\partial \mathbf{h}_k}{\partial \mathbf{U}}
\end{equation}\cite{aratBackpropagationTimeRecurrent2019}.
Summing the partial derivatives over timesteps similar to equation (\ref{eq:bptt_V}) yields the full equation
\begin{equation}
\label{eq:bptt_U}
\frac{\partial E}{\partial \mathbf{U}} = 
\sum_{t=1}^{T}
\sum_{k=1}^{t}
\frac{\partial E_{t+1}}{\partial \mathbf{\hat{y}}_{t+1}}
\frac{\partial \mathbf{\hat{y}}_{t+1}}{\partial \mathbf{h}_{t+1}}
\frac{\partial \mathbf{h}_{t+1}}{\partial \mathbf{h}_k}
\frac{\partial \mathbf{h}_k}{\partial \mathbf{U}}
\end{equation}
where
\begin{equation}
\label{eq:bptt_ht+1}
\frac{\partial \mathbf{h}_{t+1}}{\partial \mathbf{h}_k} 
= 
\left(\prod_{j=k}^{t}\frac{\partial \mathbf{h}_{j+1}}{\partial \mathbf{h}_j}\right)
=
\frac{\partial \mathbf{h}_{t+1}}{\partial \mathbf{h}_t}
\frac{\partial \mathbf{h}_{t}}{\partial \mathbf{h}_{t-1}}
 . . . 
\frac{\partial \mathbf{h}_{k+1}}{\partial \mathbf{h}_k}   
\end{equation}
The gradient with respect to $\mathbf{W}$ follows similarly.
As first demonstrated by \citeauthor{bengioLearningLongtermDependencies1994} \cite{bengioLearningLongtermDependencies1994}, RNNs face challenges with exploding or vanishing gradients, particularly in long sequences.
This can be shown by examining a single term from equation (\ref{eq:bptt_ht+1}) as this is the partial derivative between two vectors and as such a Jacobian matrix :
\begin{equation}
\label{eq:bptt_jacobian}
\frac{\partial \mathbf{h}_{j+1}}{\partial \mathbf{h}_j}
= 
\mathbf{U}^{\top} \text{diag}(\sigma_{h}' (\mathbf{W} \mathbf{x}_{j+1} + \mathbf{U} \mathbf{h}_j + \mathbf{b}_h))
\end{equation}
where diag() converts a vector into a diagonal matrix and $\sigma '$ computes the element-wise derivative of $\sigma$
\cite{pascanuDifficultyTrainingRecurrent2013}.
The eigendecomposition of $\frac{\partial \mathbf{h}_{j+1}}{\partial \mathbf{h}_j}$ yields the eigenvalues $ \lambda_1, \lambda_2, ..., \lambda_n$ where $|\lambda_1| > |\lambda_2| > ... > |\lambda_n|$ with their corresponding eigenvectors $v_1, v_2, ..., v_n$.
The change in hidden state $\Delta h_{j+1}$ in direction of a vector $v_i$ is multiplied with the eigenvalue of this eigenvector: $\lambda_i \Delta h_{j+1}$.
As these factors are multiplied across timesteps, the change is scaled by a factor equivalent to $\lambda_i^t$ which scales exponentially with the timestep $t$.
If $\lambda_1 < 1$ the gradient will vanish while if $\lambda_1 > 1$ the gradient will explode when considering $t \to \infty$ \cite{pascanuDifficultyTrainingRecurrent2013}.
This issue hinders their ability to learn long-range dependencies \cite{sutskeverTrainingRecurrentNeural2013}. 

\begin{figure}
\centering
\begin{tikzpicture}[
item/.style={circle,draw,thick,align=center, minimum size=1.2cm},
hidden/.style={item,on chain,join}]

 \begin{scope}[start chain=going right,nodes=hidden,every
 join/.style={-latex,very thick},local bounding box=chain]
 \draw node (A0) {$h_0$} node (A1) {$h_1$} node (A2) {$h_2$} node[xshift=2em] (At)
 {$h_t$};
 \end{scope}
 \node[left=1em of chain,scale=2] (eq) {$=$};
 \node[left=2em of eq,item] (AL) {$h$};
 \path (AL.west) ++ (-1em,2em) coordinate (aux);
 \draw[very thick,-latex,rounded corners] (AL.east) -| ++ (1em,2em) -- (aux) --++(0em,-2em) node[midway, left] {$U$} -- (AL.west); 
 \foreach \X in {0,1,2,t}
 {\draw[very thick,-latex] (A\X.north) -- ++ (0,2em) node[midway, right] {$V$}
 node[above,item,fill=gray!10] (h\X) {$\hat{y}_\X$};
 \draw[very thick,latex-] (A\X.south) -- ++ (0,-2em) node[midway, right] {$W$}
 node[below,item,fill=gray!10] (x\X) {$x_\X$};
 \path (A0.east) -- (A1.west) node[midway, above] {$U$};
 \path (A1.east) -- (A2.west) node[midway, above] {$U$};
 \path (A2.east) -- (At.west) node[midway, above] {$U$};
}
 
 \draw[white,line width=0.8ex] (AL.north) -- ++ (0,1.9em);
 \draw[very thick,-latex] (AL.north) -- ++ (0,2em) node[midway, right] {$V$}
 node[above,item,fill=gray!10] {$\hat{y}_t$};
 \draw[very thick,latex-] (AL.south) -- ++ (0,-2em) node[midway, right] {$W$}
 node[below,item,fill=gray!10] {$x_t$};
 \path (x2) -- (xt) node[midway,scale=2,font=\bfseries] {\dots};
\end{tikzpicture}
\caption{Unrolling of an \ac{rnn} over time}
\label{fig:rnn_unroll}
\end{figure}

\section{Gated Recurrent Unit}
\label{sec:gru}
In order to overcome the exploding/vanishing gradient problem of vanilla \acp{rnn}, gated networks like the \ac{lstm} \cite{hochreiterLongShortTermMemory1997} and \ac{gru} \cite{choLearningPhraseRepresentations2014} have been developed \cite{vanhoudtReviewLongShortterm2020}.
As they introduce an increased number of parameters compared to traditional \acp{rnn}, gated networks like the \ac{lstm} and \ac{gru} demand greater computational power \cite{deyGatevariantsGatedRecurrent2017}.
Compared to the \ac{lstm} network, \ac{gru} reduces the number of gate networks to two, thus being simpler to implement and compute \cite{choLearningPhraseRepresentations2014}, see Figure \ref{fig:gru}.
\Citeauthor{chungEmpiricalEvaluationGated2014} even found that \ac{gru} is at least comparable to \ac{lstm} most of the time \cite{chungEmpiricalEvaluationGated2014}.
The gates control the activation of each hidden unit.
The reset gate $\mathbf{r}_t$ is calculated by
\begin{equation}
\label{eq:gru_reset}
\mathbf{r}_t = \sigma (\mathbf{W}_r x_t + \mathbf{U}_r h_{t-1} + \mathbf{b}_r)
\end{equation}
and the update gate $\mathbf{z}_t$ by
\begin{equation}
\label{eq:gru_update}
\mathbf{z}_t = \sigma (\mathbf{W}_z \mathbf{x}_t + \mathbf{U}_z \mathbf{h}_{t-1} + \mathbf{b}_z)
\end{equation}
\cite{deyGatevariantsGatedRecurrent2017}.
The hidden state update is a linear interpolation between the previous activation $\mathbf{h}_{t-1}$ and the candidate activation $\mathbf{\tilde{h}}_t$, where the update gate $\mathbf{z}_t$ influences how much the hidden state is changed \cite{chungEmpiricalEvaluationGated2014}:
\begin{equation}
\label{eq:gru_h}
\mathbf{h}_t = (1-\mathbf{z}_t) \odot \mathbf{h}_{t-1} + \mathbf{z}_t \odot \mathbf{\tilde{h}}_t
\end{equation}
with
\begin{equation}
\label{eq_gru_h_tilde}
\mathbf{\tilde{h}}_t = \tanh(\mathbf{W}_h \mathbf{x}_t + \mathbf{U}_h (\mathbf{r}_t \odot \mathbf{h}_{t-1} + \mathbf{b}_h).
\end{equation}
In equations (\ref{eq:gru_h}) and (\ref{eq_gru_h_tilde}) $\odot$ denotes the element-wise (Hadamard) multiplication.

\begin{figure}
\centering
\begin{tikzpicture}[
    % Styles
    cell/.style={% For the main box
        rectangle, 
        rounded corners=5mm, 
        draw,
        very thick,
        },
    operator/.style={%For operators like +  and  x
        circle,
        draw,
        inner sep=0.5pt,
        minimum height =.2cm,
        },
    function/.style={%For functions
        ellipse,
        draw,
        inner sep=3pt
        },
    ct/.style={% For external inputs and outputs
        circle,
        draw,
        line width = .75pt,
        minimum width=1cm,
        inner sep=1pt,
        },
    gt/.style={% For internal inputs
        rectangle,
        draw,
        minimum width=4mm,
        minimum height=3mm,
        inner sep=3pt
        },
    ArrowC1/.style={% Arrows with rounded corners
        rounded corners=.25cm,
        thick,
        },
    ArrowC2/.style={% Arrows with big rounded corners
        rounded corners=.5cm,
        thick,
        },
    ]
    
   %Start drawing the thing...    
    % Draw the cell: 
    \node [cell, minimum height =4cm, minimum width=6cm] at (0,0){} ;
    
    
	%Draw operators	
	%top row
	\node [operator] (mux1) at (0,1.5) {$\times$};
    \node [operator] (add1) at (2,1.5) {$+$};
    %second row
    \node [operator] (mux2) at (-2, 0.5) {$\times$};
    \node [operator] (mux3) at (2,  0.5) {$\times$};
    \node [operator, inner sep=0pt] (minus) at (1, 0.5) {
    \begin{scriptsize}
    $1-$
    \end{scriptsize}
    };
    %bottom row
    \node [gt] (sigma1) at (-1.5, -0.5) {$\sigma$};
    \node [gt] (sigma2) at (0, -0.5) {$\sigma$};
    \node [gt] (tanh) at (2, -0.5) {$\tanh$};
    
    %draw node to show location of gates
    \node[] (zt) at (1, -0.5) {$\mathbf{z}_t$};
    \node[]  (rt) at (-1, 0) {$\mathbf{r}_t$};
    
  % Draw External inputs
    \node[] (ht-1) at (-4,1.5) {$\mathbf{h}_{t-1}$};
    \node[outer sep=1] (xt) at (-2.5,-3) {$\mathbf{x}_t$};

    % Draw External outputs
    \node[] (out) at (4,1.5) {};
    \node[] (ht) at (2.5,3) {$\mathbf{h}_t$};
    
   % Draw Arrows
   % input
	\draw [ArrowC2] (ht-1) -- (mux1) ;
	\draw [->, ArrowC1] (ht-1) -| (mux2);
	\draw[->, ArrowC1] (ht-1) -| (-2.5, -1) -| (sigma1);
	\draw[->, ArrowC1] (xt.north) -| (-2.5, -1) -| (sigma1);
	\draw[->, ArrowC1] (xt.north) |- (-1.5, -1.5) -|(tanh);
	\draw[->, ArrowC1] (xt.north) -| (-2.5, -1) -| (sigma2);
   
	% Internal   
	\draw[->, ArrowC1] (mux1) -- (add1) -- (out);
	\draw[ArrowC1] (mux2) |- (-1,-1.5); 
	\draw[->, ArrowC1] (sigma1) |- (mux2);
	\draw[->, ArrowC1] (sigma2) -- (mux1);
	\draw[->, ArrowC1] (sigma2) |- (minus);
	\draw[->, ArrowC1] (minus) -- (mux3);
	\draw[->, ArrowC1] (tanh) -- (mux3);
	\draw[->, ArrowC1] (mux3) -- (add1);
   
   %Output
   \draw[->, ArrowC1] (add1) -| (ht);
    
\end{tikzpicture}
\caption{Gated Recurrent Unit}
\label{fig:gru}
\end{figure}


\section{Feature Selection}
\label{sec:fs_algos}

Feature Selection is pivotal in machine learning, particularly when dealing with high-dimensional data. It serves the primary objectives of improving model performance by mitigating the 'curse of dimensionality,' enhancing predictive accuracy, and reducing overfitting. By eliminating irrelevant or redundant features, the model's generalization capacity is enhanced, contributing to model interpretability and potentially reducing training times.
Feature selection methods can be broadly categorized into three distinct types \cite{jovicReviewFeatureSelection2015}:
\begin{description}

\item[Filter Methods] These methods rely on model-invariant information, such as feature-class label correlation. They are computationally efficient and typically do not require user input in form of hyperparameters, but may not capture complex relationships within the data.

\item[Wrapper Methods] Wrapper methods train models iteratively on various feature subsets, incurring a higher computational cost but enabling the detection of interactions among variables.

\item[Embedded Methods] These methods perform inherent feature selection, often as an integral part of the modeling process. Tree-based models, such as Decision Trees and Gradient Boosted Trees, typically employ feature selection based on metrics like the Gini index or entropy.
\end{description}


\subsection{Pearson's Correlation Coefficient}
\label{ssec:pearsons}
\Ac{pcc} is a statistical measure widely used to evaluate the linear relationship between two variables. 
Specifically, we consider its application in the context of feature selection in machine learning, where it is used to assess the linear correlation between input features and the target variable. 
We regard the input vector $\mathbf{x}$ as a manifestation of an underlying, unknown distribution. 
Here, $X_i$ represents the random variable corresponding to the $i^{\text{th}}$ component of $\mathbf{x}$, and $y$ is the target value, viewed as a realization of the random variable $Y$ \cite{guyonIntroductionVariableFeature}. 
\Ac{pcc} is employed to quantify the linear correlation between these two random variables. It is defined by the formula:
\begin{equation}
R(i) = \frac{\text{cov}(X_i, Y)}{\sqrt{\text{var}(X_i) \cdot \text{var}(Y)}},
\end{equation}
where $\text{cov}(X_i, Y)$ is the covariance between $X_i$ and $Y$, and $\text{var}(X_i)$ and $\text{var}(Y)$ are the variances of $X_i$ and $Y$, respectively \cite{chandrashekarSurveyFeatureSelection2014}.
$R(i) \in [-1; +1]$ where -1 and +1 are strong negative or positive correlations and 0 indicates no correlation. 
In order to ascertain the significance of the test results, a hypothesis test needs to be performed, with the null hypothesis being that there is no correlation between the feature and the target.
As it is a non-parametric model, there is no need to tune hyperparameters or risk of overfitting.
While simple and effective for identifying linear relationships, \ac{pcc} only captures linear dependencies and might miss non-linear relationships crucial for neural networks.
Despite these limitations, \ac{pcc} remains a valuable tool in feature selection for its simplicity and efficiency in revealing linear correlations.

\subsection{Gradient Boosted Trees}
\label{ssec:gbt}

\Ac{gbt} is an ensemble learning technique that can be used for feature selection. 
The core idea of \ac{gbt} is to build a model in a stage-wise fashion, where each tree incrementally improves upon the previous ones by correcting their errors. 
This process involves training trees sequentially, with each new tree learning to predict the residuals or errors of the previous ensemble of trees.
There are different types of importance, such as the average or total gain across all splits the feature is used in.
The simplest definition is the 'weight', defined as the number of times a feature is used to split the data across all trees \cite{chenXGBoostScalableTree2016}.



\chapter{Data}
\label{chap:data}

Two different datasets need to be constructed: one dataset containing all relevant information prior to the start of the game and one dataset containing only the temporal information from the beginning of the game.


\section{Data Collection}
\label{sec:datacoll}

The data collection process for this study involved a dual-pronged approach, leveraging the extensive resources provided by the Riot Games API alongside a targeted web-scraping strategy.
The resulting raw dataset containing $38,573$ and  $3,972$ matches in the pre-game and in-game datasets respectively, stored in a PostgreSQL Database, reflects a comprehensive compilation of high-rank amateur League of Legends matches.

\paragraph{High-Rank Matches}
The rating system in \ac{lol} groups players into different skill groups, where the lowest is 'Iron' and the highest 'Challenger'.
The two highest ranks,'Grandmaster' and 'Challenger' contain the best 300 and 700 best players on each server.
The exact number of players these tiers depend on the player number in each region (see \cite{riotgamesMasterGrandmasterChallenger2023}).

Similar to the methodology of \citeauthor{zhangPredictionEsportsGame2021}, the focus of data acquisition was directed towards high-rank matches, in which a mix of excellent amateur and professional players play.
High rank matches in this context are defined as having at least one player holding the rank of Master, Grandmaster or Challenger.
These ranks combined account for the top $0.2\%$ of all players \cite{riotgamesRankedTiersDivisions2023}.
Riot Games themselves considers any rank above Diamond 3 as 'Elite' \cite{riotgamesDevBalanceFramework2020}, but we raise this bar just slightly to only include any rank at Master or above.
Due to the fact that for a match to be included in the dataset, only one out of ten players needs to hold one of the aforementioned highest ranks, some slightly lower ranked players are also present in the dataset.

Lower rank matches are not considered due to their higher unpredictability as less skilled players should make huge, game-changing mistakes way more often.
This higher unpredictability could make it harder for the model to learn.

Pro matches, defined as professional players playing with their respective teams in an esport tournament or league, are not included as they are not available through the official Riot Games API.
Professional players are still included in the dataset, but only if they played regular, non-tournament games.

\paragraph{Riot Games API}
The primary source of data stemmed from the Riot Games API \cite{RiotDeveloperPortal}, a comprehensive repository of information pertaining to League of Legends gameplay.
The Riot Games API provided access to a plethora of essential data points, including champion statistics, general match information, timeline details, and player-specific information.
These variables collectively form a comprehensive and multifaceted dataset crucial for the development of an effective predictive model.
\paragraph{Other Data Sources}
However, not all pertinent data were available directly from the Riot Games API.
These include the general winning chance of each champion and statistics on how each player performs on each relevant champion.
To address this limitation, additional relevant information was gathered by using web scraping on u.gg \cite{GGBestLeague}.
\paragraph{Regions}
Multiple regions were included in the data collection process, including Europe West (EUW), Europe Nordic \& East (EUN), Korea (KR), and North America (NA).
This regional diversity contributes to the model's generalizability across different player bases and playing styles.
\paragraph{Period of Time}
All matches included in the dataset were played in season 13 and on patch 20.
It is important that all matches are played on the same patch, as a patch may cause major shifts in the balance of the game, thus making certain strategies and champions way better than others.



\section{Dataset Properties}
\label{sec:dataprop}

The pre-game dataset encompasses a total of 38,573 matches, while the in-game dataset contains 28,809 matches.
Below, the pre-game dataset is presented in more detail, as the smaller in-game dataset is a random sampling from the pre-game dataset.
\paragraph{Region Distribution}
The dataset is primarily comprised of matches from three major regions: North America, Western Europe, and South Korea, which collectively constitute the vast majority of matches in our dataset. 
It is important to note that due to a lack of official data pertaining to the number of games played or the number of players in each region, we are unable to conclusively verify whether the distribution of matches within our dataset aligns with the true underlying distribution of games played per region.
The major regions in the dataset are the same regions getting guaranteed spots at the world championship \cite{2023LeagueLegends2023} with the exception of china, whose matches are not available through the Riot Games API.
Consequently, it is reasonable to assume that this composition approximately mirrors the real-world distribution of matches.
A visual representation of the distribution of matches across regions is provided in Figure \ref{fig:platformId}.


\begin{figure}[ht]
\input{./images/platformId_distribution.pgf}
\caption{Region distribution}
\label{fig:platformId}
\end{figure}

\paragraph{Game length}
As only matches with a game length of at least 16 minutes are collected, the shortest match is 16 minutes long, while the longest game is $59.62$ minutes long.
The average match length is $27.50$ minutes.
Figure \ref{fig:gameDuration} graphically illustrates the distribution of game durations. 
Notably, the histogram reveals a prominent spike at the 16-minute mark.
This spike corresponds to the earliest possible conclusion time for a match, as League of Legends prohibits surrendering prior to the 15th minute of gameplay. In instances where an entire team collectively acknowledges the futility of their chances of victory, a surrender may be initiated at the 15-minute threshold.
If a simple majority of team members want to surrender, they have to wait until the 20th minute.
However, should a simple majority of team members decide to surrender, they must adhere to a 20-minute waiting period before being able to do so. 
Consequently, this unique feature of the game's mechanics clarifies the relatively diminished frequency of matches ending in the 17th to 19th-minute range within our dataset.

\begin{figure}[ht]
\input{./images/gameDuration_distribution.pgf}
\caption{Distribution of game duration with its kernel density estimationd}
\label{fig:gameDuration}
\end{figure}


\paragraph{Rank Distribution}
As only games with at least one player ranked Master or above are considered, this distribution does not match the real distribution of ranks.
This does introduce a bias and makes the findings less applicable to games in lower ranks.
As argued in \ref{sec:datacoll}, lower rank games could make the learning harder due to higher unpredictability.

\begin{figure}
\centering
\resizebox{\textwidth}{!}
{
\input{./images/tier_distribution.pgf}
}
\caption{Distribution of ranks in the dataset}
\label{fig:tier}
\end{figure}


\subsection{Pre-Game Dataset}
\label{ssec:pre_game_data}
The raw pre-game dataset contains $368$ columns which can be categorized into four distinct groups: General Match Information, Player Information, Champion Information and Player-Champion Information.
General match information, such as the patch number, are exclusively utilized for validation purposes and are excluded from the final dataset.

\paragraph{Player Information.}
This feature $\mathbf{x}_p$ is a two-dimensional vector including the account level, serving as an indicator of the player's accumulated gaming experience, and the player's rank, functioning as a metric for assessing the player's skill level.

\paragraph{Champion Information.}
The Champion Information feature $\mathbf{x}_c$ is composed of different metrics describing the success the players have with a particular champion over all games in all ranks (e.g. win rate).
Additionally, it contains more subjective information (e.g. difficulty) which is provided by Riot Games as a general guide to the champion.
However, it is noteworthy that a limitation inherent in these metrics lies in their aggregation across all player ranks, reducing their specificity to the ranks under analysis.

\paragraph{Player-Champion Information.}
This feature vector $\mathbf{x}_f$ contains information about the player on a specific champion.
It encompasses metrics such as the average amount of gold earned by the player across all matches played on the champion during season 13. 
\Citeauthor{costaFeatureAnalysisLeague2021} \cite{costaFeatureAnalysisLeague2021} found that  the most pivotal feature within this category is the player's win rate while piloting this champion.
Unfortunately, this information is not readily available to be extracted by our web scraper,  necessitating its omission from the dataset.
Each feature category (e.g.  average gold per match) consists of 10 features, one for each participant.

\subsection{In-Game Dataset}
\label{ssec:in_game_data}

The in-game dataset comprises 28,809 matches, representing a random subset extracted from the broader pre-game dataset.
$473$ features are used to describe the current state of the game at every minute, each forming a discrete time series.
These features encompass a range of player-specific metrics, including but not limited to damage inflicted on opponents, individual champion levels, and the accumulation of gold.
Furthermore, key events like the number of turrets destroyed and each team's total gold are tracked to more precisely gauge the game's state. 
Gold, a critical indicator, underscores each victory milestone - be it destroying a turret or defeating an adversary. 
As illustrated in Figure \ref{fig:totalGold}, members of the victorious team typically amass significantly more gold by the game's conclusion compared to their counterparts.
This is more prominent in the later stages of the game, making the win prediction earlier more difficult.
Destroying turrets is crucial in the game, offering significant gold rewards and map control. 
With a minimum of five turrets required for victory, their destruction serves as a key indicator of a team's likelihood to win.
Both the number of destroyed turrets and the cumulative amount of gold is tracked for each team.

\begin{figure}
\input{./images/totalGold.pgf}
\caption{Total gold accumulated by each player of the course of the match, separated into teams by color. }
\label{fig:totalGold}
\end{figure}


\section{Data Processing}
\label{sec:data_processing}

\paragraph{Missing Values}
There are no missing values in the data obtained directly from Riot Games.
On the rare occasion that the web scraper could not find the relevant information, missing values can occur.
As this is a technical error, the missing data can be described as \ac{mcar} \cite{acockWorkingMissingValues2005} and thus deleted row-wise without introducing a bias.

By deleting all rows containing missing data, the dataset shrinks by 384???? rows.
As missing values are caused by the web scraper, the in-game dataset has no missing values.

\paragraph{Individual Feature Processing Pre-Game Dataset.}
The rank is converted from the rank-tier system into a single floating point number where the integer part denotes the tier (Master, Grandmaster, etc.) and the floating point part denotes the rank (ranges from 1-5, but only in Diamond and below).
The win rate is calculated by averaging over the number of wins and losses the player has accumulated over the season.
The champion tier is converted from D - S ranking into integer values and the champion number is one-hot encoded.
The one-hot encoding results in two vectors of size $n$ -one for each team- where $n$ is the number of champions and 
\begin{equation*}
x_i = 
\begin{cases}
	1 & \text{if a member of the team plays champion } i, \\
	0 & \text{otherwise}.
\end{cases}
\end{equation*}
It is only possible to represent the whole team composition in one vector because no two players can pick the same champion.
As the 10 features per category in $\mathbf{x}_f$ is a very fine-grained approach which greatly increases the dimensionality of the dataset, 
we found that a broader approach is sufficient, where statistics are averaged for each team, reducing 10 features per category to two.

\paragraph{Individual Feature Processing In-Game Dataset.}
The raw in-game dataset contains 474 features, 47 per participant and 2 columns per team containing the number of destroyed turrets and cumulative gold.
Utilizing domain expertise, 9 features per participant have been deemed extraneous and subsequently excluded, effectively reducing the feature count to 384. 
To further streamline the dataset, a dimensionality reduction strategy is employed whereby individual player metrics are averaged across their respective teams.
This method significantly decreases the total number of features, albeit at the expense of individual player variability and unique performance traits.
Such a reduction inherently shifts the analytical emphasis from individual prowess to overall team dynamics. 
Given that \ac{lol} is intrinsically a team-oriented game, this refocused perspective is anticipated to enhance the generalizability of a predictive model as the model is trained on team-level trends rather than individual fluctuations, which can be more noisy and less predictive of outcomes.




\paragraph{Scaling and Partitioning}
The pre-game dataset is partitioned into train, validation and test set with a validation and test size of 4,000 samples $ \approx 10\%$ respectively.
In order to have a more comparable training dataset size, the test and validation sets from the in-game dataset contain just 1,000 matches.
The validation set is used to optimize hyperparameters while the test set is used to evaluate the final performance of the model.
In order to allow proper training of the model, the data has to either be transformed into range $[1;-1]$ or standardized \cite{shankerEffectDataStandardization1996}.
The standardization is performed on each feature individually by calculating the mean $\mu$ and standard deviation $\sigma$ of the training set and applying the standardization $z = (x - \mu) / \sigma$ where $x$ is the original data and $z$ the transformed data.

\chapter{Results and Discussion}
\label{chap:results}

\section{Feature Selection Results}
\label{sec:feature_selection_results}

In order to assess the linear relationship between features and the target variable for the pre-game dataset,\acl{pcc} is employed.
In the dataset, each feature category is split in two columns, one per team.
To facilitate a comprehensive understanding of which feature category is most influential, the results are averaged across each category.
Only the absolute values of the \acp{pcc} are considered, as the direction of the relationship is of no concern when assessing its strength.
The ten features with the highest correlation are displayed in Table \ref{tab:fs_results}.
It is important to note that all $p$-values associated with these correlations are below the significance threshold of $0.01$, thereby confirming their high statistical relevance.

\Aclp{gbt} were used to assess non-linear relationships.
The model was configured with the following hyperparameters: number of estimators set to 100, maximum depth at 3, a learning rate of 0.1, and the objective function as binary logistic.
The Feature Importance Score is the number of times a feature was used to split the data across all trees.
\Ac{gbt} achieved an accuracy of 0.69.

In order to provide a clearer comparison between the \ac{pcc} and \ac{gbt} results, both sets of scores have been normalized into range $[0, 1]$.
This normalization, as depicted in Figure \ref{fig:fs_norm}, allows for a more intuitive visual comparison of the feature importance as assessed by the two different methods.

A key observation is that the highest \ac{pcc} and Feature Importance is associated with the KDA feature. 
This metric, which calculates the average ratio of $\frac{\text{Kills} + \text{Assists}}{\text{Deaths}}$ achieved by a player on their champion, still demonstrates a low linear correlation with the target variable of only $0.287$.
Notably, the three next highest correlations are Assists, Deaths and Kills, all of which are combined to calculate the KDA.
This is different to the \ac{gbt} results, as the three features with the next highest score are Gold, League Points and Assists.
This suggests that KDA encapsulates the essential information from Kills, Deaths and Assists, leading to \ac{gbt} assigning higher importance to KDA and lower importance to these related features.

In contrast to the analysis performed by \citeauthor{costaFeatureAnalysisLeague2021} \cite{costaFeatureAnalysisLeague2021}, the win rate is not the most important factor.
However, the general trend of placing the highest importance on statistics of individual players instead of general champion statistics is similar.

\begin{figure}
\centering
\resizebox{\textwidth}{!}{%
	\input{./images/feature_importance.pgf}
}
\caption{\ac{gbt} Feature Importance Scores and \acp{pcc} normalized into range $[0, 1]$}
\label{fig:fs_norm}
\end{figure}

\begin{table}
\centering
\caption{\acl{gbt} Feature Importance Scores and \aclp{pcc}, averaged per category}
\label{tab:fs_results}
\begin{tblr}{ccc}
	Category & \ac{gbt} Importance Score & \ac{pcc}\\
	\hline
	KDA & 88.5 & 0.287 \\
	Gold & 45.0 & 0.124 \\
	League Points & 37.5 & 0.030 \\
	Assists & 27.0 & 0.190 \\
	Deaths & 21.5 & 0.183 \\
	Max Kills & 19.0 & 0.021 \\
	Last Play Time & 16.0 & 0.023 \\
	Winrate & 12.5 & 0.058 \\
	Kills & 11.5 & 0.134 \\
	Championlevel & 8.5 & 0.069 \\
	Hot Streak & 8.5 & 0.066 \\
	Damage & 6.5 & 0.084 \\
	Creep Score & 3.5 & 0.058 \\
\end{tblr}
\end{table}

For the in-game dataset, manual feature selection using domain knowledge was performed.


\section{Pre-Game Classification}
\label{sec:pregame_class}
Settings used: 
\subsection{Hyperparameter Optimization}
\label{ssec:hyperparam_optim}

\begin{table}
\centering
\caption{Overview of the hyperparameter search for the pre-game classification}
\label{tab:static_hyperparam_optim}
\begin{tblr}{ccc}
Hyperparameter & Values & Distribution \\
\hline
Hidden Size & [128, 256, 512] & Selection \\
Learning Rate & [$\num{1e-5}$; $\num{1e-2}$] & uniform \\
Number of Layers & [2;15] & discrete \\
Dropout Probability & [0.3; 0.5] & discrete \\
Activation Function & [\ac{relu}, ELU, LeakyReLu] & Selection \\


\end{tblr}
\end{table}

\section{Mid-Game Classification}
\label{sec:midgame_class}


\begin{table}
\centering
\begin{longtblr}
[
caption = {Overview of the hyperparameter search for the mid-game classification},
label = {tab:timeline_hyperparam_optim},
]
{ccc}

Hyperparameter & Values & Distribution \\
\hline
Hidden Size & [128, 256, 512] & Selection \\
Learning Rate & [$\num{1e-7}$; $\num{1e-3}$] & uniform \\
Number of Layers & [1; 3] & discrete \\
Dropout Probability & [0.0; 0.4] & discrete \\
Number of Fully Connected Layers & [1; 3] & discrete \\
\end{longtblr}
\end{table}

retrain probably necessary for every patch

no real improvement with gru compared to silva on rnn
\chapter{Conclusion}
\label{chap:conclusion}

%\bibliographystyle{natdin}
%\bibliographystyle{naturemag}
%\bibliographystyle{geralpha}
\printbibliography

\appendix




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ********************* Verzeichnisse ********************* %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\listoffigures																			% Abbildungsverzeichnis
\listoftables																			% Tabellenverzeichnis
\cleardoublepage\phantomsection\addcontentsline{toc}{chapter}{List of Abbreviations}	% Abkürzungsverzeichnis
\printacronyms[heading={chapter*}, name={List of Abbreviations}]



\end{document}
