@misc{10GatedRecurrent,
  title = {10.2. {{Gated Recurrent Units}} ({{GRU}}) --- {{Dive}} into {{Deep Learning}} 1.0.3 Documentation},
  url = {https://d2l.ai/chapter_recurrent-modern/gru.html},
  urldate = {2024-02-24},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/3Q4VX7HM/gru.html}
}

@misc{2022Recap,
  title = {2022 {{Recap}}},
  journal = {YearIn.LoL},
  url = {https://yearin.lol},
  urldate = {2023-12-19},
  abstract = {Your recap for the year 2022 in League of Legends. Check out your multikill performance, total playtime, overall damage dealt, and much more.},
  langid = {english},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/9TWVLPMY/yearin.lol.html}
}

@article{2023LeagueLegends2023,
  title = {2023 {{{\emph{League}}}}{\emph{ of }}{{{\emph{Legends}}}} {{World Championship}}},
  year = {2023},
  month = dec,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=2023_League_of_Legends_World_Championship&oldid=1189902903},
  urldate = {2024-01-02},
  abstract = {The 2023 League of Legends World Championship was an esports tournament for the multiplayer online battle arena video game League of Legends. It was the thirteenth iteration of the League of Legends World Championship, an annual international tournament organized by the game's developer, Riot Games. The tournament began in South Korea on October 10 until November 19. Twenty-two teams from nine regions qualified for the tournament based on their placement in regional circuits; defending champions DRX failed to do so after losing to Dplus KIA in the 2023 LCK Regional Finals. JD Gaming were in contention to become the first team to complete the "Golden Road", but lost to eventual champions T1 in the semifinals of the knockout stage."Gods" (stylized in all caps), performed by NewJeans, was announced as the tournament's theme song. A virtual boyband named "Heartsteel" (stylized in all caps) was unveiled by Riot Games during the event, with Baekhyun from Exo and SuperM, {\O}ZI, Tobi Lou and Cal Scruby representing the group as its human counterpart and in the live performance of their debut song, "Paranoia".The final took place on 19 November 2023 at the Gocheok Sky Dome, where T1 defeated Weibo Gaming by a 3--0 score, marking the organization's record-extending fourth World Championship. The event's concurrent viewership reached a peak of 6.4 million viewers, breaking the all-time viewership record for a single esports event, not accounting for Chinese viewership.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1189902903}
}

@misc{2023WorldChampionship,
  title = {2023 {{World Championship}} [{{Worlds}} 2023] - {{LoL}} - {{Viewership}}, {{Overview}}, {{Prize Pool}} {\textbar} {{Esports Charts}}},
  url = {https://escharts.com/tournaments/lol/2023-world-championship},
  urldate = {2024-01-27},
  abstract = {2023 World Championship [Worlds 2023] - LoL statistics and viewership ► Tournament overview, 2023 World Championship [Worlds 2023] prize pool, peak viewers, how to watch live 2023 World Championship [Worlds 2023], top matches, platforms, viewer count and more},
  langid = {english},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/3EVDEIV5/2023-world-championship.html}
}

@article{acockWorkingMissingValues2005,
  title = {Working {{With Missing Values}}},
  author = {Acock, Alan C.},
  year = {2005},
  journal = {Journal of Marriage and Family},
  volume = {67},
  number = {4},
  pages = {1012--1028},
  issn = {1741-3737},
  doi = {10.1111/j.1741-3737.2005.00191.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1741-3737.2005.00191.x},
  urldate = {2024-01-06},
  abstract = {Less than optimum strategies for missing values can produce biased estimates, distorted statistical power, and invalid conclusions. After reviewing traditional approaches (listwise, pairwise, and mean substitution), selected alternatives are covered including single imputation, multiple imputation, and full information maximum likelihood estimation. The effects of missing values are illustrated for a linear model, and a series of recommendations is provided. When missing values cannot be avoided, multiple imputation and full information methods offer substantial improvements over traditional approaches. Selected results using SPSS, NORM, Stata (mvis/micombine), and Mplus are included as is a table of available software and an appendix with examples of programs for Stata and Mplus.},
  langid = {english},
  keywords = {MAR,MCAR,missing data,missing values,multiple imputation},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/PY67KNYF/Acock - 2005 - Working With Missing Values.pdf;/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/9AQ575FE/j.1741-3737.2005.00191.html}
}

@article{aeschbachPsychologyEsportsPlayers2023,
  title = {The Psychology of Esports Players' {{ELO Hell}}: {{Motivated}} Bias in {{League}} of {{Legends}} and Its Impact on Players' Overestimation of Skill},
  shorttitle = {The Psychology of Esports Players' {{ELO Hell}}},
  author = {Aeschbach, Lena Fanya and Kayser, Dominik and Berbert De Castro H{\"u}sler, Antony and Opwis, Klaus and Br{\"u}hlmann, Florian},
  year = {2023},
  month = oct,
  journal = {Computers in Human Behavior},
  volume = {147},
  pages = {107828},
  issn = {07475632},
  doi = {10.1016/j.chb.2023.107828},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0747563223001796},
  urldate = {2023-11-09},
  abstract = {This paper examines the folk theory of ELO Hell, which stems from the community of esports players. ELO Hell is a causal explanation for the failure to achieve which is prominent but controversial in esports. Within the community, the belief in the existence of ELO Hell associated with lower skill. We aim to explain the persistence of this folk theory despite the debate within the community using psychological theories. We find this folk theory relevant for investigation because the blame placed on other players could escalate to patterns of harmful behavior, known as toxicity. Given the association with lower-ranked players, we predict this could be an operationalization of the Dunning--Kruger effect, a tendency for lower-skilled performers to overestimate themselves, and its associated motivational biases. Surveying 267 players of the esports League of Legends and triangulating the quantitative, qualitative, and mined data collected, we find evidence of lowerskilled players overestimating their skills more so than higher-skilled players. Further, we find that motivational biases regarding causal attributions for failure and success did explain significant variance in the degree of overestimation. However, we also found some players withdraw their effort from competitive play and we use self-determination theory to categorize their reason for losing motivation. Taken together, we show the psychological mechanisms which lead to the formation of the folk theory of ELO Hell and the motivational biases that uphold the conflict about its existence.},
  langid = {english},
  keywords = {League of Legends,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/GN9T5QU6/Aeschbach et al. - 2023 - The psychology of esports players’ ELO Hell Motiv.pdf}
}

@article{ahnOneBillionDollar2020,
  title = {The One Billion Dollar Myth: {{Methods}} for Sizing the Massively Undervalued Esports Revenue Landscape},
  shorttitle = {The One Billion Dollar Myth},
  author = {Ahn, Joseph and Collis, William and Jenny, Seth},
  year = {2020},
  month = oct,
  journal = {International Journal of Esports},
  volume = {1},
  number = {1},
  issn = {2634-1069},
  url = {https://www.ijesports.org/article/15/html},
  urldate = {2023-12-09},
  abstract = {It is our contention that the 2019 esports industry's revenue size is massively undervalued at \$1.1B USD within the literature. This paper provides a more accurate sizing of the esports landscape, incorporating into the analysis six major sectors of the esports industry: 1) teams, professional players, and streamers, 2) game publishers, 3) streaming platforms, 4) physical products, 5) leagues and tournaments, and 6) digital tools. Each sector is discussed separately, with descriptions of the business models and corresponding revenue equations that drive each sector's revenue estimates. Overall, we purport that \$24.9B USD is a more accurate estimation of the ``true'' market size of esports for 2019.},
  langid = {english},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/E5GNQZCI/Ahn et al. - 2020 - The one billion dollar myth Methods for sizing th.pdf}
}

@misc{akhmedovMachineLearningModels2021,
  title = {Machine Learning Models for {{DOTA}} 2 Outcomes Prediction},
  author = {Akhmedov, Kodirjon and Phan, Anh Huy},
  year = {2021},
  month = jun,
  number = {arXiv:2106.01782},
  eprint = {2106.01782},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2106.01782},
  urldate = {2023-11-14},
  abstract = {Prediction of the real-time multiplayer online battle arena (MOBA) games' match outcome is one of the most important and exciting tasks in Esports analytical research. This research paper predominantly focuses on building predictive machine and deep learning models to identify the outcome of the Dota 2 MOBA game using the new method of multi-forward steps predictions. Three models were investigated and compared: Linear Regression (LR), Neural Networks (NN), and a type of recurrent neural network Long Short-Term Memory (LSTM). In order to achieve the goals, we developed a data collecting python server using Game State Integration (GSI) to track the real-time data of the players. Once the exploratory feature analysis and tuning hyper-parameters were done, our models' experiments took place on different players with dissimilar backgrounds of playing experiences. The achieved accuracy scores depend on the multi-forward prediction parameters, which for the worse case in linear regression 69\% but on average 82\%, while in the deep learning models hit the utmost accuracy of prediction on average 88\% for NN, and 93\% for LSTM models.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Dota 2,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/57WTCEMB/Akhmedov und Phan - 2021 - Machine learning models for DOTA 2 outcomes predic.pdf}
}

@inproceedings{aniVictoryPredictionLeague2019,
  title = {Victory Prediction in {{League}} of {{Legends}} Using {{Feature Selection}} and {{Ensemble}} Methods},
  booktitle = {2019 {{International Conference}} on {{Intelligent Computing}} and {{Control Systems}} ({{ICCS}})},
  author = {Ani, R. and Harikumar, Vishnu and Devan, Arjun K. and Deepa, O.S.},
  year = {2019},
  month = may,
  pages = {74--77},
  doi = {10.1109/ICCS45141.2019.9065758},
  url = {https://ieeexplore.ieee.org/abstract/document/9065758},
  urldate = {2023-10-05},
  abstract = {Prediction of winners in the online video games has become an important application for machine learning based prediction models. The main goal of the present study is to achieve a good prediction rate for a popular Electronic sport called League of Legends. League of Legends is a Multiplayer Online Battle Arena (MOBA) game that combines intensity of a Real-time strategy with various Role-playing elements. Feature selection is done and only relevant features that affect the match outcomes are considered. Prediction is done by using ensemble models of classification algorithms and the performance was evaluated. The important performance metrics and their influence on each game model were also analyzed. The results show that the reliable match result prediction is possible in the League of Legends game.},
  keywords = {League of Legends,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/WBKJXZVI/Ani et al. - 2019 - Victory prediction in League of Legends using Feat.pdf}
}

@misc{aratBackpropagationTimeRecurrent2019,
  title = {Backpropagation {{Through Time}} for {{Recurrent Neural Network}}},
  author = {Arat, Mustafa Murat},
  year = {2019},
  month = feb,
  journal = {Mustafa Murat ARAT},
  url = {https://mmuratarat.github.io//2019-02-07/bptt-of-rnn},
  urldate = {2023-12-21},
  abstract = {Homepage},
  langid = {english},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/WTR7U3TV/bptt-of-rnn.html}
}

@misc{Asec4RNNs_notes_209b2019Pdf,
  title = {A-Sec4-{{RNNs}}\_notes\_209b2019.Pdf},
  url = {https://harvard-iacs.github.io/2019-CS109B/a-sections/a-section4/notes/a-sec4-RNNs_notes_209b2019.pdf},
  urldate = {2023-12-22}
}

@article{bahrololloomiESportsPlayerPerformance2023,
  title = {E-{{Sports Player Performance Metrics}} for {{Predicting}} the {{Outcome}} of {{League}} of {{Legends Matches Considering Player Roles}}},
  author = {Bahrololloomi, Farnod and Klonowski, Fabio and Sauer, Sebastian and Horst, Robin and D{\"o}rner, Ralf},
  year = {2023},
  month = mar,
  journal = {SN Computer Science},
  volume = {4},
  number = {3},
  pages = {238},
  issn = {2661-8907},
  doi = {10.1007/s42979-022-01660-6},
  url = {https://doi.org/10.1007/s42979-022-01660-6},
  urldate = {2023-10-05},
  abstract = {Predicting results in electronic sports (e-sports) matches is not an easy task. Different methods can be used for this purpose. A well-known video game in the field of Multiplayer Online Battle Arena (MOBA) is the game League of Legends (LoL), which has a relevant professional scene. An important part of professional gaming is analyzing past matches overall and an individual player's performance to prepare for future matches. In this paper, we follow a design-oriented research methodology (analysis, design, and evaluation) and propose performance metrics that use data from past matches to evaluate a player's performance. We analyze the necessary data which we acquire by selecting a player, analyzing the player's latest games, and repeating the process recursively with the players found in his latest games. The data is utilized within a Machine Learning (ML) Model that computes an overall score from individual player variables. From this, we designed a heuristic approach and evaluated it by applying it to the challenge of winning predictions in e-sports. The difference in the influence of the individual player roles on the outcome of the game was also investigated. It was found that this difference is negligible and that the heuristic performance metric can predict the outcome of a game with an accuracy of 86\%. Furthermore, the concept of a match calculator is explored, which calculates the outcome of a match using the ML model and different player stats.},
  langid = {english},
  keywords = {League of Legends,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/953LIA25/Bahrololloomi et al. - 2023 - E-Sports Player Performance Metrics for Predicting.pdf}
}

@inproceedings{bahrololloomiMachineLearningBased2022,
  title = {A {{Machine Learning}} Based {{Analysis}} of E-{{Sports Player Performances}} in {{League}} of {{Legends}} for {{Winning Prediction}} Based on {{Player Roles}} and {{Performances}}.},
  booktitle = {{{VISIGRAPP}} (2: {{HUCAPP}})},
  author = {Bahrololloomi, Farnod and Sauer, Sebastian and Klonowski, Fabio and Horst, Robin and D{\"o}rner, Ralf},
  year = {2022},
  pages = {68--76},
  keywords = {League of Legends,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/FT3J4CE5/Bahrololloomi et al. - 2022 - A Machine Learning based Analysis of e-Sports Play.pdf}
}

@article{baileyStatisticalLearningEsports,
  title = {Statistical {{Learning}} for {{Esports Match Prediction}}},
  author = {Bailey, Kevin},
  langid = {english},
  keywords = {League of Legends,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/AGMXMZHG/Bailey - Statistical Learning for Esports Match Prediction.pdf}
}

@article{battitiUsingMutualInformation1994,
  title = {Using Mutual Information for Selecting Features in Supervised Neural Net Learning},
  author = {Battiti, R.},
  year = {1994},
  month = jul,
  journal = {IEEE Transactions on Neural Networks},
  volume = {5},
  number = {4},
  pages = {537--550},
  issn = {1941-0093},
  doi = {10.1109/72.298224},
  url = {https://ieeexplore.ieee.org/abstract/document/298224?casa_token=fEbzH5lqsegAAAAA:0qJA2Bd57gByZu8lV1uUXyqF9iRs1nv9_LEVNI07OqO9Rg0cb1D_IwYe1m-wnHk1vFPIRFSpLA},
  urldate = {2023-12-25},
  abstract = {This paper investigates the application of the mutual information criterion to evaluate a set of candidate features and to select an informative subset to be used as input data for a neural network classifier. Because the mutual information measures arbitrary dependencies between random variables, it is suitable for assessing the "information content" of features in complex classification tasks, where methods bases on linear relations (like the correlation) are prone to mistakes. The fact that the mutual information is independent of the coordinates chosen permits a robust estimation. Nonetheless, the use of the mutual information for tasks characterized by high input dimensionality requires suitable approximations because of the prohibitive demands on computation and samples. An algorithm is proposed that is based on a "greedy" selection of the features and that takes both the mutual information with respect to the output class and with respect to the already-selected features into account. Finally the results of a series of experiments are discussed.{$<>$}},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/LWL9Q7KM/Battiti - 1994 - Using mutual information for selecting features in.pdf;/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/67VPBKEC/298224.html}
}

@article{bellman1961adaptive,
  title = {Adaptive Control Processes; a Guided Tour, Princeton Univ},
  author = {Bellman, R},
  year = {1961},
  journal = {Press, NJ}
}

@article{bengioLearningLongtermDependencies1994,
  title = {Learning Long-Term Dependencies with Gradient Descent Is Difficult},
  author = {Bengio, Y. and Simard, P. and Frasconi, P.},
  year = {1994},
  month = mar,
  journal = {IEEE Transactions on Neural Networks},
  volume = {5},
  number = {2},
  pages = {157--166},
  issn = {1941-0093},
  doi = {10.1109/72.279181},
  url = {https://ieeexplore.ieee.org/abstract/document/279181?casa_token=f5w3HVDYejMAAAAA:oY_D8xnIsGbMdzLZuRzFwX-ED93aitQCWu85Y_VyBD1jmYf_KD9ILUZ8gknQ8ONf34w6LUU},
  urldate = {2023-11-07},
  abstract = {Recurrent neural networks can be used to map input sequences to output sequences, such as for recognition, production or prediction problems. However, practical difficulties have been reported in training recurrent neural networks to perform tasks in which the temporal contingencies present in the input/output sequences span long intervals. We show why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases. These results expose a trade-off between efficient learning by gradient descent and latching on information for long periods. Based on an understanding of this problem, alternatives to standard gradient descent are considered.{$<>$}},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/IZCICZ59/Bengio et al. - 1994 - Learning long-term dependencies with gradient desc.pdf}
}

@article{bentejacComparativeAnalysisGradient2021,
  title = {A Comparative Analysis of Gradient Boosting Algorithms},
  author = {Bent{\'e}jac, Candice and Cs{\"o}rg{\H o}, Anna and {Mart{\'i}nez-Mu{\~n}oz}, Gonzalo},
  year = {2021},
  month = mar,
  journal = {Artificial Intelligence Review},
  volume = {54},
  number = {3},
  pages = {1937--1967},
  issn = {1573-7462},
  doi = {10.1007/s10462-020-09896-5},
  url = {https://doi.org/10.1007/s10462-020-09896-5},
  urldate = {2024-02-20},
  abstract = {The family of gradient boosting algorithms has been recently extended with several interesting proposals (i.e. XGBoost, LightGBM and CatBoost) that focus on both speed and accuracy. XGBoost is a scalable ensemble technique that has demonstrated to be a reliable and efficient machine learning challenge solver. LightGBM is an accurate model focused on providing extremely fast training performance using selective sampling of high gradient instances. CatBoost modifies the computation of gradients to avoid the prediction shift in order to improve the accuracy of the model. This work proposes a practical analysis of how these novel variants of gradient boosting work in terms of training speed, generalization performance and hyper-parameter setup. In addition, a comprehensive comparison between XGBoost, LightGBM, CatBoost, random forests and gradient boosting has been performed using carefully tuned models as well as using their default settings. The results of this comparison indicate that CatBoost obtains the best results in generalization accuracy and AUC in the studied datasets although the differences are small. LightGBM is the fastest of all methods but not the most accurate. Finally, XGBoost places second both in accuracy and in training speed. Finally an extensive analysis of the effect of hyper-parameter tuning in XGBoost, LightGBM and CatBoost is carried out using two novel proposed tools.},
  langid = {english},
  keywords = {CatBoost,Ensembles of classifiers,Gradient boosting,LightGBM,Random forest,XGBoost},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/M2FIJDIE/Bentéjac et al. - 2021 - A comparative analysis of gradient boosting algori.pdf}
}

@article{bergstraRandomSearchHyperParameter,
  title = {Random {{Search}} for {{Hyper-Parameter Optimization}}},
  author = {Bergstra, James and Bengio, Yoshua},
  abstract = {Grid search and manual search are the most widely used strategies for hyper-parameter optimization. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a comparison with a large previous study that used grid search and manual search to configure neural networks and deep belief networks. Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising configuration space. Compared with deep belief networks configured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for configuring algorithms for new data sets. Our analysis casts some light on why recent ``High Throughput'' methods achieve surprising success---they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that random search is a natural baseline against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms.},
  langid = {english},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/FVD2PELM/Bergstra und Bengio - Random Search for Hyper-Parameter Optimization.pdf}
}

@article{blockESportsNewIndustry2021,
  title = {{{eSports}}: A New Industry},
  shorttitle = {{{eSports}}},
  author = {Block, Sebastian and Haack, Florian},
  year = {2021},
  journal = {SHS Web of Conferences},
  volume = {92},
  pages = {04002},
  publisher = {{EDP Sciences}},
  issn = {2261-2424},
  doi = {10.1051/shsconf/20219204002},
  url = {https://www.shs-conferences.org/articles/shsconf/abs/2021/03/shsconf_glob20_04002/shsconf_glob20_04002.html},
  urldate = {2024-01-27},
  abstract = {\textbf{Research background:{$<$}b/{$>$} At the beginning of this century, the eSports industry was not yet a major player although it already existed as a niche of video and computer games. The importance and interest only began to increase with the rise of the internet and its infrastructure. Especially among the younger generation, eSports, today, has a significant meaning. Worldwide, professional players duel each other in countless tournaments online and offline and are enthusiastically celebrated by their millions of fans.\textbf{Purpose of the article:{$<$}b/{$>$} The purpose of this paper is to analyze how eSports has developed in recent years since its first boom phase as well as to analyze its growth factors and how it has benefited from the COVID-19 pandemic compared to traditional competitive sports.\textbf{Methods:{$<$}b/{$>$} The global eSports revenues and prize money values are analyzed. The first step is defining the eSports term. The second is looking at the development of eSports financials since its first boom and onward. The COVID-19 pandemic and its impacts are then looked at. Finally, growth factors for the increasing numbers are analyzed.\textbf{Findings \& Value added:{$<$}b/{$>$} The findings show that eSports has gained significant importance in recent years. In particular, the strong increase in global eSports revenue and the associated increase in players' prize money clearly show that eSports will continue to gain importance and economic strength in the future.}}}}},
  copyright = {{\copyright} The Authors, published by EDP Sciences, 2021},
  langid = {english},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/RIGGMFXI/Block und Haack - 2021 - eSports a new industry.pdf}
}

@inproceedings{bridleProbabilisticInterpretationFeedforward1990,
  title = {Probabilistic {{Interpretation}} of {{Feedforward Classification Network Outputs}}, with {{Relationships}} to {{Statistical Pattern Recognition}}},
  booktitle = {Neurocomputing},
  author = {Bridle, John S.},
  editor = {Souli{\'e}, Fran{\c c}oise Fogelman and H{\'e}rault, Jeanny},
  year = {1990},
  series = {{{NATO ASI Series}}},
  pages = {227--236},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-76153-9_28},
  abstract = {We are concerned with feed-forward non-linear networks (multi-layer perceptrons, or MLPs) with multiple outputs. We wish to treat the outputs of the network as probabilities of alternatives (e.g. pattern classes), conditioned on the inputs. We look for appropriate output non-linearities and for appropriate criteria for adaptation of the parameters of the network (e.g. weights). We explain two modifications: probability scoring, which is an alternative to squared error minimisation, and a normalised exponential (softmax) multi-input generalisation of the logistic non-linearity. The two modifications together result in quite simple arithmetic, and hardware implementation is not difficult either. The use of radial units (squared distance instead of dot product) immediately before the softmax output stage produces a network which computes posterior distributions over class labels based on an assumption of Gaussian within-class distributions. However the training, which uses cross-class information, can result in better performance at class discrimination than the usual within-class training method, unless the within-class distribution assumptions are actually correct.},
  isbn = {978-3-642-76153-9},
  langid = {english},
  keywords = {Boltzmann Machine,Class Label,Hide Markov Model,Posterior Distribution,Statistical Pattern Recognition}
}

@article{campbell2021sports,
  title = {Sports versus Esports--a Comparison of Industry Size, Viewer Friendliness, and Game Competitiveness},
  author = {Campbell, William and Goss, Amanda and Trottier, Kyle and Claypool, Mark},
  year = {2021},
  journal = {Global esports: Transformation of Cultural Perceptions of Competitive Gaming, Bloomsbury, London},
  pages = {35--59}
}

@incollection{chanArtificialIntelligenceVideo2022,
  title = {Artificial {{Intelligence}} in {{Video Games}} and {{eSports}}},
  booktitle = {Applied {{Artificial Intelligence}} in {{Business}}: {{Concepts}} and {{Cases}}},
  author = {Chan, Leong and Hogaboam, Liliya and Cao, Renzhi},
  editor = {Chan, Leong and Hogaboam, Liliya and Cao, Renzhi},
  year = {2022},
  series = {Applied {{Innovation}} and {{Technology Management}}},
  pages = {335--352},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-031-05740-3_22},
  url = {https://doi.org/10.1007/978-3-031-05740-3_22},
  urldate = {2023-09-26},
  abstract = {This chapter starts with the introduction and the evolution of AI in gaming and esports. It explores the enabling technologies for AI in gaming (big data, virtual reality, AI chips and GPUs, online gaming, and cloud platforms). AI applications in video games and esports include AI Opponents, AI NPCs, procedural content generation, player experience modeling, antisocial behavior detection, win prediction, player telemetry analytics, intelligent tutoring, and training. Case studies section consists of DeepMind Alpha Go, Alpha Star, and Microsoft HoloLens.},
  isbn = {978-3-031-05740-3},
  langid = {english},
  keywords = {MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/IAFMRCVL/Chan et al. - 2022 - Artificial Intelligence in Video Games and eSports.pdf}
}

@article{chandrashekarSurveyFeatureSelection2014,
  title = {A Survey on Feature Selection Methods},
  author = {Chandrashekar, Girish and Sahin, Ferat},
  year = {2014},
  month = jan,
  journal = {Computers \& Electrical Engineering},
  volume = {40},
  number = {1},
  pages = {16--28},
  issn = {00457906},
  doi = {10.1016/j.compeleceng.2013.11.024},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0045790613003066},
  urldate = {2023-12-01},
  abstract = {Plenty of feature selection methods are available in literature due to the availability of data with hundreds of variables leading to data with very high dimension. Feature selection methods provides us a way of reducing computation time, improving prediction performance, and a better understanding of the data in machine learning or pattern recognition applications. In this paper we provide an overview of some of the methods present in literature. The objective is to provide a generic introduction to variable elimination which can be applied to a wide array of machine learning problems. We focus on Filter, Wrapper and Embedded methods. We also apply some of the feature selection techniques on standard datasets to demonstrate the applicability of feature selection techniques.},
  langid = {english},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/CXWEB3I6/Chandrashekar und Sahin - 2014 - A survey on feature selection methods.pdf}
}

@article{chaudhuryRobustnessAdaptiveNeural2021,
  title = {Robustness of {{Adaptive Neural Network Optimization Under Training Noise}}},
  author = {Chaudhury, Subhajit and Yamasaki, Toshihiko},
  year = {2021},
  journal = {IEEE Access},
  volume = {9},
  pages = {37039--37053},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2021.3062990},
  url = {https://ieeexplore.ieee.org/abstract/document/9366477},
  urldate = {2024-01-16},
  abstract = {Adaptive gradient methods such as adaptive moment estimation (Adam), RMSProp, and adaptive gradient (AdaGrad) use the temporal history of the gradient updates to improve the speed of convergence and reduce reliance on manual learning rate tuning, making them a popular choice for off-the-shelf Deep Neural Network (DNN) optimizers. In this article, we study the robustness of neural network optimizers in the presence of training perturbations. We show that popular adaptive optimization methods exhibit poor generalization while learning from noisy training data, compared to vanilla Stochastic Gradient Descent (SGD) and its variants, which manifest better implicit regularization properties. We construct an illustrative example of a family of two-class linearly separable toy-data such that models trained under noise using adaptive optimizers show only 52\% test accuracy (random classifier), whereas SGD-based methods can achieve 100\% test accuracy. We strengthen our hypothesis by empirical analysis using Convolutional Neural Networks (CNNs) on publicly available image datasets. For this purpose, our method trains neural network models with various optimizers on noisy training data, and we compute test accuracy on clean test data. Our results further highlight the robustness of SGD optimization against such noisy training data compared to its adaptive counterparts. Based on the results, our paper suggests a reconsideration of the extensive use of adaptive gradient methods for neural network optimization, especially when the training data is noisy.},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/Y7K9NU2H/Chaudhury und Yamasaki - 2021 - Robustness of Adaptive Neural Network Optimization.pdf;/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/W7MPAPGB/9366477.html}
}

@inproceedings{chenXGBoostScalableTree2016,
  title = {{{XGBoost}}: {{A Scalable Tree Boosting System}}},
  shorttitle = {{{XGBoost}}},
  booktitle = {Proceedings of the 22nd {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Chen, Tianqi and Guestrin, Carlos},
  year = {2016},
  month = aug,
  series = {{{KDD}} '16},
  pages = {785--794},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2939672.2939785},
  url = {https://dl.acm.org/doi/10.1145/2939672.2939785},
  urldate = {2023-12-02},
  abstract = {Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.},
  isbn = {978-1-4503-4232-2},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/WS9PDQHT/Chen und Guestrin - 2016 - XGBoost A Scalable Tree Boosting System.pdf}
}

@misc{choLearningPhraseRepresentations2014,
  title = {Learning {{Phrase Representations}} Using {{RNN Encoder-Decoder}} for {{Statistical Machine Translation}}},
  author = {Cho, Kyunghyun and {van Merrienboer}, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  year = {2014},
  month = sep,
  number = {arXiv:1406.1078},
  eprint = {1406.1078},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1406.1078},
  url = {http://arxiv.org/abs/1406.1078},
  urldate = {2023-11-03},
  abstract = {In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-length vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.},
  archiveprefix = {arxiv},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/SMU6BTJW/Cho et al. - 2014 - Learning Phrase Representations using RNN Encoder-.pdf}
}

@misc{chungEmpiricalEvaluationGated2014,
  title = {Empirical {{Evaluation}} of {{Gated Recurrent Neural Networks}} on {{Sequence Modeling}}},
  author = {Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
  year = {2014},
  month = dec,
  number = {arXiv:1412.3555},
  eprint = {1412.3555},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/1412.3555},
  urldate = {2023-09-26},
  abstract = {In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/DCTY8S5M/Chung et al. - 2014 - Empirical Evaluation of Gated Recurrent Neural Net.pdf}
}

@misc{claytorRiotGamesAWS2023,
  title = {Riot {{Games}} and {{AWS}} Bring Esports `{{Win Probability}}' Stat to 2023 {{League}} of {{Legends World Championships}} Broadcasts {\textbar} {{AWS}} for {{Games Blog}}},
  author = {Claytor, Ross and Ehrlich, Elena},
  year = {2023},
  month = oct,
  url = {https://aws.amazon.com/blogs/gametech/riot-games-and-aws-bring-esports-win-probability-stat-to-2023-league-of-legends-world-championships-broadcasts/},
  urldate = {2024-01-27},
  chapter = {Amazon SageMaker},
  langid = {american},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/X37ECVIC/riot-games-and-aws-bring-esports-win-probability-stat-to-2023-league-of-legends-world-champions.html}
}

@inproceedings{cleghernPredictingFutureStates2017,
  title = {Predicting Future States in {{DotA}} 2 Using Value-Split Models of Time Series Attribute Data},
  booktitle = {Proceedings of the 12th {{International Conference}} on the {{Foundations}} of {{Digital Games}}},
  author = {Cleghern, Zach and Lahiri, Soumendra and {\"O}zaltin, Osman and Roberts, David L.},
  year = {2017},
  month = aug,
  series = {{{FDG}} '17},
  pages = {1--10},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3102071.3102095},
  url = {https://dl.acm.org/doi/10.1145/3102071.3102095},
  urldate = {2023-10-05},
  abstract = {In Multiplayer Online Battle Arena (MOBA) games, teams of players compete in combat to complete an objective and defeat the opposing team. To stay alive, players must closely monitor their character's status, especially remaining health. Understanding how health may change in the near future can be vital in determining what tactics a player may use. We analyzed replay logs of the game Defense of the Ancients 2 (DotA 2) to discover methods to predict how players' health evolves over time. For DotA 2, our results suggest that forecasting changes in a player's health can be done by viewing gameplay as two separate processes: normal gameplay flow in which changes in health are smaller and more regular, and less frequent but higher-impact events in which players experience larger changes in their health, such as team battles. We accomplished this by considering health data as two separate, but interleaved, time series in which separate processes govern low magnitude changes in health from high magnitude changes. In this paper, we present a value-split approach to predicting changes in health and describe the results of our approach using autoregressive moving-average models for low magnitude health changes and a combination of statistical models for the larger changes.},
  isbn = {978-1-4503-5319-9},
  keywords = {Dota 2,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/8FVL6WXT/Cleghern et al. - 2017 - Predicting future states in DotA 2 using value-spl.pdf}
}

@inproceedings{costaFeatureAnalysisLeague2021,
  title = {Feature {{Analysis}} to {{League}} of {{Legends Victory Prediction}} on the {{Picks}} and {{Bans Phase}}},
  booktitle = {2021 {{IEEE Conference}} on {{Games}} ({{CoG}})},
  author = {Costa, Lincoln Magalh{\~a}es and Mantovani, Rafael Gomes and Monteiro Souza, Francisco Carlos and Xex{\'e}o, Geraldo},
  year = {2021},
  month = aug,
  pages = {01--05},
  issn = {2325-4289},
  doi = {10.1109/CoG52621.2021.9619019},
  url = {https://ieeexplore.ieee.org/abstract/document/9619019},
  urldate = {2023-10-05},
  abstract = {Victory prediction in online video games has become an important application for machine learning due to the large amount of data generated by these games and their growing popularity. The creation of professional leagues also drives these applications, as teams want to know their chances of victory and know what are the determining factors to achieve it. Thus, in this research, we analyze whether pre-game information can be explored for victory prediction of professional matches of League of Legends (LoL), one of the main MOBA games. In experiments, we benchmarked different feature sets and algorithms to assess the victory predictions in LoL. The results show that historical performance information is the most accurate features for performing this task. The induced models, especially Random Forest and Logistic Regression, achieved AUC values of 0.97.},
  keywords = {League of Legends,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/XXV82RQE/Costa et al. - 2021 - Feature Analysis to League of Legends Victory Pred.pdf}
}

@article{dalmiaChampionsLeagueFinal2023,
  title = {Champions {{League}} Final Set to Reach 450 Million Broadcast Viewers Worldwide},
  author = {Dalmia, Nikunj},
  year = {2023},
  month = jun,
  journal = {The Economic Times},
  issn = {0013-0389},
  url = {https://economictimes.indiatimes.com/news/sports/champions-league-final-set-to-reach-450-million-broadcast-viewers-worldwide/articleshow/100902286.cms?from=mdr},
  urldate = {2024-01-29},
  abstract = {Madrid's 1-0 victory over Liverpool one year ago had an average audience of 166 million, according to UEFA research, and the same two teams' final in 2018 had a 161 million average. When Liverpool played another English club, Tottenham, one year later in 2019 the average audience was just 91 million, according to UEFA.},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/NEV2YUMN/100902286.html}
}

@inproceedings{deyGatevariantsGatedRecurrent2017,
  title = {Gate-Variants of {{Gated Recurrent Unit}} ({{GRU}}) Neural Networks},
  booktitle = {2017 {{IEEE}} 60th {{International Midwest Symposium}} on {{Circuits}} and {{Systems}} ({{MWSCAS}})},
  author = {Dey, Rahul and Salem, Fathi M.},
  year = {2017},
  month = aug,
  pages = {1597--1600},
  issn = {1558-3899},
  doi = {10.1109/MWSCAS.2017.8053243},
  url = {https://ieeexplore.ieee.org/abstract/document/8053243?casa_token=aP9ZzK6D-7sAAAAA:FtaEMxjEzG7XgdwG6MKDiwSz1lZ2FDyft_3QzXh4WR8hI6TRH2o-WxoHZZ8DOIQHEM15C8U},
  urldate = {2023-11-07},
  abstract = {The paper evaluates three variants of the Gated Recurrent Unit (GRU) in recurrent neural networks (RNNs) by retaining the structure and systematically reducing parameters in the update and reset gates. We evaluate the three variant GRU models on MNIST and IMDB datasets and show that these GRU-RNN variant models perform as well as the original GRU RNN model while reducing the computational expense. In this comparative study, we simply refer to the three variants as, respectively, GRU1, GRU2, and GRU3 RNNs.},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/L22XJBH5/Dey und Salem - 2017 - Gate-variants of Gated Recurrent Unit (GRU) neural.pdf}
}

@inproceedings{doUsingMachineLearning2021,
  title = {Using {{Machine Learning}} to {{Predict Game Outcomes Based}} on {{Player-Champion Experience}} in {{League}} of {{Legends}}},
  booktitle = {Proceedings of the 16th {{International Conference}} on the {{Foundations}} of {{Digital Games}}},
  author = {Do, Tiffany D. and Wang, Seong Ioi and Yu, Dylan S. and McMillian, Matthew G. and McMahan, Ryan P.},
  year = {2021},
  month = oct,
  series = {{{FDG}} '21},
  pages = {1--5},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3472538.3472579},
  url = {https://dl.acm.org/doi/10.1145/3472538.3472579},
  urldate = {2023-11-14},
  abstract = {League of Legends (LoL) is the most widely played multiplayer online battle arena (MOBA) game in the world. An important aspect of LoL is competitive ranked play, which utilizes a skill-based matchmaking system to form fair teams. However, players' skill levels vary widely depending on which champion, or hero, that they choose to play as. In this paper, we propose a method for predicting game outcomes in ranked LoL games based on players' experience with their selected champion. Using a deep neural network, we found that game outcomes can be predicted with 75.1\% accuracy after all players have selected champions, which occurs before gameplay begins. Our results have important implications for playing LoL and matchmaking. Firstly, individual champion skill plays a significant role in the outcome of a match, regardless of team composition. Secondly, even after the skill-based matchmaking, there is still a wide variance in team skill before gameplay begins. Finally, players should only play champions that they have mastered, if they want to win games.},
  isbn = {978-1-4503-8422-3},
  keywords = {League of Legends,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/MIP3P348/Do et al. - 2021 - Using Machine Learning to Predict Game Outcomes Ba.pdf}
}

@inproceedings{drachenSkillbasedDifferencesSpatiotemporal2014,
  title = {Skill-Based Differences in Spatio-Temporal Team Behaviour in Defence of the {{Ancients}} 2 ({{DotA}} 2)},
  booktitle = {2014 {{IEEE Games Media Entertainment}}},
  author = {Drachen, Anders and Yancey, Matthew and Maguire, John and Chu, Derrek and Wang, Iris Yuhui and Mahlmann, Tobias and Schubert, Matthias and Klabajan, Diego},
  year = {2014},
  month = oct,
  pages = {1--8},
  doi = {10.1109/GEM.2014.7048109},
  url = {https://ieeexplore.ieee.org/abstract/document/7048109},
  urldate = {2023-10-05},
  abstract = {Multiplayer Online Battle Arena (MOBA) games are among the most played digital games in the world. In these games, teams of players fight against each other in arena environments, and the gameplay is focussed on tactical combat. In this paper, we present three data-driven measures of spatio-temporal behaviour in Defence of the Ancients 2 (DotA 2): 1) Zone changes; 2) Distribution of team members and: 3) Time series clustering via a fuzzy approach. We present a method for obtaining accurate positional data from DotA 2. We investigate how behaviour varies across these measures as a function of the skill level of teams, using four tiers from novice to professional players. Results from three analyses indicate that spatio-temporal behaviour of MOBA teams is highly related to team skill.},
  keywords = {Dota 2,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/M4ZRY2DS/Drachen et al. - 2014 - Skill-based differences in spatio-temporal team be.pdf}
}

@article{dunnePairingSoftmaxActivation1997,
  title = {On {{The Pairing Of The Softmax Activation And Cross}}\{\vphantom\}{{Entropy Penalty Functions And The Derivation Of The Softmax Activation Function}}},
  author = {Dunne, R A and Campbell, N A},
  year = {1997},
  abstract = {It is suggested in the literature 2, 1] that there is a natural pairing between the softmax activation function and the cross\{entropy penalty function. We clarify a reason for this pairing and give an improved derivation of the softmax activation function. In addition, we empirically compare some penalty/activation function pairs.\vphantom\}},
  langid = {english},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/ATJEB5IA/Dunne und Campbell - 1997 - On The Pairing Of The Softmax Activation And Cross.pdf}
}

@inproceedings{eggertClassificationPlayerRoles2015,
  title = {Classification of {{Player Roles}} in the {{Team-Based Multi-player Game Dota}} 2},
  booktitle = {Entertainment {{Computing}} - {{ICEC}} 2015},
  author = {Eggert, Christoph and Herrlich, Marc and Smeddinck, Jan and Malaka, Rainer},
  editor = {Chorianopoulos, Konstantinos and Divitini, Monica and Baalsrud Hauge, Jannicke and Jaccheri, Letizia and Malaka, Rainer},
  year = {2015},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {112--125},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-24589-8_9},
  abstract = {Computer games are big business, which is also reflected in the growing interest in competitive gaming, the so-called electronic sports. Multi-player online battle arena games are among the most successful games in this regard. In order to execute complex team-based strategies, players take on very specific roles within a team. This paper investigates the applicability of supervised machine learning to classifying player behavior in terms of specific and commonly accepted but not formally well-defined roles within a team of players of the game Dota 2. We provide an in-depth discussion and novel approaches for constructing complex attributes from low-level data extracted from replay files. Using attribute evaluation techniques, we are able to reduce a larger set of candidate attributes down to a manageable number. Based on this resulting set of attributes, we compare and discuss the performance of a variety of supervised classification algorithms. Our results with a data set of 708 labeled players see logistic regression as the overall most stable and best performing classifier.},
  isbn = {978-3-319-24589-8},
  langid = {english},
  keywords = {Dota 2,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/PHUQSL6S/Eggert et al. - 2015 - Classification of Player Roles in the Team-Based M.pdf}
}

@article{elmanFindingStructureTime1990,
  title = {Finding {{Structure}} in {{Time}}},
  author = {Elman, Jeffrey L.},
  year = {1990},
  journal = {Cognitive Science},
  volume = {14},
  number = {2},
  pages = {179--211},
  issn = {1551-6709},
  doi = {10.1207/s15516709cog1402_1},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1207/s15516709cog1402_1},
  urldate = {2023-11-03},
  abstract = {Time underlies many interesting human behaviors. Thus, the question of how to represent time in connectionist models is very important. One approach is to represent time implicitly by its effects on processing rather than explicitly (as in a spatial representation). The current report develops a proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory. In this approach, hidden unit patterns are fed back to themselves: the internal representations which develop thus reflect task demands in the context of prior internal states. A set of simulations is reported which range from relatively simple problems (temporal version of XOR) to discovering syntactic/semantic features for words. The networks are able to learn interesting internal representations which incorporate task demands with memory demands: indeed, in this approach the notion of memory is inextricably bound up with task processing. These representations reveal a rich structure, which allows them to be highly context-dependent, while also expressing generalizations across classes of items. These representations suggest a method for representing lexical categories and the type/token distinction.},
  copyright = {{\copyright} 1990 Cognitive Science Society, Inc.},
  langid = {english},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/5LLXR4N8/Elman - 1990 - Finding Structure in Time.pdf}
}

@misc{estebanPredictingClinicalEvents2016,
  title = {Predicting {{Clinical Events}} by {{Combining Static}} and {{Dynamic Information Using Recurrent Neural Networks}}},
  author = {Esteban, Crist{\'o}bal and Staeck, Oliver and Yang, Yinchong and Tresp, Volker},
  year = {2016},
  month = nov,
  number = {arXiv:1602.02685},
  eprint = {1602.02685},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/1602.02685},
  urldate = {2023-11-28},
  abstract = {In clinical data sets we often find static information (e.g. patient gender, blood type, etc.) combined with sequences of data that are recorded during multiple hospital visits (e.g. medications prescribed, tests performed, etc.). Recurrent Neural Networks (RNNs) have proven to be very successful for modelling sequences of data in many areas of Machine Learning. In this work we present an approach based on RNNs, specifically designed for the clinical domain, that combines static and dynamic information in order to predict future events. We work with a database collected in the Charite{\textasciiacute} Hospital in Berlin that contains complete information concerning patients that underwent a kidney transplantation. After the transplantation three main endpoints can occur: rejection of the kidney, loss of the kidney and death of the patient. Our goal is to predict, based on information recorded in the Electronic Health Record of each patient, whether any of those endpoints will occur within the next six or twelve months after each visit to the clinic. We compared different types of RNNs that we developed for this work, with a model based on a Feedforward Neural Network and a Logistic Regression model. We found that the RNN that we developed based on Gated Recurrent Units provides the best performance for this task. We also used the same models for a second task, i.e., next event prediction, and found that here the model based on a Feedforward Neural Network outperformed the other models. Our hypothesis is that long-term dependencies are not as relevant in this task.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/DF2NVVYX/Esteban et al. - 2016 - Predicting Clinical Events by Combining Static and.pdf}
}

@article{fangSurveyResearchRNNBased2021,
  title = {Survey on {{Research}} of {{RNN-Based Spatio-Temporal Sequence Prediction Algorithms}}},
  author = {Fang, Wei and Chen, Yupeng and Xue, Qiongying},
  year = {2021},
  journal = {Journal on Big Data},
  volume = {3},
  number = {3},
  pages = {97--110},
  issn = {2579-0056},
  doi = {10.32604/jbd.2021.016993},
  url = {https://www.techscience.com/jbd/v3n3/45671},
  urldate = {2023-11-03},
  abstract = {In the past few years, deep learning has developed rapidly, and many researchers try to combine their subjects with deep learning. The algorithm based on Recurrent Neural Network (RNN) has been successfully applied in the fields of weather forecasting, stock forecasting, action recognition, etc. because of its excellent performance in processing Spatio-temporal sequence data. Among them, algorithms based on LSTM and GRU have developed most rapidly because of their good design. This paper reviews the RNN-based Spatiotemporal sequence prediction algorithm, introduces the development history of RNN and the common application directions of the Spatio-temporal sequence prediction, and includes precipitation nowcasting algorithms and traffic flow forecasting algorithms. At the same time, it also compares the advantages and disadvantages, and innovations of each algorithm. The purpose of this article is to give readers a clear understanding of solutions to such problems. Finally, it prospects the future development of RNN in the Spatio-temporal sequence prediction algorithm.},
  langid = {english},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/TC2LZJBB/Fang et al. - 2021 - Survey on Research of RNN-Based Spatio-Temporal Se.pdf}
}

@misc{fearless-ad5644HighlightMyLOL2024,
  type = {Reddit {{Post}}},
  title = {Highlight of My {{LOL}} Career},
  author = {{Fearless-Ad5644}},
  year = {2024},
  month = feb,
  journal = {r/leagueoflegends},
  url = {www.reddit.com/r/leagueoflegends/comments/1aup3o3/highlight_of_my_lol_career/},
  urldate = {2024-03-06},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/ZGLZ9BDH/highlight_of_my_lol_career.html}
}

@article{friedmanGreedyFunctionApproximation2001,
  title = {Greedy {{Function Approximation}}: {{A Gradient Boosting Machine}}},
  shorttitle = {Greedy {{Function Approximation}}},
  author = {Friedman, Jerome H.},
  year = {2001},
  journal = {The Annals of Statistics},
  volume = {29},
  number = {5},
  eprint = {2699986},
  eprinttype = {jstor},
  pages = {1189--1232},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0090-5364},
  url = {https://www.jstor.org/stable/2699986},
  urldate = {2024-03-06},
  abstract = {Function estimation/approximation is viewed from the perspective of numerical optimization in function space, rather than parameter space. A connection is made between stagewise additive expansions and steepest-descent minimization. A general gradient descent "boosting" paradigm is developed for additive expansions based on any fitting criterion. Specific algorithms are presented for least-squares, least absolute deviation, and Huber-M loss functions for regression, and multiclass logistic likelihood for classification. Special enhancements are derived for the particular case where the individual additive components are regression trees, and tools for interpreting such "TreeBoost" models are presented. Gradient boosting of regression trees produces competitive, highly robust, interpretable procedures for both regression and classification, especially appropriate for mining less than clean data. Connections between this approach and the boosting methods of Freund and Shapire and Friedman, Hastie and Tibshirani are discussed.},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/AT636YKI/Friedman - 2001 - Greedy Function Approximation A Gradient Boosting.pdf}
}

@article{gaoParallelFeatureFusion2022,
  title = {A {{Parallel Feature Fusion Network Combining GRU}} and {{CNN}} for {{Motor Imagery EEG Decoding}}},
  author = {Gao, Siheng and Yang, Jun and Shen, Tao and Jiang, Wen},
  year = {2022},
  month = sep,
  journal = {Brain Sciences},
  volume = {12},
  number = {9},
  pages = {1233},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2076-3425},
  doi = {10.3390/brainsci12091233},
  url = {https://www.mdpi.com/2076-3425/12/9/1233},
  urldate = {2023-11-28},
  abstract = {In recent years, deep-learning-based motor imagery (MI) electroencephalography (EEG) decoding methods have shown great potential in the field of the brain--computer interface (BCI). The existing literature is relatively mature in decoding methods for two classes of MI tasks. However, with the increase in MI task classes, decoding studies for four classes of MI tasks need to be further explored. In addition, it is difficult to obtain large-scale EEG datasets. When the training data are limited, deep-learning-based decoding models are prone to problems such as overfitting and poor robustness. In this study, we design a data augmentation method for MI-EEG. The original EEG is slid along the time axis and reconstructed to expand the size of the dataset. Second, we combine the gated recurrent unit (GRU) and convolutional neural network (CNN) to construct a parallel-structured feature fusion network to decode four classes of MI tasks. The parallel structure can avoid temporal, frequency and spatial features interfering with each other. Experimenting on the well-known four-class MI dataset BCI Competition IV 2a shows a global average classification accuracy of 80.7\% and a kappa value of 0.74. The proposed method improves the robustness of deep learning to decode small-scale EEG datasets and alleviates the overfitting phenomenon caused by insufficient data. The method can be applied to BCI systems with a small amount of daily recorded data.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/VMB5JNC5/Gao et al. - 2022 - A Parallel Feature Fusion Network Combining GRU an.pdf}
}

@misc{GGBestLeague,
  title = {U {{GG}}: {{The Best League}} of {{Legends Builds LoL Build Champion Probuilds LoL Runes Tier List Counters Guides}}},
  shorttitle = {U {{GG}}},
  url = {https://u.gg},
  urldate = {2023-12-15},
  abstract = {Best Builds from the Best Data. Riot-approved U.GG provides the best League of Legends builds, LoL runes, Probuilds, Tier List, Counters, and more.},
  langid = {english},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/7GLXVIPB/u.gg.html}
}

@inproceedings{gordon-rodriguezUsesAbusesCrossEntropy2020,
  title = {Uses and {{Abuses}} of the {{Cross-Entropy Loss}}: {{Case Studies}} in {{Modern Deep Learning}}},
  shorttitle = {Uses and {{Abuses}} of the {{Cross-Entropy Loss}}},
  author = {{Gordon-Rodriguez}, Elliott and {Loaiza-Ganem}, Gabriel and Pleiss, Geoff and Cunningham, John Patrick},
  year = {2020},
  month = feb,
  pages = {1--10},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v137/gordon-rodriguez20a.html},
  urldate = {2023-11-02},
  abstract = {Modern deep learning is primarily an experimental science, in which empirical advances occasionally come at the expense of probabilistic rigor. Here we focus on one such example; namely the use of the categorical cross-entropy loss to model data that is not strictly categorical, but rather takes values on the simplex. This practice is standard in neural network architectures with label smoothing and actor-mimic reinforcement learning, amongst others. Drawing on the recently discovered continuous-categorical distribution, we propose probabilistically-inspired alternatives to these models, providing an approach that is more principled and theoretically appealing. Through careful experimentation, including an ablation study, we identify the potential for outperformance in these models, thereby highlighting the importance of a proper probabilistic treatment, as well as illustrating some of the failure modes thereof.},
  langid = {english},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/93N5Y4I8/Gordon-Rodriguez et al. - 2020 - Uses and Abuses of the Cross-Entropy Loss Case St.pdf;/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/UH5JPJGP/Gordon-Rodriguez et al. - 2020 - Uses and Abuses of the Cross-Entropy Loss Case St.pdf}
}

@misc{goughLeagueLegendsChampionships,
  title = {League of {{Legends}} Championships Viewers 2022},
  author = {Gough, Christina},
  journal = {Statista},
  url = {https://www.statista.com/statistics/518126/league-of-legends-championship-viewers/},
  urldate = {2023-12-09},
  abstract = {The League of Legends World Championship is an annual tournament hosted by Riot Games which pits the best League of Legends eSports players against each other for the chance to win a large amount of money.},
  langid = {english},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/8EUC32GX/league-of-legends-championship-viewers.html}
}

@phdthesis{gravesSupervisedSequenceLabelling2012,
  title = {Supervised {{Sequence Labelling}} with {{Recurrent Neural Networks}}},
  author = {Graves, Alex},
  year = {2012},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-24797-2},
  url = {https://link.springer.com/10.1007/978-3-642-24797-2},
  urldate = {2023-12-21},
  langid = {english},
  school = {Springer Berlin Heidelberg},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/LH63U9IS/Graves - 2012 - Supervised Sequence Labelling with Recurrent Neura.pdf}
}

@article{greffLSTMSearchSpace2017,
  title = {{{LSTM}}: {{A Search Space Odyssey}}},
  shorttitle = {{{LSTM}}},
  author = {Greff, Klaus and Srivastava, Rupesh K. and Koutn{\'i}k, Jan and Steunebrink, Bas R. and Schmidhuber, J{\"u}rgen},
  year = {2017},
  month = oct,
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  volume = {28},
  number = {10},
  pages = {2222--2232},
  issn = {2162-2388},
  doi = {10.1109/TNNLS.2016.2582924},
  url = {https://ieeexplore.ieee.org/abstract/document/7508408?casa_token=wJar7bnjMcIAAAAA:_R37S3pOcLsctz574U-qLv5J7Ens-RNo7yJ-Kc0Vw_9aMA2cML0N3BlrrayKiWfdcL4gK5ZPJWg},
  urldate = {2023-11-01},
  abstract = {Several variants of the long short-term memory (LSTM) architecture for recurrent neural networks have been proposed since its inception in 1995. In recent years, these networks have become the state-of-the-art models for a variety of machine learning problems. This has led to a renewed interest in understanding the role and utility of various computational components of typical LSTM variants. In this paper, we present the first large-scale analysis of eight LSTM variants on three representative tasks: speech recognition, handwriting recognition, and polyphonic music modeling. The hyperparameters of all LSTM variants for each task were optimized separately using random search, and their importance was assessed using the powerful functional ANalysis Of VAriance framework. In total, we summarize the results of 5400 experimental runs ( {\textbackslash}approx 15 years of CPU time), which makes our study the largest of its kind on LSTM networks. Our results show that none of the variants can improve upon the standard LSTM architecture significantly, and demonstrate the forget gate and the output activation function to be its most critical components. We further observe that the studied hyperparameters are virtually independent and derive guidelines for their efficient adjustment.},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/YY6PEKEQ/Greff et al. - 2017 - LSTM A Search Space Odyssey.pdf}
}

@article{grosseLecture15Exploding,
  title = {Lecture 15: {{Exploding}} and {{Vanishing Gradients}}},
  author = {Grosse, Roger},
  langid = {english},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/4SLMAHYV/Grosse - Lecture 15 Exploding and Vanishing Gradients.pdf}
}

@article{guyonIntroductionVariableFeature2003,
  title = {An {{Introduction}} to {{Variable}} and {{Feature Selection}}},
  author = {Guyon, Isabelle and Elisseeff, Andre},
  year = {2003},
  journal = {Journal of machine learning research},
  volume = {3},
  pages = {1157--1182},
  abstract = {Variable and feature selection have become the focus of much research in areas of application for which datasets with tens or hundreds of thousands of variables are available. These areas include text processing of internet documents, gene expression array analysis, and combinatorial chemistry. The objective of variable selection is three-fold: improving the prediction performance of the predictors, providing faster and more cost-effective predictors, and providing a better understanding of the underlying process that generated the data. The contributions of this special issue cover a wide range of aspects of such problems: providing a better definition of the objective function, feature construction, feature ranking, multivariate feature selection, efficient search methods, and feature validity assessment methods.},
  langid = {english},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/ZEBH9EEP/Guyon und Elisseeff - An Introduction to Variable and Feature Selection.pdf}
}

@phdthesis{hallCorrelationbasedFeatureSelection1999,
  type = {Thesis},
  title = {Correlation-Based Feature Selection for Machine Learning},
  author = {Hall, Mark A.},
  year = {1999},
  url = {https://researchcommons.waikato.ac.nz/handle/10289/15043},
  urldate = {2023-10-05},
  abstract = {A central problem in machine learning is identifying a representative set of features from which to construct a classification model for a particular task. This thesis addresses the problem of feature selection for machine learning through a correlation based approach. The central hypothesis is that good feature sets contain features that are highly correlated with the class, yet uncorrelated with each other. A feature evaluation formula, based on ideas from test theory, provides an operational definition of this hypothesis. CFS (Correlation based Feature Selection) is an algorithm that couples this evaluation formula with an appropriate correlation measure and a heuristic search strategy.     CFS was evaluated by experiments on artificial and natural datasets. Three machine learning algorithms were used: C4.5 (a decision tree learner), IB 1 (an instance based learner), and naive Bayes. Experiments on artificial datasets showed that CFS quickly identifies and screens irrelevant, redundant, and noisy features, and identifies relevant features as long as their relevance does not strongly depend on other features. On natural domains, CFS typically eliminated well over half the features. In most cases, classification accuracy using the reduced feature set equaled or bettered accuracy using the complete feature set. Feature selection degraded machine learning performance in cases where some features were eliminated which were highly predictive of very small areas of the instance space.     Further experiments compared CFS with a wrapper - a well known approach to feature selection that employs the target learning algorithm to evaluate feature sets. In many cases CFS gave comparable results to the wrapper, and in general, outperformed the wrapper on small datasets. CFS executes many times faster than the wrapper, which allows it to scale to larger datasets.    Two methods of extending CFS to handle feature interaction are presented and experimentally evaluated. The first considers pairs of features and the second incorporates feature weights calculated by the RELIEF algorithm. Experiments on artificial domains showed that both methods were able to identify interacting features. On natural domains, the pairwise method gave more reliable results than using weights provided by RELIEF.},
  langid = {english},
  school = {The University of Waikato},
  keywords = {notion},
  annotation = {Accepted: 2022-08-18T02:09:56Z},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/Q4GTGMYW/Hall - 1999 - Correlation-based feature selection for machine le.pdf}
}

@inproceedings{haymanMcCullochPittsModel1999,
  title = {The {{McCulloch-Pitts}} Model},
  booktitle = {{{IJCNN}}'99. {{International Joint Conference}} on {{Neural Networks}}. {{Proceedings}} ({{Cat}}. {{No}}.{{99CH36339}})},
  author = {Hayman, S.},
  year = {1999},
  month = jul,
  volume = {6},
  pages = {4438-4439 vol.6},
  issn = {1098-7576},
  doi = {10.1109/IJCNN.1999.830886},
  url = {https://ieeexplore.ieee.org/abstract/document/830886?casa_token=ivTNFXKoCoIAAAAA:dbqsgVQhqCOH7LcbBz6ThI9ruzT6MKKc-G8P3jEvbnWZIk7ml5ZH9D0EqeSF8f5fvwRc0o7sa6c},
  urldate = {2023-11-01},
  abstract = {Neural net theory is founded on the model of McCulloch and Pitts (1943). The article discusses the principles of the model and the associated algebra. The adaptability comes from representing the synaptic action by a variable weight which determines the degree to which a neuron should 'take notice' of firing signals that take place at the synapse concerned. The neuron is thought to take firing signals at all its synapses into account by summing their effects, both excitatory and inhibitory, and thereby determining whether it should or should not fire. The effect of a synapse is represented by a weight in the range -1 to 1. The effect on a neuron of any particular synapse is the weight if the neuron fire, 0 if not, and the product of the weight and another number if it be not known whether the neuron fires.},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/HGKKDPJ7/Hayman - 1999 - The McCulloch-Pitts model.pdf}
}

@article{hewamalageRecurrentNeuralNetworks2021,
  title = {Recurrent {{Neural Networks}} for {{Time Series Forecasting}}: {{Current}} Status and Future Directions},
  shorttitle = {Recurrent {{Neural Networks}} for {{Time Series Forecasting}}},
  author = {Hewamalage, Hansika and Bergmeir, Christoph and Bandara, Kasun},
  year = {2021},
  month = jan,
  journal = {International Journal of Forecasting},
  volume = {37},
  number = {1},
  pages = {388--427},
  issn = {0169-2070},
  doi = {10.1016/j.ijforecast.2020.06.008},
  url = {https://www.sciencedirect.com/science/article/pii/S0169207020300996},
  urldate = {2023-11-03},
  abstract = {Recurrent Neural Networks (RNNs) have become competitive forecasting methods, as most notably shown in the winning method of the recent M4 competition. However, established statistical models such as exponential smoothing (ETS) and the autoregressive integrated moving average (ARIMA) gain their popularity not only from their high accuracy, but also because they are suitable for non-expert users in that they are robust, efficient, and automatic. In these areas, RNNs have still a long way to go. We present an extensive empirical study and an open-source software framework of existing RNN architectures for forecasting, and we develop guidelines and best practices for their use. For example, we conclude that RNNs are capable of modelling seasonality directly if the series in the dataset possess homogeneous seasonal patterns; otherwise, we recommend a deseasonalisation step. Comparisons against ETS and ARIMA demonstrate that (semi-) automatic RNN models are not silver bullets, but they are nevertheless competitive alternatives in many situations.},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/LHITQKAW/Hewamalage et al. - 2021 - Recurrent Neural Networks for Time Series Forecast.pdf}
}

@article{hitar-garciaMachineLearningMethods2023,
  title = {Machine {{Learning Methods}} for {{Predicting League}} of {{Legends Game Outcome}}},
  author = {{Hitar-Garc{\'i}a}, Juan Agust{\'i}n and {Mor{\'a}n-Fern{\'a}ndez}, Laura and {Bol{\'o}n-Canedo}, Ver{\'o}nica},
  year = {2023},
  month = jun,
  journal = {IEEE Transactions on Games},
  volume = {15},
  number = {2},
  pages = {171--181},
  issn = {2475-1510},
  doi = {10.1109/TG.2022.3153086},
  url = {https://ieeexplore.ieee.org/abstract/document/9720122},
  urldate = {2023-10-05},
  abstract = {The video game League of Legends has several professional leagues and tournaments that offer prizes reaching several million dollars, making it one of the most followed games in the Esports scene. This article addresses the prediction of the winning team in professional matches of the game, using only pregame data. We propose to improve the accuracy of the models trained with the features offered by the game application programming interface (API). To this end, new features are built to collect interesting information, such as the skills of a player handling a certain champion, the synergies between players of the same team or the ability of a player to beat another player. Then, we perform feature selection and train different classification algorithms aiming at obtaining the best model. Experimental results show classification accuracy above 0.70, which is comparable to the results of other proposals presented in the literature, but with the added benefit of using few samples and not requiring the use of external sources to collect additional statistics.},
  keywords = {League of Legends,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/TNHQVGCX/Hitar-García et al. - 2023 - Machine Learning Methods for Predicting League of .pdf}
}

@article{hochreiterLongShortTermMemory1997,
  title = {Long {{Short-Term Memory}}},
  author = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  year = {1997},
  month = nov,
  journal = {Neural Computation},
  volume = {9},
  number = {8},
  pages = {1735--1780},
  issn = {0899-7667},
  doi = {10.1162/neco.1997.9.8.1735},
  url = {https://ieeexplore.ieee.org/abstract/document/6795963},
  urldate = {2023-11-01},
  abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/PIHAK9ST/lstm.pdf}
}

@article{hochreiterVanishingGradientProblem1998,
  title = {The {{Vanishing Gradient Problem During Learning Recurrent Neural Nets}} and {{Problem Solutions}}},
  author = {Hochreiter, Sepp},
  year = {1998},
  month = apr,
  journal = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  volume = {06},
  number = {02},
  pages = {107--116},
  issn = {0218-4885, 1793-6411},
  doi = {10.1142/S0218488598000094},
  url = {https://www.worldscientific.com/doi/abs/10.1142/S0218488598000094},
  urldate = {2023-12-22},
  abstract = {Recurrent nets are in principle capable to store past inputs to produce the currently desired output. Because of this property recurrent nets are used in time series prediction and process control. Practical applications involve temporal dependencies spanning many time steps, e.g. between relevant inputs and desired outputs. In this case, however, gradient based learning methods take too much time. The extremely increased learning time arises because the error vanishes as it gets propagated back. In this article the de-caying error flow is theoretically analyzed. Then methods trying to overcome vanishing gradients are briefly discussed. Finally, experiments comparing conventional algorithms and alternative methods are presented. With advanced methods long time lag problems can be solved in reasonable time.},
  langid = {english},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/LS9TYJCH/Hochreiter - 1998 - The Vanishing Gradient Problem During Learning Rec.pdf}
}

@misc{hodgeWinPredictionEsports2017,
  title = {Win {{Prediction}} in {{Esports}}: {{Mixed-Rank Match Prediction}} in {{Multi-player Online Battle Arena Games}}},
  shorttitle = {Win {{Prediction}} in {{Esports}}},
  author = {Hodge, Victoria and Devlin, Sam and Sephton, Nick and Block, Florian and Drachen, Anders and Cowling, Peter},
  year = {2017},
  month = nov,
  number = {arXiv:1711.06498},
  eprint = {1711.06498},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/1711.06498},
  urldate = {2023-09-25},
  abstract = {Esports has emerged as a popular genre for players as well as spectators, supporting a global entertainment industry. Esports analytics has evolved to address the requirement for data-driven feedback, and is focused on cyber-athlete evaluation, strategy and prediction. Towards the latter, previous work has used match data from a variety of player ranks from hobbyist to professional players. However, professional players have been shown to behave differently than lower ranked players. Given the comparatively limited supply of professional data, a key question is thus whether mixed-rank match datasets can be used to create data-driven models which predict winners in professional matches and provide a simple in-game statistic for viewers and broadcasters. Here we show that, although there is a slightly reduced accuracy, mixed-rank datasets can be used to predict the outcome of professional matches, with suitably optimized configurations.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Dota 2,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/ZCSJJK2E/Hodge et al. - 2017 - Win Prediction in Esports Mixed-Rank Match Predic.pdf}
}

@article{hodgeWinPredictionMultiplayer2021,
  title = {Win {{Prediction}} in {{Multiplayer Esports}}: {{Live Professional Match Prediction}}},
  shorttitle = {Win {{Prediction}} in {{Multiplayer Esports}}},
  author = {Hodge, Victoria J. and Devlin, Sam and Sephton, Nick and Block, Florian and Cowling, Peter I. and Drachen, Anders},
  year = {2021},
  month = dec,
  journal = {IEEE Transactions on Games},
  volume = {13},
  number = {4},
  pages = {368--379},
  issn = {2475-1510},
  doi = {10.1109/TG.2019.2948469},
  url = {https://ieeexplore.ieee.org/abstract/document/8906016},
  urldate = {2023-09-25},
  abstract = {Esports are competitive videogames watched by audiences. Most esports generate detailed data for each match that are publicly available. Esports analytics research is focused on predicting match outcomes. Previous research has emphasized prematch prediction and used data from amateur games, which are more easily available than those from professional level. However, the commercial value of win prediction exists at the professional level. Furthermore, predicting real-time data is unexplored, as is its potential for informing audiences. Here, we present the first comprehensive case study on live win prediction in a professional esport. We provide a literature review for win prediction in a multiplayer online battle arena (MOBA) esport. This article evaluates the first professional-level prediction models for live DotA 2 matches, one of the most popular MOBA games, and trials it at a major international esports tournament. Using standard machine learning models, feature engineering and optimization, our model is up to 85\% accurate after 5 min of gameplay. Our analyses highlight the need for algorithm evaluation and optimization. Finally, we present implications for the esports/game analytics domains, describe commercial opportunities and practical challenges, and propose a set of evaluation criteria for research on esports win prediction.},
  keywords = {Dota 2,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/MEENXXI3/Hodge et al. - 2021 - Win Prediction in Multiplayer Esports Live Profes.pdf}
}

@article{hornikMultilayerFeedforwardNetworks1989,
  title = {Multilayer Feedforward Networks Are Universal Approximators},
  author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  year = {1989},
  month = jan,
  journal = {Neural Networks},
  volume = {2},
  number = {5},
  pages = {359--366},
  issn = {08936080},
  doi = {10.1016/0893-6080(89)90020-8},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0893608089900208},
  urldate = {2023-11-02},
  abstract = {This paper rigorously establishes thut standard rnultiluyer feedforward networks with as f\&v us one hidden layer using arbitrary squashing functions ure capable of upproximating uny Bore1 measurable function from one finite dimensional space to another to any desired degree of uccuracy, provided sujficirntly muny hidden units are available. In this sense, multilayer feedforward networks are u class of universul rlpproximators.},
  langid = {english},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/AGQTPNP4/Hornik et al. - 1989 - Multilayer feedforward networks are universal appr.pdf}
}

@article{horvatUseMachineLearning2020,
  title = {The Use of Machine Learning in Sport Outcome Prediction: {{A}} Review},
  shorttitle = {The Use of Machine Learning in Sport Outcome Prediction},
  author = {Horvat, Tomislav and Job, Josip},
  year = {2020},
  journal = {WIREs Data Mining and Knowledge Discovery},
  volume = {10},
  number = {5},
  pages = {e1380},
  issn = {1942-4795},
  doi = {10.1002/widm.1380},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/widm.1380},
  urldate = {2024-01-12},
  abstract = {The increase in the volume of structured and unstructured data related to more than just sport events leads to the development and increased use of techniques that extract information and employ machine-learning algorithms in predicting process outcomes based on input but not necessarily output data. Taking sports into consideration, predicting outcomes, and extracting valuable information has become appealing not only to sports workers but also to the wider audience, particularly in the areas of team management and sports betting. The aim of this article is to review the existing machine learning (ML) algorithms in predicting sport outcomes. Over 100 papers were analyzed and only some of these papers were taken into consideration. Almost all of the analyzed papers use some sort of feature selection and feature extraction, most often prior to using the machine-learning algorithm. As an evaluation method of ML algorithms, researchers, in most cases, use data segmentation with data being chronologically distributed. In addition to data segmentation, researchers also use the k-cross-evaluation method. Sport predictions are usually treated as a classification problem with one class being predicted and rare cases being predicted as numerical values. Mostly used ML models are neural networks using data segmentation. This article is categorized under: Technologies {$>$} Machine Learning Technologies {$>$} Prediction},
  copyright = {{\copyright} 2020 Wiley Periodicals LLC.},
  langid = {english},
  keywords = {learning algorithms,machine learning,outcome prediction,sport},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/X7CZIJWH/Horvat und Job - 2020 - The use of machine learning in sport outcome predi.pdf;/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/6NW8MMUB/widm.html}
}

@inproceedings{irieLSTMGRUHighway2016,
  title = {{{LSTM}}, {{GRU}}, {{Highway}} and a {{Bit}} of {{Attention}}: {{An Empirical Overview}} for {{Language Modeling}} in {{Speech Recognition}}},
  shorttitle = {{{LSTM}}, {{GRU}}, {{Highway}} and a {{Bit}} of {{Attention}}},
  booktitle = {Interspeech 2016},
  author = {Irie, Kazuki and T{\"u}ske, Zolt{\'a}n and Alkhouli, Tamer and Schl{\"u}ter, Ralf and Ney, Hermann},
  year = {2016},
  month = sep,
  pages = {3519--3523},
  publisher = {{ISCA}},
  doi = {10.21437/Interspeech.2016-491},
  url = {https://www.isca-speech.org/archive/interspeech_2016/irie16_interspeech.html},
  urldate = {2023-11-07},
  abstract = {Popularized by the long short-term memory (LSTM), multiplicative gates have become a standard means to design artificial neural networks with intentionally organized information flow. Notable examples of such architectures include gated recurrent units (GRU) and highway networks. In this work, we first focus on the evaluation of each of the classical gated architectures for language modeling for large vocabulary speech recognition. Namely, we evaluate the highway network, lateral network, LSTM and GRU. Furthermore, the motivation underlying the highway network also applies to LSTM and GRU. An extension specific to the LSTM has been recently proposed with an additional highway connection between the memory cells of adjacent LSTM layers. In contrast, we investigate an approach which can be used with both LSTM and GRU: a highway network in which the LSTM or GRU is used as the transformation function. We found that the highway connections enable both standalone feedforward and recurrent neural language models to benefit better from the deep structure and provide a slight improvement of recognition accuracy after interpolation with count models. To complete the overview, we include our initial investigations on the use of the attention mechanism for learning word triggers.},
  langid = {english},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/BLUSQ6UD/Irie et al. - 2016 - LSTM, GRU, Highway and a Bit of Attention An Empi.pdf}
}

@book{janssonNeuralNetworksStandardizing2022,
  title = {Neural {{Networks}} for {{Standardizing Ratings}} in {{League}} of {{Legends}}},
  author = {Jansson, Andr{\'e}as and Karlsson, Erik},
  year = {2022},
  url = {https://urn.kb.se/resolve?urn=urn:nbn:se:oru:diva-102668},
  urldate = {2023-12-09},
  abstract = {DiVA portal is a finding tool for research publications and student theses written at the following 50 universities and research institutions.},
  langid = {english},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/LLJ4N74X/Jansson und Karlsson - 2022 - Neural Networks for Standardizing Ratings inLeague.pdf}
}

@book{johanssonResultPredictionMining2015,
  title = {Result {{Prediction}} by {{Mining Replays}} in {{Dota}} 2},
  author = {Johansson, Filip and Wikstr{\"o}m, Jesper},
  year = {2015},
  url = {https://urn.kb.se/resolve?urn=urn:nbn:se:bth-2288},
  urldate = {2023-10-05},
  abstract = {DiVA portal is a finding tool for research publications and student theses written at the following 50 universities and research institutions.},
  langid = {english},
  keywords = {Dota 2,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/Y6MNG3CQ/Johansson und Wikström - 2015 - Result Prediction by Mining Replays in Dota 2.pdf}
}

@inproceedings{jovicReviewFeatureSelection2015,
  title = {A Review of Feature Selection Methods with Applications},
  booktitle = {2015 38th {{International Convention}} on {{Information}} and {{Communication Technology}}, {{Electronics}} and {{Microelectronics}} ({{MIPRO}})},
  author = {Jovic, A. and Brkic, K. and Bogunovic, N.},
  year = {2015},
  month = may,
  pages = {1200--1205},
  publisher = {{IEEE}},
  address = {{Opatija, Croatia}},
  doi = {10.1109/MIPRO.2015.7160458},
  url = {http://ieeexplore.ieee.org/document/7160458/},
  urldate = {2023-12-01},
  abstract = {Feature selection (FS) methods can be used in data pre-processing to achieve efficient data reduction. This is useful for finding accurate data models. Since exhaustive search for optimal feature subset is infeasible in most cases, many search strategies have been proposed in literature. The usual applications of FS are in classification, clustering, and regression tasks. This review considers most of the commonly used FS techniques. Particular emphasis is on the application aspects. In addition to standard filter, wrapper, and embedded methods, we also provide insight into FS for recent hybrid approaches and other advanced topics.},
  isbn = {978-953-233-082-3},
  langid = {english},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/YTW4R424/Jovic et al. - 2015 - A review of feature selection methods with applica.pdf}
}

@inproceedings{katonaTimeDeathPrediction2019,
  title = {Time to {{Die}}: {{Death Prediction}} in {{Dota}} 2 Using {{Deep Learning}}},
  shorttitle = {Time to {{Die}}},
  booktitle = {2019 {{IEEE Conference}} on {{Games}} ({{CoG}})},
  author = {Katona, Adam and Spick, Ryan and Hodge, Victoria J. and Demediuk, Simon and Block, Florian and Drachen, Anders and Walker, James Alfred},
  year = {2019},
  month = aug,
  pages = {1--8},
  issn = {2325-4289},
  doi = {10.1109/CIG.2019.8847997},
  url = {https://ieeexplore.ieee.org/abstract/document/8847997?casa_token=BdsiAxBSGpUAAAAA:cCCR9yP_2dKCinpYdBHkFsFcBBlZeP8sYlDFVGPX3EOP4zWrlxAnZqJCY-nkDRR9eqtkVxR3Hg},
  urldate = {2023-09-25},
  abstract = {Esports have become major international sports with hundreds of millions of spectators. Esports games generate massive amounts of telemetry data. Using these to predict the outcome of esports matches has received considerable attention, but micro-predictions, which seek to predict events inside a match, is as yet unknown territory. Micro-predictions are however of perennial interest across esports commentators and audience, because they provide the ability to observe events that might otherwise be missed: esports games are highly complex with fast-moving action where the balance of a game can change in the span of seconds, and where events can happen in multiple areas of the playing field at the same time. Such events can happen rapidly, and it is easy for commentators and viewers alike to miss an event and only observe the following impact of events. In Dota 2, a player hero being killed by the opposing team is a key event of interest to commentators and audience. We present a deep learning network with shared weights which provides accurate death predictions within a five-second window. The network is trained on a vast selection of Dota 2 gameplay features and professional/semi-professional level match dataset. Even though death events are rare within a game (1\% of the data), the model achieves 0.377 precision with 0.725 recall on test data when prompted to predict which of any of the 10 players of either team will die within 5 seconds. An example of the system applied to a Dota 2 match is presented. This model enables real-time micro-predictions of kills in Dota 2, one of the most played esports titles in the world, giving commentators and viewers time to move their attention to these key events.},
  keywords = {Dota 2,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/C5JXRAR4/Katona et al. - 2019 - Time to Die Death Prediction in Dota 2 using Deep.pdf}
}

@inproceedings{kaurReviewDeepLearning2019,
  title = {A {{Review}} of {{Deep Learning}} with {{Recurrent Neural Network}}},
  booktitle = {2019 {{International Conference}} on {{Smart Systems}} and {{Inventive Technology}} ({{ICSSIT}})},
  author = {Kaur, Manjot and Mohta, Aakash},
  year = {2019},
  month = nov,
  pages = {460--465},
  doi = {10.1109/ICSSIT46314.2019.8987837},
  url = {https://ieeexplore.ieee.org/document/8987837?denied=},
  urldate = {2023-11-05},
  abstract = {Recurrent Neural Network (RNN) is a deep learning model that uses the concept of supervised learning. Deep learning belongs to the family of machine learning. It is also called hierarchical learning or deep structured learning. The classic machine learning algorithms are definite, while the deep learning algorithms follow a chain of command. Deep learning has the capability to deal with more complex neural networks and it mainly deals with sequential data. Recurrent networks can process examples one at a time, preserving an element, that reflects over a long period of time.},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/7RB5IA59/Kaur und Mohta - 2019 - A Review of Deep Learning with Recurrent Neural Ne.pdf}
}

@inproceedings{kimConfidenceCalibratedMOBAGame2020,
  title = {A {{Confidence-Calibrated MOBA Game Winner Predictor}}},
  booktitle = {2020 {{IEEE Conference}} on {{Games}} ({{CoG}})},
  author = {Kim, Dong-Hee and Lee, Changwoo and Chung, Ki-Seok},
  year = {2020},
  month = aug,
  pages = {622--625},
  issn = {2325-4289},
  doi = {10.1109/CoG47356.2020.9231878},
  url = {https://ieeexplore.ieee.org/document/9231878},
  urldate = {2024-01-10},
  abstract = {In this paper, we propose a confidence-calibration method for predicting the winner of a famous multiplayer online battle arena (MOBA) game, League of Legends. In MOBA games, the dataset may contain a large amount of input-dependent noise; not all of such noise is observable. Hence, it is desirable to attempt a confidence-calibrated prediction. Unfortunately, most existing confidence calibration methods are pertaining to image and document classification tasks where consideration on uncertainty is not crucial. In this paper, we propose a novel calibration method that takes data uncertainty into consideration. The proposed method achieves an outstanding expected calibration error (ECE) (0.57\%) mainly owing to data uncertainty consideration, compared to a conventional temperature scaling method of which ECE value is 1.11\%.},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/K4KRCP9K/Kim et al. - 2020 - A Confidence-Calibrated MOBA Game Winner Predictor.pdf;/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/LHHQ8DL7/9231878.html}
}

@article{kimModelingLongtermHuman2017,
  title = {Modeling Long-Term Human Activeness Using Recurrent Neural Networks for Biometric Data},
  author = {Kim, Zae Myung and Oh, Hyung Rai and Kim, Han-Gyu and Lim, Chae-Gyun and Oh, Kyo-Joong and Choi, Ho-Jin},
  year = {2017},
  month = may,
  journal = {BMC Medical Informatics and Decision Making},
  volume = {17},
  doi = {10.1186/s12911-017-0453-1},
  abstract = {Background With the invention of fitness trackers, it has been possible to continuously monitor a user's biometric data such as heart rates, number of footsteps taken, and amount of calories burned. This paper names the time series of these three types of biometric data, the user's ``activeness'', and investigates the feasibility in modeling and predicting the long-term activeness of the user. Methods The dataset used in this study consisted of several months of biometric time-series data gathered by seven users independently. Four recurrent neural network (RNN) architectures--as well as a deep neural network and a simple regression model--were proposed to investigate the performance on predicting the activeness of the user under various length-related hyper-parameter settings. In addition, the learned model was tested to predict the time period when the user's activeness falls below a certain threshold. Results A preliminary experimental result shows that each type of activeness data exhibited a short-term autocorrelation; and among the three types of data, the consumed calories and the number of footsteps were positively correlated, while the heart rate data showed almost no correlation with neither of them. It is probably due to this characteristic of the dataset that although the RNN models produced the best results on modeling the user's activeness, the difference was marginal; and other baseline models, especially the linear regression model, performed quite admirably as well. Further experimental results show that it is feasible to predict a user's future activeness with precision, for example, a trained RNN model could predict--with the precision of 84\%--when the user would be less active within the next hour given the latest 15 min of his activeness data. Conclusions This paper defines and investigates the notion of a user's ``activeness'', and shows that forecasting the long-term activeness of the user is indeed possible. Such information can be utilized by a health-related application to proactively recommend suitable events or services to the user.},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/Z4FLGST5/Kim et al. - 2017 - Modeling long-term human activeness using recurren.pdf}
}

@inproceedings{kimWhatMakesStrong2017,
  title = {What Makes a Strong Team? {{Using}} Collective Intelligence to Predict Team Performance in {{League}} of {{Legends}}},
  shorttitle = {What Makes a Strong Team?},
  booktitle = {Proceedings of the 2017 {{ACM}} Conference on Computer Supported Cooperative Work and Social Computing},
  author = {Kim, Young Ji and Engel, David and Woolley, Anita Williams and Lin, Jeffrey Yu-Ting and McArthur, Naomi and Malone, Thomas W.},
  year = {2017},
  pages = {2316--2329},
  keywords = {League of Legends,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/9PLECNWZ/Kim et al. - 2017 - What makes a strong team Using collective intelli.pdf}
}

@misc{kingmaAdamMethodStochastic2017,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  shorttitle = {Adam},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  year = {2017},
  month = jan,
  number = {arXiv:1412.6980},
  eprint = {1412.6980},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1412.6980},
  url = {http://arxiv.org/abs/1412.6980},
  urldate = {2024-01-16},
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/89BKFQEL/Kingma und Ba - 2017 - Adam A Method for Stochastic Optimization.pdf;/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/YI3MCKGC/1412.html}
}

@article{kinkade2015dota,
  title = {Dota 2 Win Prediction},
  author = {Kinkade, Nicholas and Lim, K},
  year = {2015},
  journal = {Univ Calif},
  volume = {1},
  pages = {1--13},
  keywords = {Dota 2,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/QHY49G49/018.pdf}
}

@article{klineRevisitingSquarederrorCrossentropy2005,
  title = {Revisiting Squared-Error and Cross-Entropy Functions for Training Neural Network Classifiers},
  author = {Kline, Douglas M. and Berardi, Victor L.},
  year = {2005},
  month = dec,
  journal = {Neural Computing \& Applications},
  volume = {14},
  number = {4},
  pages = {310--318},
  issn = {1433-3058},
  doi = {10.1007/s00521-005-0467-y},
  url = {https://doi.org/10.1007/s00521-005-0467-y},
  urldate = {2023-11-02},
  abstract = {This paper investigates the efficacy of cross-entropy and square-error objective functions used in training feed-forward neural networks to estimate posterior probabilities. Previous research has found no appreciable difference between neural network classifiers trained using cross-entropy or squared-error. The approach employed here, though, shows cross-entropy has significant, practical advantages over squared-error.},
  langid = {english},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/CG6GRRLQ/Kline und Berardi - 2005 - Revisiting squared-error and cross-entropy functio.pdf}
}

@article{kuglerHowAIDriving2022,
  title = {How {{AI}} Is Driving the Esports Boom},
  author = {Kugler, Logan},
  year = {2022},
  month = aug,
  journal = {Communications of the ACM},
  volume = {65},
  number = {9},
  pages = {17--18},
  issn = {0001-0782},
  doi = {10.1145/3546956},
  url = {https://dl.acm.org/doi/10.1145/3546956},
  urldate = {2023-10-05},
  abstract = {Artificial intelligence is helping the esports industry take the world by storm.},
  keywords = {MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/S8LFNHEN/Kugler - 2022 - How AI is driving the esports boom.pdf}
}

@article{kunnIndoorAirQuality2023,
  title = {Indoor {{Air Quality}} and {{Strategic Decision Making}}},
  author = {K{\"u}nn, Steffen and Palacios, Juan and Pestel, Nico},
  year = {2023},
  month = sep,
  journal = {Management Science},
  volume = {69},
  number = {9},
  pages = {5354--5377},
  publisher = {{INFORMS}},
  issn = {0025-1909},
  doi = {10.1287/mnsc.2022.4643},
  url = {https://pubsonline.informs.org/doi/full/10.1287/mnsc.2022.4643},
  urldate = {2024-03-06},
  abstract = {Decision making on the job is becoming increasingly important in the labor market, in which there is an unprecedented rise in demand for workers with problem-solving and critical-thinking skills. This paper investigates how indoor air quality affects the quality of strategic decision making based on data from official chess tournaments. Our main analysis relies on a unique data set linking the readings of air-quality monitors inside the tournament room to the quality of 30,000 moves, each of them objectively evaluated by a powerful artificial intelligence--based chess engine. The results show that poor indoor air quality hampers players' decision making. We find that an increase in the indoor concentration of fine particulate matter (PM 2.5 2.5 ) by 10  {$\mu$}g/ m 3 {$\mu$}g/m3  (corresponding to 75\% of a standard deviation in our sample) increases a player's probability of making an erroneous move by 26.3\%. The decomposition of the effects by different stages of the game shows that time pressure amplifies the damage of poor air quality to the players' decisions. We implement a number of robustness checks and conduct a replication exercise with analogous move-quality data from games in the top national league showing the strength of our results. The results highlight the costs of poor air quality for highly skilled professionals faced with strategic decisions under time pressure. This paper was accepted by Prof. Yan Chen, behavioral economics and decision analysis. Funding: The authors gratefully acknowledge the financial support from the Graduate School of Business and Economics at Maastricht University as well as the Institute of Labor Economics Bonn. Supplemental Material: The online appendix and data are available at https://doi.org/10.1287/mnsc.2022.4643.},
  keywords = {chess,indoor air quality,pollution,strategic decision making},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/M2JBWJU8/Künn et al. - 2023 - Indoor Air Quality and Strategic Decision Making.pdf}
}

@article{LeagueLegends2024,
  title = {{\emph{League of }}{{{\emph{Legends}}}}},
  year = {2024},
  month = feb,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=League_of_Legends&oldid=1209785427},
  urldate = {2024-02-24},
  abstract = {League of Legends (LoL), commonly referred to as League, is a 2009 multiplayer online battle arena video game developed and published by Riot Games. Inspired by Defense of the Ancients, a custom map for Warcraft III, Riot's founders sought to develop a stand-alone game in the same genre. Since its release in October 2009, League has been free-to-play and is monetized through purchasable character customization. The game is available for Microsoft Windows and macOS. In the game, two teams of five players battle in player-versus-player combat, each team occupying and defending their half of the map. Each of the ten players controls a character, known as a "champion", with unique abilities and differing styles of play. During a match, champions become more powerful by collecting experience points, earning gold, and purchasing items to defeat the opposing team. In League's main mode, Summoner's Rift, a team wins by pushing through to the enemy base and destroying their "Nexus", a large structure located within. League of Legends has received generally positive reviews; critics highlighted its accessibility, character designs, and production value. The game's long lifespan has resulted in a critical reappraisal, with reviews trending positively; it is considered one of the greatest video games ever made. However, negative and abusive in-game player behavior, criticized since the game's early days, persists despite Riot's attempts to fix the problem. In 2019, League regularly peaked at eight million concurrent players, and its popularity has led to tie-ins such as music, comic books, short stories, and the animated series Arcane. Its success has spawned several spin-off video games, including League of Legends: Wild Rift, a mobile version, Legends of Runeterra, a digital collectible card game and Ruined King: A League of Legends Story, a turn-based role-playing game, among others. A massively multiplayer online role-playing game based on the property is in development. League of Legends is the world's largest esport, with an international competitive scene consisting of multiple regional leagues; they culminate in an annual League of Legends World Championship. The 2019 event registered over 100 million unique viewers, peaking at a concurrent viewership of 44 million during the finals. Domestic and international events have been broadcast on livestreaming websites such as Twitch, YouTube, Bilibili, and on cable television sports channel ESPN.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1209785427},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/BXEHKUSE/League_of_Legends.html}
}

@article{lecunDeepLearning2015,
  title = {Deep Learning},
  author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  year = {2015},
  month = may,
  journal = {Nature},
  volume = {521},
  number = {7553},
  pages = {436--444},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature14539},
  url = {https://www.nature.com/articles/nature14539},
  urldate = {2023-11-01},
  langid = {english},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/TKSDZFUV/LeCun et al. - 2015 - Deep learning.pdf}
}

@article{lehnertBoomingESportsMarket2020,
  title = {The Booming {{eSports}} Market: A Field Day for Fans},
  shorttitle = {The Booming {{eSports}} Market},
  author = {Lehnert, Kevin and Walz, Anna and Christianson, Ryan},
  year = {2020},
  month = jan,
  journal = {Journal of Business Strategy},
  volume = {43},
  number = {2},
  pages = {122--128},
  publisher = {{Emerald Publishing Limited}},
  issn = {0275-6668},
  doi = {10.1108/JBS-07-2020-0159},
  url = {https://doi.org/10.1108/JBS-07-2020-0159},
  urldate = {2024-01-27},
  abstract = {Purpose This paper aims to explore the emerging market of video game streaming and eSports to provide readers with an understanding of the nature and content of this quickly growing entertainment industry. eSports or eGaming is the playing of video games for competition and for spectators by professionals. Popular platforms, eGaming celebrities and revenue sources are introduced. Building upon this knowledge, the authors then show the opportunities marketers have to use this medium for branding, promotional and retailing purposes. Challenges to these aims are also discussed. Design/methodology/approach The eGaming and eSports industry is summarized by studying its evolution and current state. A thorough review of the players and their possible revenue sources is presented. Likewise, a survey of marketing-related tactics and challenges is discussed to help readers not only understand the field but also use the industry's growth. Findings This paper provides valuable information to understand why this new market of video game streaming is rapidly increasing and what impact it will have on consumers, brands and marketing strategists. Originality/value This paper is unique in the sense that in one place it not only summarizes the advent and growth of an evolving field but also shows the opportunities that firms have to take advantage of this unique medium for connecting with customers. Firms are at the same time cautioned to consider increasing challenges with this new industry.},
  keywords = {Digital marketing,EGaming,ESports,Marketing strategy,Online strategies,Streaming},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/K78P7AEC/Lehnert et al. - 2020 - The booming eSports market a field day for fans.pdf}
}

@inproceedings{leontjevaCombiningStaticDynamic2016,
  title = {Combining {{Static}} and {{Dynamic Features}} for {{Multivariate Sequence Classification}}},
  booktitle = {2016 {{IEEE International Conference}} on {{Data Science}} and {{Advanced Analytics}} ({{DSAA}})},
  author = {Leontjeva, Anna and Kuzovkin, Ilya},
  year = {2016},
  month = oct,
  eprint = {1712.08160},
  primaryclass = {cs, stat},
  pages = {21--30},
  doi = {10.1109/DSAA.2016.10},
  url = {http://arxiv.org/abs/1712.08160},
  urldate = {2023-11-28},
  abstract = {Model precision in a classification task is highly dependent on the feature space that is used to train the model. Moreover, whether the features are sequential or static will dictate which classification method can be applied as most of the machine learning algorithms are designed to deal with either one or another type of data. In real-life scenarios, however, it is often the case that both static and dynamic features are present, or can be extracted from the data. In this work, we demonstrate how generative models such as Hidden Markov Models (HMM) and Long Short-Term Memory (LSTM) artificial neural networks can be used to extract temporal information from the dynamic data. We explore how the extracted information can be combined with the static features in order to improve the classification performance. We evaluate the existing techniques and suggest a hybrid approach, which outperforms other methods on several public datasets.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/NWMZGU3E/1712.08160.pdf}
}

@article{lianoRobustErrorMeasure1996,
  title = {Robust Error Measure for Supervised Neural Network Learning with Outliers},
  author = {Liano, K.},
  year = {1996},
  month = jan,
  journal = {IEEE Transactions on Neural Networks},
  volume = {7},
  number = {1},
  pages = {246--250},
  issn = {1941-0093},
  doi = {10.1109/72.478411},
  url = {https://ieeexplore.ieee.org/abstract/document/478411?casa_token=0jyPyVbllkwAAAAA:nhqXqLYr4A9ycR0tFERzxjz3SlQJSMw2oWs0J9qHkkEELwxnKsv2m2mDl_IkcFv8SD-q0ho1aA},
  urldate = {2023-11-02},
  abstract = {Most supervised neural networks (NNs) are trained by minimizing the mean squared error (MSE) of the training set. In the presence of outliers, the resulting NN model can differ significantly from the underlying system that generates the data. Two different approaches are used to study the mechanism by which outliers affect the resulting models: influence function and maximum likelihood. The mean log squared error (MLSE) is proposed as the error criteria that can be easily adapted by most supervised learning algorithms. Simulation results indicate that the proposed method is robust against outliers.},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/B5TDN9QC/Liano - 1996 - Robust error measure for supervised neural network.pdf}
}

@inproceedings{liIntegratingStaticTimeSeries2021,
  title = {Integrating {{Static}} and {{Time-Series Data}} in {{Deep Recurrent Models}} for {{Oncology Early Warning Systems}}},
  booktitle = {Proceedings of the 30th {{ACM International Conference}} on {{Information}} \& {{Knowledge Management}}},
  author = {Li, Dingwen and Lyons, Patrick and Klaus, Jeff and Gage, Brian and Kollef, Marin and Lu, Chenyang},
  year = {2021},
  month = oct,
  pages = {913--936},
  publisher = {{ACM}},
  address = {{Virtual Event Queensland Australia}},
  doi = {10.1145/3459637.3482441},
  url = {https://dl.acm.org/doi/10.1145/3459637.3482441},
  urldate = {2023-11-28},
  abstract = {Machine learning techniques have shown promise in predicting clinical deterioration of hospitalized patients based on electronic health record (EHR). However, building accurate early warning systems (EWS) remains challenging in practice. EHRs are heterogeneous, comprising both static and time-series data. Moreover, missing values are prevalent in both static and time-series data, and the missingness of certain data can be correlated to clinical outcomes. This paper proposes a novel approach for integrating static and time-series clinical data in deep recurrent models through multimodal fusion. Furthermore, we exploit the correlation of static and time-series data through cross-modal imputation in an integrated recurrent model. We apply the proposed approaches to a dataset extracted from the EHR of 20,700 hospitalizations of adult oncology patients in a research hospital. The experiments demonstrate the proposed approaches outperform the state-of-the-art models in terms of predictive accuracy in generating early warnings for clinical deterioration. A case study further establishes the efficacy of the predictive model for early warning systems under realistic clinical settings.},
  isbn = {978-1-4503-8446-9},
  langid = {english},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/KQ34UJFR/Li et al. - 2021 - Integrating Static and Time-Series Data in Deep Re.pdf}
}

@inproceedings{liMOBAGameAnalysis2021,
  title = {{{MOBA Game Analysis System Based}} on {{Neural Networks}}},
  booktitle = {Web {{Information Systems Engineering}} -- {{WISE}} 2021},
  author = {Li, Kangwei and Li, Mengwei and Tian, Jia and Cao, Xiaobo and Nie, Tiezheng and Kou, Yue and Shen, Derong},
  editor = {Zhang, Wenjie and Zou, Lei and Maamar, Zakaria and Chen, Lu},
  year = {2021},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {518--526},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-91560-5_40},
  abstract = {The domain of knowledge contained in Multiplayer Online Battle Arena (MOBA) is quite complex, which is of great research value. With the rapid development of E-sports, the impact of data analysis on MOBA games is increasing. For example, data mining and deep learning methods can be used to guide players and develop appropriate strategies to win games. This paper proposes a novel MOBA game analysis system. The system includes three individual modules, namely lineup recommendation, real-time win rate prediction, and trend forecasting. The lineup module is implemented using NSGA-II algorithm to recommend hero combinations according to the enemy lineup. Win rate module is a neural network for predicting the quantitative advantage between teams. Trend module is a sequence-to-sequence model that forecasts the future team gold and exp. Finally, the system is applied to Dota 2, one of the most popular MOBA games. Experiments on a large number of professional match replays show that the system works well on arbitrary matches.},
  isbn = {978-3-030-91560-5},
  langid = {english},
  keywords = {Dota 2,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/IE3YTEVY/Li et al. - 2021 - MOBA Game Analysis System Based on Neural Networks.pdf}
}

@article{linDeterminingMatchFairness,
  title = {Determining {{Match Fairness}} from {{Skill Ratings}}},
  author = {Lin, Anthony},
  langid = {english},
  keywords = {MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/8ZFEIQ55/Lin - Determining Match Fairness from Skill Ratings.pdf}
}

@article{linLeagueLegendsMatch2016,
  title = {League of {{Legends Match Outcome Prediction}}},
  author = {Lin, Lucas},
  year = {2016},
  journal = {Comput. Sci. Dept., Univ. Stanford, Stanford, CA, USA, Rep},
  abstract = {We use gradient boosted trees and gradient boosted trees with logistic regression to predict the match outcomes of the popular online multiplayer game, League of Legends. Features are extracted from the data that Riot Games API exposes--including champions picked for the game, player role information, and mastery levels for the players' champions (pre-game knowledge) as well as in-game player statistics. One-hot encoding is used to transform this mostly categorical data of pre-game knowledge into a feature vector that is used in the machine learning algorithms. We find that using only prematch knowledge (champions, masteries, roles, spells) from the very start is only a weak predictor of match outcome but using in-game statistics, the model becomes a strong predictor.},
  langid = {english},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/ATG663NS/Lin - League of Legends Match Outcome Prediction.pdf}
}

@misc{LoLEsports,
  title = {{{LoL Esports}}},
  url = {https://lolesports.com/article/dev-diary-win-probability-powered-by-aws-at-worlds/blt403ee07f98e2e0fc},
  urldate = {2024-01-27},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/7LLXMCNJ/blt403ee07f98e2e0fc.html}
}

@incollection{mattheakis2019recurrent,
  title = {Recurrent Neural Networks: {{Exploding}} Vanishing Gradients \& Reservoir Computing},
  booktitle = {Advanced Topics in Data Science},
  author = {Mattheakis, M and Protopapas, P},
  year = {2019},
  publisher = {{Harvard Press Cambridge, MA, USA}},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/966DHZFQ/a-sec4-RNNs_notes_209b2019.pdf}
}

@article{mccullochLogicalCalculusIdeas1943,
  title = {A Logical Calculus of the Ideas Immanent in Nervous Activity},
  author = {McCulloch, Warren S. and Pitts, Walter},
  year = {1943},
  month = dec,
  journal = {The bulletin of mathematical biophysics},
  volume = {5},
  number = {4},
  pages = {115--133},
  issn = {1522-9602},
  doi = {10.1007/BF02478259},
  url = {https://doi.org/10.1007/BF02478259},
  urldate = {2023-11-01},
  abstract = {Because of the ``all-or-none'' character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.},
  langid = {english},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/YECLVBD6/McCulloch und Pitts - 1943 - A logical calculus of the ideas immanent in nervou.pdf}
}

@article{minchenliTutorialBackwardPropagation2016,
  title = {A {{Tutorial On Backward Propagation Through Time}} ({{BPTT}}) {{In The Gated Recurrent Unit}} ({{GRU}}) {{RNN}}},
  author = {{Minchen Li}},
  year = {2016},
  publisher = {{Unpublished}},
  doi = {10.13140/RG.2.2.32858.98247},
  url = {http://rgdoi.net/10.13140/RG.2.2.32858.98247},
  urldate = {2023-11-07},
  abstract = {In this tutorial, we provide a thorough explanation of how BPTT in GRU1 is conducted. A MATLAB program which implements the entire BPTT for GRU and the pseudo-codes describing the algorithms explicitly will be presented. We provide two algorithms for BPTT, a direct but quadratic time algorithm for easy understanding, and an optimized linear time algorithm. This tutorial starts with a specification of the problem followed by a mathematical derivation before the computational solutions.},
  langid = {english},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/WRLT8ADF/Minchen Li - 2016 - A Tutorial On Backward Propagation Through Time (B.pdf}
}

@inproceedings{mondalDoesSupportRole2022,
  title = {Does {{A Support Role Player}} Really {{Create Difference}} towards {{Triumph}}? {{Analyzing Individual Performances}} of {{Specific Role Players}} to {{Predict Victory}} in {{League}} of {{Legends}}},
  shorttitle = {Does {{A Support Role Player}} Really {{Create Difference}} towards {{Triumph}}?},
  booktitle = {2022 25th {{International Conference}} on {{Computer}} and {{Information Technology}} ({{ICCIT}})},
  author = {Mondal, Joyanta Jyoti and Zahin, Abrar and Manab, Meem Arafat and Zahidul Hasan, Mohammad},
  year = {2022},
  month = dec,
  pages = {768--773},
  doi = {10.1109/ICCIT57492.2022.10055689},
  url = {https://ieeexplore.ieee.org/abstract/document/10055689},
  urldate = {2023-10-05},
  abstract = {Players make comments like "Mid Diff", "Top Diff", "JG Diff", etc. in the in-game chat at the end of almost every match of League of Legends. It represents the relative difference in in-game abilities of players of the same position that leads to a significant difference between two teams in determining the loss/win of a particular match. However, no player seems to pay enough heed to if there is a difference between players who play the Support role (or "SP Diff" to be specific) which also may have also helped them to win a match. In most places, this role is considered insignificant among players. But do they really not contribute towards the winning of a match? In our research, we investigate the impact of a player who contributes in a Support role toward match victory. Previous researches show collective intelligence (CI) to be a factor in team games that helps to analyze their capacity to work and win collectively. To our knowledge, this is the first work that focuses on the contribution of any single particular role out of the full team of five players toward the victory of a match. We also create a custom dataset based on the match statistics and match-specific performances of different Support role players and evaluate if the outcomes and performance shown by a particular role are crucial enough to the world of teams in competitive online video games, where intensive, self-organized, and time-pressured cooperation takes place entirely online. The results show a stronger correlation between a certain support player's performance and the match result than usually thought of. This points towards more reliable match result prediction in the game. We make the dataset publicly available at https://www.kaggle.com/datasets/joyanta180199/lol-sp},
  keywords = {League of Legends,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/2B76SXH6/Mondal et al. - 2022 - Does A Support Role Player really Create Differenc.pdf}
}

@article{mora-cantallopsMOBAGamesLiterature2018,
  title = {{{MOBA}} Games: {{A}} Literature Review},
  shorttitle = {{{MOBA}} Games},
  author = {{Mora-Cantallops}, Mar{\c c}al and Sicilia, Miguel-{\'A}ngel},
  year = {2018},
  month = may,
  journal = {Entertainment Computing},
  volume = {26},
  pages = {128--138},
  issn = {18759521},
  doi = {10.1016/j.entcom.2018.02.005},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1875952117300149},
  urldate = {2023-10-05},
  abstract = {This article aims to perform a literature review of the available research that focuses strictly on MOBA (multiplayer online battle arena) games. First, a review identifying the relevant papers published since 2011 is conducted, exploring them systematically to extract similarities, gaps and main findings. Results show how League of Legends is the most explored game, with player experience and toxic behaviour as popular topics for research. Second, as MOBA games remain underexplored by researchers despite their vast, enthusiast community, as well as projection and influence on contemporary game designers, a proposal on future lines for research is provided.},
  langid = {english},
  keywords = {Dota 2,League of Legends,notion,Survey},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/3XA7UFLR/Mora-Cantallops und Sicilia - 2018 - MOBA games A literature review.pdf}
}

@inproceedings{myslakDevelopingGameStructureSensitive2015,
  title = {Developing {{Game-Structure Sensitive Matchmaking System}} for {{Massive-Multiplayer Online Games}}},
  booktitle = {Social {{Informatics}}},
  author = {My{\'s}lak, Mateusz and Deja, Dominik},
  editor = {Aiello, Luca Maria and McFarland, Daniel},
  year = {2015},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {200--208},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-15168-7_25},
  abstract = {Providing a fair matchmaking system is an essential issue, while developing every online video game. In the article, we show that the currently existing matchmaking system in League of Legends, one of the most popular online video games currently existing, is built on a base of conditions which do not hold true in the presence of empirical data. This, in short, decreases the effectiveness of the ranking system, and negatively affects users experience. Therefore, we propose a new ranking system, which genuinely answers the needs, which arise from League of Legends gameplay. As League of Legends gameplay model is nowadays highly popular amid online video games, the proposed system can be easily generalized and adopted by other online video games that are currently popular among gamers.},
  isbn = {978-3-319-15168-7},
  langid = {english},
  keywords = {MOBA,notion}
}

@book{nasrCrossEntropyError2002,
  title = {Cross Entropy Error Function in Neural Networks},
  author = {Nasr, G. E. and Badr, E. A. and Joun, C.},
  year = {2002},
  publisher = {{ACM}},
  url = {https://laur.lau.edu.lb:8443/xmlui/handle/10725/6723},
  urldate = {2023-11-02},
  abstract = {This paper applies artificial neural networks to forecast gasoline consumption. The ANN is implemented using the cross entropy error function in the training stage. The cross entropy function is proven to accelerate the backpropagation algorithm and to provide good overall network performance with relatively short stagnation periods. To forecast gasoline consumption (GC), the ANN uses previous GC data and its determinants in a training data set. The determinants of gasoline consumption employed in this study are the price (P) and car registration (CR). Two ANNs models are presented. The first model is a univariate model based on past GC values. The second model is a trivariate model based on GC, price and car registration time series. Forecasting performance measures such as mean square errors (MSE) and mean absolute deviations (MAD) are presented for both models.},
  isbn = {978-1-57735-141-2},
  langid = {english},
  keywords = {notion},
  annotation = {Accepted: 2017-12-05T14:09:40Z},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/NUWM5JI5/Nasr et al. - 2002 - Cross entropy error function in neural networks.pdf}
}

@article{noQuantitativeAnalysisWin2021,
  title = {Quantitative {{Analysis}} for {{Win}}/{{Loss Prediction}} of '{{League}} of {{Legends}}' {{Utilizing}} the {{Deep Neural Network System}} through {{Big Data}}},
  author = {No, Si-Jae and Moon, Yoo-Jin and Hwang, Young-Ho},
  year = {2021},
  journal = {Journal of the Korea Society of Computer and Information},
  volume = {26},
  number = {4},
  pages = {213--221},
  publisher = {{Korean Society of Computer Information}},
  issn = {1598-849X},
  doi = {10.9708/jksci.2021.26.04.213},
  url = {https://koreascience.kr/article/JAKO202113759909760.page},
  urldate = {2024-01-10},
  abstract = {이 논문은 League of Legends (LOL) 게임의 승패를 예측하기 위하여 Deep Neural Network Model 시스템을 제안한다. 이 모델은 다양한 LOL 빅데이터를 활용하여 TensorFlow 의 Keras에 의하여 설계하였다. 연구 방법으로 한국 서버의 챌린저 리그에서 행해진 약 26000 경기 데이터 셋을 분석하여, 경기 도중 데이터를 수집하여 그 중에서 드래곤 처치 수, 챔피언 레벨, 정령, 타워 처치 수가 게임 결과에 유의미한 영향을 끼치는 것을 확인하였다. 이 모델은 Sigmoid, ReLu 와 Logcosh 함수를 사용했을 때 더 높은 정확도를 얻을 수 있었다. 실제 LOL의 프로 게임 16경기를 예측한 결과 93.75\%의 정확도를 도출했다. 게임 평균시간이 34분인 것을 고려하였을 때, 게임 중반 15분 정도에 게임의 승패를 예측할 수 있음이 증명되었다. 본 논문에서 설계한 이 프로그램은 전 세계 E-sports 프로리그의 활성화, 승패예측과 프로팀의 유용한 훈련지표로 활용 가능하다고 사료된다. In this paper, we suggest the Deep Neural Network Model System for predicting results of the match of 'League of Legends (LOL).' The model utilized approximately 26,000 matches of the LOL game and Keras of Tensorflow. It performed an accuracy of 93.75\% without overfitting disadvantage in predicting the '2020 League of Legends Worlds Championship' utilizing the real data in the middle of the game. It employed functions of Sigmoid, Relu and Logcosh, for better performance. The experiments found that the four variables largely affected the accuracy of predicting the match --- 'Dragon Gap', 'Level Gap', 'Blue Rift Heralds', and 'Tower Kills Gap,' and ordinary users can also use the model to help develop game strategies by focusing on four elements. Furthermore, the model can be applied to predicting the match of E-sports professional leagues around the world and to the useful training indicators for professional teams, contributing to vitalization of E-sports.},
  langid = {english},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/SBVQSC7H/No et al. - 2021 - Quantitative Analysis for WinLoss Prediction of '.pdf}
}

@inproceedings{pascanuDifficultyTrainingRecurrent2013,
  title = {On the Difficulty of Training Recurrent Neural Networks},
  booktitle = {Proceedings of the 30th {{International Conference}} on {{Machine Learning}}},
  author = {Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
  year = {2013},
  month = may,
  pages = {1310--1318},
  publisher = {{PMLR}},
  issn = {1938-7228},
  url = {https://proceedings.mlr.press/v28/pascanu13.html},
  urldate = {2023-12-22},
  abstract = {There are two widely known issues with properly training recurrent neural networks, the vanishing and the exploding gradient problems detailed in Bengio et al. (1994). In this paper we attempt to improve the understanding of the underlying issues by exploring these problems from an analytical, a geometric and a dynamical systems perspective. Our analysis is used to justify a simple yet effective solution. We propose a gradient norm clipping strategy to deal with exploding gradients and a soft constraint for the vanishing gradients problem. We validate empirically our hypothesis and proposed solutions in the experimental section.},
  langid = {english},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/Q485DY59/Pascanu et al. - 2013 - On the difficulty of training recurrent neural net.pdf}
}

@misc{PythonAPIReference,
  title = {Python {{API Reference}} --- Xgboost 2.0.2 Documentation},
  url = {https://xgboost.readthedocs.io/en/stable/python/python_api.html},
  urldate = {2023-12-02},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/MPT7VSCX/python_api.html}
}

@misc{raizinFileMapMOBA2013,
  title = {File:{{Map}} of {{MOBA}}.Svg - {{Wikipedia}}},
  shorttitle = {File},
  author = {Raizin},
  year = {2013},
  month = nov,
  url = {https://commons.wikimedia.org/wiki/File:Map_of_MOBA.svg},
  urldate = {2024-03-06},
  langid = {english},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/YCRB4SD7/FileMap_of_MOBA.html}
}

@misc{RankDistributionLeague,
  title = {Rank Distribution - {{League}} of {{Legends}}},
  url = {https://www.leagueofgraphs.com/rankings/rank-distribution},
  urldate = {2023-11-09},
  abstract = {We track millions of LoL games played every day gathering champion stats, matchups, builds \& summoner rankings, as well as champion stats, popularity, winrate, teams rankings, best items and spells.},
  langid = {english},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/JLLI8QZR/rank-distribution.html}
}

@article{rehmerVanishingExplodingGradient2020,
  title = {On the Vanishing and Exploding Gradient Problem in {{Gated Recurrent Units}}},
  author = {Rehmer, Alexander and Kroll, Andreas},
  year = {2020},
  month = jan,
  journal = {IFAC-PapersOnLine},
  series = {21st {{IFAC World Congress}}},
  volume = {53},
  number = {2},
  pages = {1243--1248},
  issn = {2405-8963},
  doi = {10.1016/j.ifacol.2020.12.1342},
  url = {https://www.sciencedirect.com/science/article/pii/S2405896320317481},
  urldate = {2023-12-22},
  abstract = {Recurrent Neural Networks are applied in areas such as speech recognition, natural language and video processing, and the identification of nonlinear state space models. Conventional Recurrent Neural Networks, e.g. the Elman Network, are hard to train. A more recently developed class of recurrent neural networks, so-called Gated Units, outperform their counterparts on virtually every task. This paper aims to provide additional insights into the differences between RNNs and Gated Units in order to explain the superior perfomance of gated recurrent units. It is argued, that Gated Units are easier to optimize not because they solve the vanishing gradient problem, but because they circumvent the emergence of large local gradients.},
  keywords = {Gated Recurrent Units,Nonlinear system identification,Recurrent Neural Networks},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/9Y3SV8BL/Rehmer und Kroll - 2020 - On the vanishing and exploding gradient problem in.pdf;/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/L7XAKX9J/S2405896320317481.html}
}

@misc{RiotDeveloperPortal,
  title = {Riot {{Developer Portal}}},
  url = {https://developer.riotgames.com/},
  urldate = {2023-12-19},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/2BHJRP2M/developer.riotgames.com.html}
}

@misc{riotgamesDevBalanceFramework2020,
  title = {/Dev: {{Balance Framework Update}} - {{League}} of {{Legends}}},
  shorttitle = {/Dev},
  author = {Riot Games},
  year = {2020},
  month = jun,
  url = {https://www.leagueoflegends.com/news/dev/dev-balance-framework-update/},
  urldate = {2023-11-09},
  abstract = {We introduced a more objective approach to champ balance last year. Here's what we learned so far.},
  langid = {american},
  keywords = {League of Legends,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/LLP2F79S/dev-balance-framework-update.html}
}

@misc{riotgamesHowRiotEsports2022,
  title = {How {{Riot Esports Delivers Worlds}} 2022 {{Broadcast}} to a {{Global Audience}}},
  author = {Riot Games},
  year = {2022},
  month = nov,
  journal = {How Riot Delivers a Global Broadcast for Worlds 2022},
  url = {https://www.riotgames.com/en/news/riot-esports-delivering-custom-global-broadcasts-worlds-2022},
  urldate = {2024-01-29},
  abstract = {With Worlds 2022 happening in North America, Rioters and partners around the world deliver live League of Legends broadcasts custom tailored to local audiences.},
  langid = {english},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/BE39284Y/riot-esports-delivering-custom-global-broadcasts-worlds-2022.html}
}

@misc{riotgamesMasterGrandmasterChallenger2023,
  title = {Master, {{Grandmaster}}, and {{Challenger}}: {{The Apex Tiers}}},
  shorttitle = {Master, {{Grandmaster}}, and {{Challenger}}},
  author = {Riot Games},
  year = {2023},
  month = aug,
  journal = {League of Legends Support},
  url = {https://support-leagueoflegends.riotgames.com/hc/en-us/articles/4405776545427-Master-Grandmaster-and-Challenger-The-Apex-Tiers},
  urldate = {2024-01-01},
  abstract = {Welcome to the top of the food chain. To reach any of the top three ranked tiers in League of Legends is an incredible accomplishment and proves without a doubt you're among the best players in the...},
  langid = {american},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/VSMDRRBZ/4405776545427-Master-Grandmaster-and-Challenger-The-Apex-Tiers.html}
}

@misc{riotgamesRanglistenklassenDivisionenUnd2023,
  title = {{Ranglistenklassen, Divisionen und Warteschlangen}},
  author = {Riot Games},
  year = {2023},
  month = aug,
  journal = {League of Legends Support},
  url = {https://support-leagueoflegends.riotgames.com/hc/de/articles/4406004330643-Ranglistenklassen-Divisionen-und-Warteschlangen},
  urldate = {2023-11-09},
  abstract = {Von den Slums von Zhaun bis zur Spitze des Targon, Runeterra ist die Heimat der unterschiedlichsten Personen und Orte. Und das Gleiche gilt in gewisser Weise auch f{\"u}r League! Es spielt keine Rolle,...},
  langid = {ngerman},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/X6YF8VR4/4406004330643.html}
}

@misc{riotgamesRankedTiersDivisions2023,
  title = {Ranked {{Tiers}}, {{Divisions}}, and {{Queues}}},
  author = {Riot Games},
  year = {2023},
  month = aug,
  journal = {League of Legends Support},
  url = {https://support-leagueoflegends.riotgames.com/hc/en-us/articles/4406004330643-Ranked-Tiers-Divisions-and-Queues},
  urldate = {2023-11-09},
  abstract = {From the slums of Zaun to the peak of Targon, Runeterra holds a tremendous gradient of people and places. And in a lot of ways, League is no different! Whether you're a weekend warrior or dial in d...},
  langid = {american},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/FXKJ74HK/4406004330643-Ranked-Tiers-Divisions-and-Queues.html}
}

@article{rioultMiningTracksCompetitive2014,
  title = {Mining {{Tracks}} of {{Competitive Video Games}}},
  author = {Rioult, Fran{\c c}ois and M{\'e}tivier, Jean-Philippe and Helleu, Boris and Scelles, Nicolas and Durand, Christophe},
  year = {2014},
  month = jan,
  journal = {AASRI Procedia},
  series = {2014 {{AASRI Conference}} on {{Sports Engineering}} and {{Computer Science}} ({{SECS}} 2014)},
  volume = {8},
  pages = {82--87},
  issn = {2212-6716},
  doi = {10.1016/j.aasri.2014.08.014},
  url = {https://www.sciencedirect.com/science/article/pii/S221267161400081X},
  urldate = {2023-10-05},
  abstract = {The development and professionalization of a video game requires tools for analyzing the practice of the players and teams, their tactics and strategies. These games are very popular and by nature numerical, they provide many tracks that we analyzed in terms of team play. We studied Defense of the Ancients (DotA), a Multiplayer Online Battle Arena (MOBA), where two teams battle in a game very similar to rugby or American football. Through topological measures -- area of polygon described by the players, inertia, diameter, distance to the base -- that are independent of the exact nature of the game, we show that the outcome of the match can be relevantly predicted. Mining e-sport's tracks is opening interest in further application of these tools for analyzing real time sport.},
  keywords = {Dota 2,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/DKIDDVMN/Rioult et al. - 2014 - Mining Tracks of Competitive Video Games.pdf}
}

@article{rosenblattPerceptronProbabilisticModel1958,
  title = {The Perceptron: {{A}} Probabilistic Model for Information Storage and Organization in the Brain},
  shorttitle = {The Perceptron},
  author = {Rosenblatt, F.},
  year = {1958},
  journal = {Psychological Review},
  volume = {65},
  number = {6},
  pages = {386--408},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1471},
  doi = {10.1037/h0042519},
  abstract = {To answer the questions of how information about the physical world is sensed, in what form is information remembered, and how does information retained in memory influence recognition and behavior, a theory is developed for a hypothetical nervous system called a perceptron. The theory serves as a bridge between biophysics and psychology. It is possible to predict learning curves from neurological variables and vice versa. The quantitative statistical approach is fruitful in the understanding of the organization of cognitive systems. 18 references. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/BDLV7JLH/Rosenblatt - 1958 - The perceptron A probabilistic model for informat.pdf}
}

@article{rumelhartLearningRepresentationsBackpropagating1986,
  title = {Learning Representations by Back-Propagating Errors},
  author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  year = {1986},
  month = oct,
  journal = {Nature},
  volume = {323},
  number = {6088},
  pages = {533--536},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/323533a0},
  url = {https://www.nature.com/articles/323533a0},
  urldate = {2023-11-02},
  abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal `hidden' units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
  copyright = {1986 Springer Nature Limited},
  langid = {english},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/9NH839CL/Rumelhart et al. - 1986 - Learning representations by back-propagating error.pdf}
}

@inproceedings{saputrarangkutiSentimentAnalysisMovie2018,
  title = {Sentiment {{Analysis}} on {{Movie Reviews Using Ensemble Features}} and {{Pearson Correlation Based Feature Selection}}},
  booktitle = {2018 {{International Conference}} on {{Sustainable Information Engineering}} and {{Technology}} ({{SIET}})},
  author = {Saputra Rangkuti, Fachrul Rozy and Fauzi, M. Ali and Sari, Yuita Arum and Sari, Eka Dewi Lukmana},
  year = {2018},
  month = nov,
  pages = {88--91},
  doi = {10.1109/SIET.2018.8693211},
  url = {https://ieeexplore.ieee.org/abstract/document/8693211?casa_token=5__tibPUwjAAAAAA:bPmeWdzCSDIV5gN4czJIZok2ibpd0jsGfW6Vfl0rX617k4jJF_OL_JzDbgt_0VB9jwyTEIo},
  urldate = {2023-12-01},
  abstract = {Microblogging has become the media information that is very popular among internet users. Therefore, the microblogging became a source of rich data for opinions and reviews especially on movie reviews. We proposed, sentiment analysis on movie review using ensemble features and Bag of Words and selection Features Pearson's Correlation to reduce the dimension of the feature and get the optimal feature combinations. Use the feature selection is done to improve the performance of the classification, reducing the dimension of the feature and get the optimal feature combinations. The process of classification using several models of Na\"{\i}ve Bayes i.e. Bernoulli Na\"{\i}ve Bayes for binary data, Gaussian Na\"{\i}ve Bayes for continuous data and Multinomial Na\"{\i}ve Bayes for numeric data. The results of this study indicate that by using the non-standard word on tweet evaluation results obtained accuracy 82\%, precision 86\%, recall 79.62\% and f-measure 82.69\% using Feature Selection 20\%. Then after using manual standardization of word the evaluation results on the accuracy increased by 8\% and then the accuracy becomes 90\%, precision 92\%, recall 88.46\% and f-measure 90.19\% using 85\% feature selection. Based on these results it can be concluded that by using the standardization of word can improve the performance of classification and feature selection Pearson's provide optimal feature combinations and reducing the total number of dimensions' feature.},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/2TI28SDN/Saputra Rangkuti et al. - 2018 - Sentiment Analysis on Movie Reviews Using Ensemble.pdf}
}

@article{sazliBriefReviewFeedforward2006,
  title = {A Brief Review of Feed-Forward Neural Networks},
  author = {Sazli, Murat H.},
  year = {2006},
  month = jan,
  journal = {Communications Faculty of Sciences University of Ankara Series A2-A3 Physical Sciences and Engineering},
  volume = {50},
  number = {01},
  pages = {0--0},
  publisher = {{Ankara University}},
  issn = {2618-6462},
  doi = {10.1501/commua1-2_0000000026},
  url = {https://dergipark.org.tr/en/pub/aupse/issue/60555/890416},
  urldate = {2023-11-01},
  abstract = {Artificial neural networks, or shortly neural networks, find applications in a very wide spectrum. In this paper, following a brief presentation of the basic aspects of feed-forward neural netvvorks, their mostly used leaming/training algorithm, the so-called back-propagation algorithm, have been described.},
  langid = {english},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/EJMHXYGK/Sazli - 2006 - A brief review of feed-forward neural networks.pdf}
}

@article{schoutenDanceMechanismsHow2021,
  title = {The {{Dance}} of the {{Mechanisms}}: {{How Observed Information Influences}} the {{Validity}} of {{Missingness Assumptions}}},
  shorttitle = {The {{Dance}} of the {{Mechanisms}}},
  author = {Schouten, Rianne Margaretha and Vink, Gerko},
  year = {2021},
  month = aug,
  journal = {Sociological Methods \& Research},
  volume = {50},
  number = {3},
  pages = {1243--1258},
  publisher = {{SAGE Publications Inc}},
  issn = {0049-1241},
  doi = {10.1177/0049124118799376},
  url = {https://doi.org/10.1177/0049124118799376},
  urldate = {2024-01-14},
  abstract = {Missing data in scientific research go hand in hand with assumptions about the nature of the missingness. When dealing with missing values, a set of beliefs has to be formulated about the extent to which the observed data may also hold for the missing parts of the data. It is vital that the validity of these missingness assumptions is verified, tested, and that assumptions are adjusted when necessary. In this article, we demonstrate how observed data structures could a priori indicate whether it is likely that our beliefs about the missingness can be trusted. To this end, we simulate complete data and generate missing values according several types of MCAR, MAR, and MNAR mechanisms. We demonstrate that in scenarios where the data correlations are either low or very substantial, strictly different mechanisms yield equivalent statistical inferences. In addition, we show that the choice of quantity of scientific interest together with the distribution of the nonresponse govern the validity of the missingness assumptions.},
  langid = {english},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/QBDG2V7S/Schouten und Vink - 2021 - The Dance of the Mechanisms How Observed Informat.pdf}
}

@misc{schubert2016esports,
  title = {Esports Analytics through Encounter Detection},
  author = {Schubert, Matthias and Drachen, Anders and Mahlmann, Tobias},
  year = {2016},
  keywords = {Dota 2,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/LFHI2MR9/Schubert et al. - 2016 - Esports analytics through encounter detection othe.pdf}
}

@inproceedings{semenovPerformanceMachineLearning2017,
  title = {Performance of {{Machine Learning Algorithms}} in {{Predicting Game Outcome}} from {{Drafts}} in {{Dota}} 2},
  booktitle = {Analysis of {{Images}}, {{Social Networks}} and {{Texts}}},
  author = {Semenov, Aleksandr and Romov, Peter and Korolev, Sergey and Yashkov, Daniil and Neklyudov, Kirill},
  editor = {Ignatov, Dmitry I. and Khachay, Mikhail Yu. and Labunets, Valeri G. and Loukachevitch, Natalia and Nikolenko, Sergey I. and Panchenko, Alexander and Savchenko, Andrey V. and Vorontsov, Konstantin},
  year = {2017},
  series = {Communications in {{Computer}} and {{Information Science}}},
  pages = {26--37},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-52920-2_3},
  abstract = {In this paper we suggest the first systematic review and compare performance of most frequently used machine learning algorithms for prediction of the match winner from the teams' drafts in Dota 2 computer game. Although previous research attempted this task with simple models, weve made several improvements in our approach aiming to take into account interactions among heroes in the draft. For that purpose we've tested the following machine learning algorithms: Naive Bayes classifier, Logistic Regression and Gradient Boosted Decision Trees. We also introduced Factorization Machines for that task and got our best results from them. Besides that, we found that model's prediction accuracy depends on skill level of the players. We've prepared publicly available dataset which takes into account shortcomings of data used in previous research and can be used further for algorithms development, testing and benchmarking.},
  isbn = {978-3-319-52920-2},
  langid = {english},
  keywords = {Dota 2,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/ZZMFWKJP/Semenov et al. - 2017 - Performance of Machine Learning Algorithms in Pred.pdf}
}

@article{shankerEffectDataStandardization1996,
  title = {Effect of Data Standardization on Neural Network Training},
  author = {Shanker, M. and Hu, M. Y. and Hung, M. S.},
  year = {1996},
  month = aug,
  journal = {Omega},
  volume = {24},
  number = {4},
  pages = {385--397},
  issn = {0305-0483},
  doi = {10.1016/0305-0483(96)00010-2},
  url = {https://www.sciencedirect.com/science/article/pii/0305048396000102},
  urldate = {2024-01-06},
  abstract = {Data transformation is a popular option in training neural networks. This study evaluates the effectiveness of two well-known transformation methods: linear transformation and statistical standardization. These two are referred to as data standardization. A carefully designed experiment is used in which data from two-group classification problems were trained by feedforward networks. Different kinds of classification problems, from relatively simple to hard, were generated. Other experimental factors include network architecture, sample size, and sample proportion of group 1 members. Three performance measurements for the effect of data standardization are employed. The results suggest that networks trained on standardized data yield better results in general, but the advantage diminishes as network and sample size become large. In other words, neural networks exhibit a self-scaling capability. In addition, impact of data standardization on the performance of training algorithm in terms of computation time and number of iterations is evaluated. The results indicate that, overall, data standardization slows down training. Finally, these results are illustrated with a data set obtained from the American Telephone and Telegraph Company.},
  keywords = {modelling,neural networks},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/I2SUFF9Z/Shanker et al. - 1996 - Effect of data standardization on neural network t.pdf;/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/QUIC8JPX/0305048396000102.html}
}

@article{shapiroAnalysisVarianceTest1965,
  title = {An {{Analysis}} of {{Variance Test}} for {{Normality}} ({{Complete Samples}})},
  author = {Shapiro, S. S. and Wilk, M. B.},
  year = {1965},
  month = dec,
  journal = {Biometrika},
  volume = {52},
  number = {3/4},
  eprint = {2333709},
  eprinttype = {jstor},
  pages = {591},
  issn = {00063444},
  doi = {10.2307/2333709},
  url = {https://www.jstor.org/stable/2333709?origin=crossref},
  urldate = {2023-11-29},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/D2S8A48Z/Shapiro und Wilk - 1965 - An Analysis of Variance Test for Normality (Comple.pdf}
}

@inproceedings{sharmaEraDeepNeural2017,
  title = {Era of Deep Neural Networks: {{A}} Review},
  shorttitle = {Era of Deep Neural Networks},
  booktitle = {2017 8th {{International Conference}} on {{Computing}}, {{Communication}} and {{Networking Technologies}} ({{ICCCNT}})},
  author = {Sharma, Poonam and Singh, Akansha},
  year = {2017},
  month = jul,
  pages = {1--5},
  doi = {10.1109/ICCCNT.2017.8203938},
  url = {https://ieeexplore.ieee.org/abstract/document/8203938},
  urldate = {2023-11-01},
  abstract = {Deep learning has achieved remarkable success in various machine learning and computer vision applications. The learning allows multiple processing layers to learn features by themselves opposite to conventional machine learning approaches which were not able to process the data in their natural form. Deep convolution networks have shown great performance in processing images and videos, whereas recurrent nets have shown great success for sequential data. This paper reviews all the aspects and researches done till now in this area along with their future possibilities.},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/YUQ5A6KQ/Sharma und Singh - 2017 - Era of deep neural networks A review.pdf}
}

@article{shenDeepLearningGated2018,
  title = {Deep {{Learning}} with {{Gated Recurrent Unit Networks}} for {{Financial Sequence Predictions}}},
  author = {Shen, Guizhu and Tan, Qingping and Zhang, Haoyu and Zeng, Ping and Xu, Jianjun},
  year = {2018},
  month = jan,
  journal = {Procedia Computer Science},
  series = {Recent {{Advancement}} in {{Information}} and {{Communication Technology}}:},
  volume = {131},
  pages = {895--903},
  issn = {1877-0509},
  doi = {10.1016/j.procs.2018.04.298},
  url = {https://www.sciencedirect.com/science/article/pii/S1877050918306781},
  urldate = {2023-10-31},
  abstract = {Gated recurrent unit (GRU) networks perform well in sequence learning tasks and overcome the problems of vanishing and explosion of gradients in traditional recurrent neural networks (RNNs) when learning long-term dependencies. Although they apply essentially to financial time series predictions, they are seldom used in the field. To fill this void, we propose GRU networks and its improved version for predicting trading signals for stock indexes of the Hang Seng Indexes (HSI), the Deutscher Aktienindex (DAX) and the S\&P 500 Index from 1991 to 2017, and compare the GRU-based models with the traditional deep net and the benchmark classifier support vector machine (SVM). Experimental results show that the two GRU models proposed in this paper both obtain higher prediction accuracy on these data sets, and the improved version can effectively improve the learning ability of the model.},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/8JASP4TY/Shen et al. - 2018 - Deep Learning with Gated Recurrent Unit Networks f.pdf}
}

@inproceedings{shenMachineLearningApproach2022,
  title = {A Machine Learning Approach to Predict the Result of {{League}} of {{Legends}}},
  booktitle = {2022 {{International Conference}} on {{Machine Learning}} and {{Knowledge Engineering}} ({{MLKE}})},
  author = {Shen, Qiyuan},
  year = {2022},
  month = feb,
  pages = {38--45},
  doi = {10.1109/MLKE55170.2022.00013},
  abstract = {Nowadays, the MOBA game is the game type with the most audiences and players around the world. Recently, the League of Legends has become an official sport as an e-sport among 37 events in the 2022 Asia Games held in Hangzhou. As the development in the e-sport, analytical skills are also involved in this field. The topic of this research is to use the machine learning approach to analyze the data of the League of Legends and make a prediction about the result of the game. In this research, the method of machine learning is applied to the dataset which records the first 10 minutes in diamond-ranked games. Several popular machine learning (AdaBoost, GradientBoost, RandomForest, ExtraTree, SVM, Na\"{\i}ve Bayes, KNN, LogisticRegression, and DecisionTree) are applied to test the performance by cross-validation. Then several algorithms that outperform others are selected to make a voting classifier to predict the game result. The accuracy of the voting classifier is 72.68\%.},
  keywords = {League of Legends,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/2EIL2KT2/Shen - 2022 - A machine learning approach to predict the result .pdf}
}

@article{silvaContinuousOutcomePrediction2018,
  title = {Continuous Outcome Prediction of League of Legends Competitive Matches Using Recurrent Neural Networks},
  author = {Silva, Antonio Luis Cardoso and Pappa, Gisele Lobo and Chaimowicz, Luiz},
  year = {2018},
  journal = {SBC-proceedings of SBCGames},
  pages = {2179--2259},
  keywords = {League of Legends,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/WAWXTCHA/Silva et al. - 2018 - Continuous outcome prediction of league of legends.pdf}
}

@article{songPredictingWinningSide,
  title = {Predicting the Winning Side of {{DotA2}}},
  author = {Song, Kuangyan and Zhang, Tianyi and Ma, Chao},
  abstract = {In this paper, we tried using logistic regression to predict the winning side of DotA2 games based on hero lineups. We collected data using API provided by the game developer. We find out that only based on hero lineup to predict the game result is not good enough. We also tried to select feature using stepwise regression and the result is better than using all the heroes and hero combos as features.},
  langid = {english},
  keywords = {Dota 2,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/ZT2WLQD8/Song et al. - Predicting the winning side of DotA2.pdf}
}

@phdthesis{sutskeverTrainingRecurrentNeural2013,
  title = {Training Recurrent Neural Networks},
  author = {Sutskever, Ilya},
  year = {2013},
  address = {{Toronto, ON, Canada}},
  url = {https://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf},
  urldate = {2023-11-01},
  school = {University of Toronto},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/ZHED2SV5/ilya_sutskever_phd_thesis.pdf}
}

@article{svozilIntroductionMultilayerFeedforward1997,
  title = {Introduction to Multi-Layer Feed-Forward Neural Networks},
  author = {Svozil, Daniel and Kvasnicka, Vladim{\'i}r and Pospichal, Ji{\^r}{\'i}},
  year = {1997},
  month = nov,
  journal = {Chemometrics and Intelligent Laboratory Systems},
  volume = {39},
  number = {1},
  pages = {43--62},
  issn = {0169-7439},
  doi = {10.1016/S0169-7439(97)00061-0},
  url = {https://www.sciencedirect.com/science/article/pii/S0169743997000610},
  urldate = {2023-11-01},
  abstract = {Basic definitions concerning the multi-layer feed-forward neural networks are given. The back-propagation training algorithm is explained. Partial derivatives of the objective function with respect to the weight and threshold coefficients are derived. These derivatives are valuable for an adaptation process of the considered neural network. Training and generalisation of multi-layer feed-forward neural networks are discussed. Improvements of the standard back-propagation algorithm are reviewed. Example of the use of multi-layer feed-forward neural networks for prediction of carbon-13 NMR chemical shifts of alkanes is given. Further applications of neural networks in chemistry are reviewed. Advantages and disadvantages of multilayer feed-forward neural networks are discussed.},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/7E7FYPZP/Svozil et al. - 1997 - Introduction to multi-layer feed-forward neural ne.pdf}
}

@article{tsoiDiscreteTimeRecurrent1997,
  title = {Discrete Time Recurrent Neural Network Architectures: {{A}} Unifying Review},
  shorttitle = {Discrete Time Recurrent Neural Network Architectures},
  author = {Tsoi, Ah Chung and Back, Andrew},
  year = {1997},
  month = jun,
  journal = {Neurocomputing},
  series = {Recurrent {{Neural Networks}}},
  volume = {15},
  number = {3},
  pages = {183--223},
  issn = {0925-2312},
  doi = {10.1016/S0925-2312(97)00161-6},
  url = {https://www.sciencedirect.com/science/article/pii/S0925231297001616},
  urldate = {2023-10-31},
  abstract = {In this paper, after giving definitions for a set of commonly used terms in recurrent neural networks (RNNs), all possible RNN architectures based on these definitions are enumerated, and described. Then, most existing RNN architectures are categorized under these headings. Four general neural network architectures, in increasing degree of complexity, are introduced. It is shown that all the existing RNN architectures can be considered as special cases of the general RNN architectures. Furthermore, it is shown how these existing architectures can be transformed to the general RNN architectures. Some open issues concerning RNN architectures are discussed.},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/YURYBDVQ/Tsoi und Back - 1997 - Discrete time recurrent neural network architectur.pdf}
}

@incollection{tsoiRecurrentNeuralNetwork1998,
  title = {Recurrent Neural Network Architectures: {{An}} Overview},
  shorttitle = {Recurrent Neural Network Architectures},
  booktitle = {Adaptive {{Processing}} of {{Sequences}} and {{Data Structures}}: {{International Summer School}} on {{Neural Networks}} ``{{E}}.{{R}}. {{Caianiello}}'' {{Vietri}} Sul {{Mare}}, {{Salerno}}, {{Italy September}} 6--13, 1997 {{Tutorial Lectures}}},
  author = {Tsoi, Ah Chung},
  editor = {Giles, C. Lee and Gori, Marco},
  year = {1998},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {1--26},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/BFb0053993},
  url = {https://doi.org/10.1007/BFb0053993},
  urldate = {2023-10-31},
  abstract = {In this paper, we have first considered a number of popular recurrent neural network architectures. Then, two subclasses of general recurrent neural network architectures are introduced. It is shown that all these popular recurrent neural network architectures can be grouped under either of these two subclasses of general recurrent neural network architectures. It is also inferred that these two subclasses of recurrent neural network architectures are distinct, in that it is not possible to transform from one form to the other. Two recently introduced recurrent neural network architectures specifically designed for special purposes, viz., for overcoming long term temporal dependency, and for data structure classifications are also considered.},
  isbn = {978-3-540-69752-7},
  langid = {english},
  keywords = {notion}
}

@article{vanhoudtReviewLongShortterm2020,
  title = {A Review on the Long Short-Term Memory Model},
  author = {Van Houdt, Greg and Mosquera, Carlos and N{\'a}poles, Gonzalo},
  year = {2020},
  month = dec,
  journal = {Artificial Intelligence Review},
  volume = {53},
  number = {8},
  pages = {5929--5955},
  issn = {1573-7462},
  doi = {10.1007/s10462-020-09838-1},
  url = {https://doi.org/10.1007/s10462-020-09838-1},
  urldate = {2023-11-01},
  abstract = {Long short-term memory (LSTM) has transformed both machine learning and neurocomputing fields. According to several online sources, this model has improved Google's speech recognition, greatly improved machine translations on Google Translate, and the answers of Amazon's Alexa. This neural system is also employed by Facebook, reaching over 4 billion LSTM-based translations per day as of 2017. Interestingly, recurrent neural networks had shown a rather discrete performance until LSTM showed up. One reason for the success of this recurrent network lies in its ability to handle the exploding/vanishing gradient problem, which stands as a difficult issue to be circumvented when training recurrent or very deep neural networks. In this paper, we present a comprehensive review that covers LSTM's formulation and training, relevant applications reported in the literature and code resources implementing this model for a toy example.},
  langid = {english},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/EB5JZJMH/Van Houdt et al. - 2020 - A review on the long short-term memory model.pdf}
}

@article{venkateshReviewFeatureSelection2019,
  title = {A {{Review}} of {{Feature Selection}} and {{Its Methods}}},
  author = {Venkatesh, B. and Anuradha, J.},
  year = {2019},
  month = mar,
  journal = {Cybernetics and Information Technologies},
  volume = {19},
  number = {1},
  pages = {3--26},
  doi = {10.2478/cait-2019-0001},
  url = {https://sciendo.com/article/10.2478/cait-2019-0001},
  urldate = {2023-12-01},
  abstract = {AbstractNowadays, being in digital era the data generated by various applications are increasing drastically both row-wise and column wise; this creates a bottleneck for analytics and also increases the burden of machine learning algorithms that work for pattern recognition. This cause of dimensionality can be handled through reduction techniques. The Dimensionality Reduction (DR) can be handled in two ways namely Feature Selection (FS) and Feature Extraction (FE). This paper focuses on a survey of feature selection methods, from this extensive survey we can conclude that most of the FS methods use static data. However, after the emergence of IoT and web-based applications, the data are generated dynamically and grow in a fast rate, so it is likely to have noisy data, it also hinders the performance of the algorithm. With the increase in the size of the data set, the scalability of the FS methods becomes jeopardized. So the existing DR algorithms do not address the issues with the dynamic data. Using FS methods not only reduces the burden of the data but also avoids overfitting of the model.},
  langid = {english},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/WZSX5FRG/Venkatesh und Anuradha - 2019 - A Review of Feature Selection and Its Methods.pdf}
}

@article{wangComprehensiveSurveyLoss2022,
  title = {A {{Comprehensive Survey}} of {{Loss Functions}} in {{Machine Learning}}},
  author = {Wang, Qi and Ma, Yue and Zhao, Kun and Tian, Yingjie},
  year = {2022},
  month = apr,
  journal = {Annals of Data Science},
  volume = {9},
  number = {2},
  pages = {187--212},
  issn = {2198-5812},
  doi = {10.1007/s40745-020-00253-5},
  url = {https://doi.org/10.1007/s40745-020-00253-5},
  urldate = {2023-11-02},
  abstract = {As one of the important research topics in machine learning, loss function plays an important role in the construction of machine learning algorithms and the improvement of their performance, which has been concerned and explored by many researchers. But it still has a big gap to summarize, analyze and compare the classical loss functions. Therefore, this paper summarizes and analyzes 31 classical loss functions in machine learning. Specifically, we describe the loss functions from the aspects of traditional machine learning and deep learning respectively. The former is divided into classification problem, regression problem and unsupervised learning according to the task type. The latter is subdivided according to the application scenario, and here we mainly select object detection and face recognition to introduces their loss functions. In each task or application, in addition to analyzing each loss function from formula, meaning, image and algorithm, the loss functions under the same task or application are also summarized and compared to deepen the understanding and provide help for the selection and improvement of loss function.},
  langid = {english},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/3BXNBIKE/Wang et al. - 2022 - A Comprehensive Survey of Loss Functions in Machin.pdf}
}

@article{wangModelDrivenMethodQuality,
  title = {A {{Model-Driven Method}} for {{Quality Reviews Detection}}: {{An Ensemble Model}} of {{Feature Selection}}},
  author = {Wang, Hongwei and Meng, Yuan and Yin, Pei and Hua, Jin},
  abstract = {With the rapid growth of e-commerce and user-generated content online, the increasing product online reviews have significant influence on both buyers and sellers. However, among the thousands of online reviews, only the reviews of high-quality matters to the market, thus quality reviews detection rises in response to the requirement of retrieving authentic feedbacks from consumers. In this paper, a state-of-the-art ensemble model, gradient boosting decision trees (GBDT), is applied to select useful features for quality evaluation of online reviews. Firstly, four types of features are extracted based on information adoption theory. Then, the GBDT model is adopted to select useful features for quality reviews detection. At last, comparative experiments are conducted through online reviews of searching goods, based on two baseline models such as Decision Tree and Logistic Regression, and the results show that GBDT model achieves a better performance in detecting reviews of high-quality. This research indicates that product attributes, reviewer characteristics and objectiveness of reviews are key ingredients in high quality reviews.},
  langid = {english},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/D8V2GBX8/Wang et al. - A Model-Driven Method for Quality Reviews Detectio.pdf}
}

@mastersthesis{wangPredictingMultiplayerOnline2016,
  title = {Predicting {{Multiplayer Online Battle Arena}} ({{MOBA}}) {{Game Outcome Based}} on {{Hero Draft Data}}},
  author = {Wang, Weiqi},
  year = {2016},
  month = dec,
  url = {https://norma.ncirl.ie/2523/},
  urldate = {2023-10-05},
  abstract = {DotA 2 is a popular multi-player online battle area (MOBA) game. A critical part of the game play involves choosing from a pool of more than one hundred heroes to form two five-players team. However, as different heroes have their unique attributes and skill sets, selecting a strong combination of heroes (i.e., hero drafting) is an challenging task for new players which requires extensive knowledge and experience. Previous studies have shown that using hero draft data alone can achieve as high as 69.8\% of accuracy in predicting game outcomes. However, many aspects in hero draft remains to be further investigated. In this study, we aimed to achieve higher accuracy by adding game length as an input feature. In addition, we used multi-layer feedforward neural networks to predict the game outcome with GPU enabled. However, the results showed that adding game length does not improve the performance significantly nor did neural networks outperform logistic regression significantly.},
  langid = {english},
  school = {Dublin, National College of Ireland},
  keywords = {Dota 2,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/NK2SMRUC/Wang - 2016 - Predicting Multiplayer Online Battle Arena (MOBA) .pdf}
}

@inproceedings{whiteScalablePsychologicalMomentum2020,
  title = {Scalable {{Psychological Momentum Forecasting}} in {{Esports}}},
  booktitle = {Proceedings of the 13th {{International Conference}} on {{Web Search}} and {{Data Mining}}},
  author = {White, Alfonso and Romano, Daniela M},
  year = {2020},
  abstract = {The world of competitive Esports and video gaming has seen and continues to experience steady growth in popularity and complexity. Correspondingly, more research on the topic is being published, ranging from social network analyses to the benchmarking of advanced artificial intelligence systems in playing against humans. In this paper, we present ongoing work on an intelligent agent recommendation engine that suggests actions to players in order to maximise success and enjoyment, both in the space of in-game choices, as well as decisions made around play session timing in the broader context. By leveraging temporal data and appropriate models, we show that a learned representation of player psychological momentum, and of tilt, can be used, in combination with player expertise, to achieve state-of-the-art performance in preand post-draft win prediction. Our progress toward fulfilling the potential for deriving optimal recommendations is documented.},
  langid = {english},
  keywords = {League of Legends,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/GACNTEW4/White und Romano - 2020 - Scalable Psychological Momentum Forecasting in Esp.pdf}
}

@article{xiaWhatContributesSuccess2019,
  title = {What {{Contributes}} to {{Success}} in {{MOBA Games}}? {{An Empirical Study}} of {{Defense}} of the {{Ancients}} 2},
  shorttitle = {What {{Contributes}} to {{Success}} in {{MOBA Games}}?},
  author = {Xia, Bang and Wang, Huiwen and Zhou, Ronggang},
  year = {2019},
  month = jul,
  journal = {Games and Culture},
  volume = {14},
  number = {5},
  pages = {498--522},
  publisher = {{SAGE Publications}},
  issn = {1555-4120},
  doi = {10.1177/1555412017710599},
  url = {https://doi.org/10.1177/1555412017710599},
  urldate = {2023-10-05},
  abstract = {With the development of computer science and Internet technology, online games have become one of the most important sources of entertainment in daily life. Meanwhile, increasing attention has been paid to top international electronic sports (eSports) tournaments in which competitive pressure is becoming increasingly more serious. Therefore, how to win such games is a problem worth exploring. This article proposes a set of evaluation indicators for testing gameplay in Defense of the Ancients 2, which is a popular multiplayer online game. The analysis shows that the multiplayer killing indicator is an effective predictor of the game result. Furthermore, the evaluation indicators are divided into two categories: operational skills and tactical awareness. The functions of the indicators in each category are discussed. The results show that, for professional eSports teams, tactical awareness affects the multiplayer killing indicator and the game result more so than operational skills.},
  langid = {english},
  keywords = {Dota 2,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/EVE3TP9B/Xia et al. - 2019 - What Contributes to Success in MOBA Games An Empi.pdf}
}

@inproceedings{xuGradientBoostedFeature2014,
  title = {Gradient Boosted Feature Selection},
  booktitle = {Proceedings of the 20th {{ACM SIGKDD}} International Conference on {{Knowledge}} Discovery and Data Mining},
  author = {Xu, Zhixiang and Huang, Gao and Weinberger, Kilian Q. and Zheng, Alice X.},
  year = {2014},
  month = aug,
  series = {{{KDD}} '14},
  pages = {522--531},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2623330.2623635},
  url = {https://dl.acm.org/doi/10.1145/2623330.2623635},
  urldate = {2024-01-15},
  abstract = {A feature selection algorithm should ideally satisfy four conditions: reliably extract relevant features; be able to identify non-linear feature interactions; scale linearly with the number of features and dimensions; allow the incorporation of known sparsity structure. In this work we propose a novel feature selection algorithm, Gradient Boosted Feature Selection (GBFS), which satisfies all four of these requirements. The algorithm is flexible, scalable, and surprisingly straight-forward to implement as it is based on a modification of Gradient Boosted Trees. We evaluate GBFS on several real world data sets and show that it matches or outperforms other state of the art feature selection algorithms. Yet it scales to larger data set sizes and naturally allows for domain-specific side information.},
  isbn = {978-1-4503-2956-9},
  keywords = {feature selection,gradient boosting,large-scale},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/D32E8EV9/Xu et al. - 2014 - Gradient boosted feature selection.pdf}
}

@article{yangIdentifyingPatternsCombat,
  title = {Identifying {{Patterns}} in {{Combat}} That Are {{Predictive}} of {{Success}} in {{MOBA Games}}},
  author = {Yang, Pu and Harrison, Brent and Roberts, David L},
  abstract = {Multiplayer Online Battle Arena (MOBA) games rely primarily on combat to determine the ultimate outcome of the game. Combat in these types of games is highly-dynamic and can be difficult for novice players to learn. Typically, mastery of combat requires that players obtain expert knowledge through practice, which can be difficult to concisely describe. In this paper, we present a data-driven approach for discovering patterns in combat tactics that are common among winning teams in MOBA games. We model combat as a sequence of graphs and extract patterns that predict successful outcomes not just of combat, but of the entire game. To identify those patterns, we attribute features to these graphs using well known graph metrics. These features allow us to describe, in meaningful terms, how different combat tactics contribute to team success. We also present an evaluation of our methodology on the popular MOBA game, DotA 2 (Defense of the Ancients 2). Experiments show that extracted patterns achieve an 80\% prediction accuracy when testing on new game logs.},
  langid = {english},
  keywords = {Dota 2,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/BN78FU8J/Yang et al. - Identifying Patterns in Combat that are Predictive.pdf}
}

@article{yangPredictingEventsMOBA2023,
  title = {Predicting {{Events}} in {{MOBA Games}}: {{Prediction}}, {{Attribution}}, and {{Evaluation}}},
  shorttitle = {Predicting {{Events}} in {{MOBA Games}}},
  author = {Yang, Zelong and Wang, Yan and Li, Piji and Lin, Shaobin and Shi, Shuming and Huang, Shao-Lun and Bi, Wei},
  year = {2023},
  month = jun,
  journal = {IEEE Transactions on Games},
  volume = {15},
  number = {2},
  pages = {193--201},
  issn = {2475-1510},
  doi = {10.1109/TG.2022.3159704},
  url = {https://ieeexplore.ieee.org/abstract/document/9736637?casa_token=pGyrmu9M6zkAAAAA:bRG_TvNgtbgl297zcvJzStcZsQGOF0OFedkBUl2V7K11ZQMB4q6H3VO6tBzk2ZfB90CFsDXg},
  urldate = {2023-09-26},
  abstract = {The multiplayer online battle arena (MOBA) games have become increasingly popular in recent years. Consequently, many efforts have been devoted to providing pregame or in-game predictions for them. These predictions can be used in many MOBA esports-related applications, such as artificial intelligence commentator systems, in-game data analysis, and game-assistant bots. However, these works are limited in the following two aspects: the lack of sufficient in-game features and the absence of interpretability in the prediction results. These two limitations greatly restrict the practical performance and industrial application of the current works. In this work, we collect a large-scale dataset containing rich in-game features for the popular MOBA game Honor of Kings. We then propose to predict four types of prediction tasks in an interpretable way by attributing the predictions to the input features using two gradient-based attribution methods: Integrated Gradients and SmoothGrad. To evaluate the explanatory power of different models and attribution methods, a fidelity-based evaluation metric is further proposed. Finally, we evaluate the accuracy and fidelity of several competitive methods to assess how well machines predict events in MOBA games.},
  keywords = {MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/QV6R7I8B/Yang et al. - 2023 - Predicting Events in MOBA Games Prediction, Attri.pdf}
}

@misc{yangRealtimeESportsMatch2016,
  title = {Real-Time {{eSports Match Result Prediction}}},
  author = {Yang, Yifan and Qin, Tian and Lei, Yu-Heng},
  year = {2016},
  month = dec,
  number = {arXiv:1701.03162},
  eprint = {1701.03162},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1701.03162},
  url = {http://arxiv.org/abs/1701.03162},
  urldate = {2023-09-25},
  abstract = {In this paper, we try to predict the winning team of a match in the multiplayer eSports game Dota 2. To address the weaknesses of previous work, we consider more aspects of prior (pre-match) features from individual players' match history, as well as real-time (during-match) features at each minute as the match progresses. We use logistic regression, the proposed Attribute Sequence Model, and their combinations as the prediction models. In a dataset of 78362 matches where 20631 matches contain replay data, our experiments show that adding more aspects of prior features improves accuracy from 58.69\% to 71.49\%, and introducing real-time features achieves up to 93.73\% accuracy when predicting at the 40th minute.},
  archiveprefix = {arxiv},
  keywords = {Dota 2,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/XTNCHLIB/Yang et al. - 2016 - Real-time eSports Match Result Prediction.pdf}
}

@book{yongjinGlobalEsportsTransformation2021,
  title = {Global Esports: {{Transformation}} of {{Cultural Perceptions}} of {{Competitive Gaming}}},
  shorttitle = {Global Esports},
  author = {Yong Jin, Dal},
  year = {2021},
  publisher = {{Bloomsbury Academic}},
  doi = {10.5040/9781501368745},
  url = {http://www.bloomsburycollections.com/book/global-esports-transformation-of-cultural-perceptions-of-competitive-gaming},
  urldate = {2024-01-27},
  isbn = {978-1-5013-6877-6 978-1-5013-6875-2 978-1-5013-6876-9 978-1-5013-6874-5},
  langid = {english},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/ESWB3S27/Yong Jin - 2021 - Global esports Transformation of Cultural Percept.pdf}
}

@book{yuMOBASliceTimeSlice2018,
  title = {{{MOBA-Slice}}: {{A Time Slice Based Evaluation Framework}} of {{Relative Advantage}} between {{Teams}} in {{MOBA Games}}},
  shorttitle = {{{MOBA-Slice}}},
  author = {Yu, Lijun and Zhang, Dawei and Chen, Xiangqun and Xie, Xing},
  year = {2018},
  month = jul,
  abstract = {Multiplayer Online Battle Arena (MOBA) is currently one of the most popular genres of digital games around the world. The domain of knowledge contained in these complicated games is large. It is hard for humans and algorithms to evaluate the real-time game situation or predict the game result. In this paper, we introduce MOBA-Slice, a time slice based evaluation framework of relative advantage between teams in MOBA games. MOBA-Slice is a quantitative evaluation method based on learning, similar to the value network of AlphaGo. It establishes a foundation for further MOBA related research including AI development. In MOBA-Slice, with an analysis of the deciding factors of MOBA game results, we design a neural network model to fit our discounted evaluation function. Then we apply MOBA-Slice to Defense of the Ancients 2 (DotA2), a typical and popular MOBA game. Experiments on a large number of match replays show that our model works well on arbitrary matches. MOBA-Slice not only has an accuracy 3.7\% higher than DotA Plus Assistant at result prediction, but also supports the prediction of the remaining time of the game, and then realizes the evaluation of relative advantage between teams.},
  keywords = {Dota 2,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/U9PWHFP4/Yu et al. - 2018 - MOBA-Slice A Time Slice Based Evaluation Framewor.pdf}
}

@article{yuReviewRecurrentNeural2019,
  title = {A {{Review}} of {{Recurrent Neural Networks}}: {{LSTM Cells}} and {{Network Architectures}}},
  shorttitle = {A {{Review}} of {{Recurrent Neural Networks}}},
  author = {Yu, Yong and Si, Xiaosheng and Hu, Changhua and Zhang, Jianxun},
  year = {2019},
  month = jul,
  journal = {Neural Computation},
  volume = {31},
  number = {7},
  pages = {1235--1270},
  issn = {0899-7667},
  doi = {10.1162/neco_a_01199},
  url = {https://doi.org/10.1162/neco_a_01199},
  urldate = {2023-11-07},
  abstract = {Recurrent neural networks (RNNs) have been widely adopted in research areas concerned with sequential data, such as text, audio, and video. However, RNNs consisting of sigma cells or tanh cells are unable to learn the relevant information of input data when the input gap is large. By introducing gate functions into the cell structure, the long short-term memory (LSTM) could handle the problem of long-term dependencies well. Since its introduction, almost all the exciting results based on RNNs have been achieved by the LSTM. The LSTM has become the focus of deep learning. We review the LSTM cell and its variants to explore the learning capacity of the LSTM cell. Furthermore, the LSTM networks are divided into two broad categories: LSTM-dominated networks and integrated LSTM networks. In addition, their various applications are discussed. Finally, future research directions are presented for LSTM networks.},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/2MKNGEIB/A-Review-of-Recurrent-Neural-Networks-LSTM-Cells.html}
}

@inproceedings{zangAutomatedChessCommentator2019,
  title = {Automated {{Chess Commentator Powered}} by {{Neural Chess Engine}}},
  booktitle = {Proceedings of the 57th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Zang, Hongyu and Yu, Zhiwei and Wan, Xiaojun},
  year = {2019},
  pages = {5952--5961},
  publisher = {{Association for Computational Linguistics}},
  address = {{Florence, Italy}},
  doi = {10.18653/v1/P19-1597},
  url = {https://www.aclweb.org/anthology/P19-1597},
  urldate = {2024-03-06},
  abstract = {In this paper, we explore a new approach for automated chess commentary generation, which aims to generate chess commentary texts in different categories (e.g., description, comparison, planning, etc.). We introduce a neural chess engine into text generation models to help with encoding boards, predicting moves, and analyzing situations. By jointly training the neural chess engine and the generation models for different categories, the models become more effective. We conduct experiments on 5 categories in a benchmark Chess Commentary dataset and achieve inspiring results in both automatic and human evaluations.},
  langid = {english},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/3VQL5JYH/Zang et al. - 2019 - Automated Chess Commentator Powered by Neural Ches.pdf}
}

@inproceedings{zhangGeneralizedCrossEntropy2018,
  title = {Generalized {{Cross Entropy Loss}} for {{Training Deep Neural Networks}} with {{Noisy Labels}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Zhang, Zhilu and Sabuncu, Mert},
  year = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper_files/paper/2018/hash/f2925f97bc13ad2852a7a551802feea0-Abstract.html},
  urldate = {2023-11-02},
  abstract = {Deep neural networks (DNNs) have achieved tremendous success in a variety of applications across many disciplines. Yet, their superior performance comes with the expensive cost of requiring correctly annotated large-scale datasets. Moreover, due to DNNs' rich capacity, errors in training labels can hamper performance. To combat this problem, mean absolute error (MAE) has recently been proposed as a noise-robust alternative to the commonly-used categorical cross entropy (CCE) loss. However, as we show in this paper, MAE can perform poorly with DNNs and large-scale datasets. Here, we present a theoretically grounded set of noise-robust loss functions that can be seen as a generalization of MAE and CCE. Proposed loss functions can be readily applied with any existing DNN architecture and algorithm, while yielding good performance in a wide range of noisy label scenarios. We report results from experiments conducted with CIFAR-10, CIFAR-100 and FASHION-MNIST datasets and synthetically generated noisy labels.},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/KHNNGZH7/Zhang und Sabuncu - 2018 - Generalized Cross Entropy Loss for Training Deep N.pdf}
}

@inproceedings{zhangPredictionEsportsGame2021,
  title = {Prediction of {{Esports Game Results Using Early Game Datasets}}},
  booktitle = {{{ICMLCA}} 2021; 2nd {{International Conference}} on {{Machine Learning}} and {{Computer Application}}},
  author = {Zhang, Yunhai},
  year = {2021},
  month = dec,
  pages = {1--6},
  url = {https://ieeexplore.ieee.org/abstract/document/9736891},
  urldate = {2023-10-05},
  abstract = {Large e-sports games are becoming prevailing at an unprecedented around the world in recent years. Thus, an increasing amount of effort is put into game-predictions for worldwide audiences. However, most of the game prediction results are restricted by both the high uncertainty at the early-game stage, and the hardship of interpreting them for audiences. In this paper, we mainly focus on predicting the game results for one of the most popular games, League of Legends, using the first ten minute in-game features. This research uses Active Learning as the main method to evaluate the dataset that contains approximately ten thousand high-Elo ranked games. Then, the research compares the results of prediction based on our active learning algorithms and the random selection methods. The research experiment finally presents that the prediction result of the active learning model is similar to that of the traditional machine learning methods and outweigh the accuracy of random selection. The paper can conclude that we may save a lot of human-needed work and use a relatively small amount of initial datasets to generate more accurate game predictions by implementing active learning in large data-based e-sports matches.},
  keywords = {League of Legends,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/4ZFJA4YH/Zhang - 2021 - Prediction of Esports Game Results Using Early Gam.pdf}
}

@article{zhaoMachineHealthMonitoring2018,
  title = {Machine {{Health Monitoring Using Local Feature-Based Gated Recurrent Unit Networks}}},
  author = {Zhao, Rui and Wang, Dongzhe and Yan, Ruqiang and Mao, Kezhi and Shen, Fei and Wang, Jinjiang},
  year = {2018},
  month = feb,
  journal = {IEEE Transactions on Industrial Electronics},
  volume = {65},
  number = {2},
  pages = {1539--1548},
  issn = {1557-9948},
  doi = {10.1109/TIE.2017.2733438},
  url = {https://ieeexplore.ieee.org/abstract/document/7997605?casa_token=u7k-YBUjNT0AAAAA:e9PEPAki0WeYV3o2jnV11-sDpj3Cnuz0jEwwn_dBHJOPNOyxOqManHOqaNqez4VhIb5YRdZxgeDE},
  urldate = {2024-02-24},
  abstract = {In modern industries, machine health monitoring systems (MHMS) have been applied wildly with the goal of realizing predictive maintenance including failures tracking, downtime reduction, and assets preservation. In the era of big machinery data, data-driven MHMS have achieved remarkable results in the detection of faults after the occurrence of certain failures (diagnosis) and prediction of the future working conditions and the remaining useful life (prognosis). The numerical representation for raw sensory data is the key stone for various successful MHMS. Conventional methods are the labor-extensive as they usually depend on handcrafted features, which require expert knowledge. Inspired by the success of deep learning methods that redefine representation learning from raw data, we propose local feature-based gated recurrent unit (LFGRU) networks. It is a hybrid approach that combines handcrafted feature design with automatic feature learning for machine health monitoring. First, features from windows of input time series are extracted. Then, an enhanced bidirectional GRU network is designed and applied on the generated sequence of local features to learn the representation. A supervised learning layer is finally trained to predict machine condition. Experiments on three machine health monitoring tasks: tool wear prediction, gearbox fault diagnosis, and incipient bearing fault detection verify the effectiveness and generalization of the proposed LFGRU.},
  keywords = {Computational modeling,Data mining,Fault diagnosis,feature engineering,Feature extraction,gated recurrent unit (GRU),Logic gates,machine health monitoring (MHM),Monitoring,Sensors,tool wear prediction},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/KBNFD6FE/Zhao et al. - 2018 - Machine Health Monitoring Using Local Feature-Base.pdf;/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/MRMKLIZH/7997605.html}
}

@inproceedings{zhaoWinningTrackerNew2022,
  title = {Winning {{Tracker}}: {{A New Model}} for {{Real-time Winning Prediction}} in {{MOBA Games}}},
  shorttitle = {Winning {{Tracker}}},
  booktitle = {Proceedings of the {{ACM Web Conference}} 2022},
  author = {Zhao, Chuang and Zhao, Hongke and Ge, Yong and Wu, Runze and Shen, Xudong},
  year = {2022},
  month = apr,
  pages = {3387--3395},
  publisher = {{ACM}},
  address = {{Virtual Event, Lyon France}},
  doi = {10.1145/3485447.3512274},
  url = {https://dl.acm.org/doi/10.1145/3485447.3512274},
  urldate = {2023-09-25},
  abstract = {With an increasing popularity, Multiplayer Online Battle Arena (MOBA) games where two opposing teams compete against each other, have played a major role in E-sports tournaments. Among game analysis, real-time winning prediction is an important but challenging problem, which is mainly due to the complicated coupling of the overall Confrontation1, the excessive noise of the player's Movement, and unclear optimization goals. Existing research is difficult to solve this problem in a dynamic, comprehensive and systematic way. In this study, we design a unified framework, namely Winning Tracker (WT), for solving this problem. Specifically, offense and defense extractors are developed to extract the Confrontation of both sides. A well-designed trajectory representation algorithm is applied to extracting individual's Movement information. Moreover, we design a hierarchical attention mechanism to capture team-level strategies and facilitate the interpretability of the framework. To optimize accurately, we adopt a multi-task learning method to design short-term and long-term goals, which are used to represent immediate state and make end-state prediction respectively. Intensive experiments on a real-world data set demonstrate that our proposed method WT outperforms state-of-the-art algorithms. Furthermore, our work has been practically deployed in real MOBA games, and provided case studies reflecting its outstanding commercial value.},
  isbn = {978-1-4503-9096-5},
  langid = {english},
  keywords = {Dota 2,MOBA,notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/FA98I9RA/Zhao et al. - 2022 - Winning Tracker A New Model for Real-time Winning.pdf}
}

@article{zhouServingDeepLearning2022,
  title = {Serving {{Deep Learning Models}} with {{Deduplication}} from {{Relational Databases}}},
  author = {Zhou, Lixi and Chen, Jiaqing and Das, Amitabh and Min, Hong and Yu, Lei and Zhao, Ming and Zou, Jia},
  year = {2022},
  month = jun,
  journal = {Proceedings of the VLDB Endowment},
  volume = {15},
  number = {10},
  eprint = {2201.10442},
  primaryclass = {cs},
  pages = {2230--2243},
  issn = {2150-8097},
  doi = {10.14778/3547305.3547325},
  url = {http://arxiv.org/abs/2201.10442},
  urldate = {2023-09-10},
  abstract = {There are significant benefits to serve deep learning models from relational databases. First, features extracted from databases do not need to be transferred to any decoupled deep learning systems for inferences, and thus the system management overhead can be significantly reduced. Second, in a relational database, data management along the storage hierarchy is fully integrated with query processing, and thus it can continue model serving even if the working set size exceeds the available memory. Applying model deduplication can greatly reduce the storage space, memory footprint, cache misses, and inference latency. However, existing data deduplication techniques are not applicable to the deep learning model serving applications in relational databases. They do not consider the impacts on model inference accuracy as well as the inconsistency between tensor blocks and database pages. This work proposed synergistic storage optimization techniques for duplication detection, page packing, and caching, to enhance database systems for model serving. We implemented the proposed approach in netsDB, an object-oriented relational database. Evaluation results show that our proposed techniques significantly improved the storage efficiency and the model inference latency, and serving models from relational databases outperformed existing deep learning frameworks when the working set size exceeds available memory.},
  archiveprefix = {arxiv},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/244A35X9/Zhou et al. - 2022 - Serving Deep Learning Models with Deduplication fr.pdf}
}

@inproceedings{zhuComparisonLossFunctions2018,
  title = {Comparison of {{Loss Functions}} for {{Training}} of {{Deep Neural Networks}} in {{Shogi}}},
  booktitle = {2018 {{Conference}} on {{Technologies}} and {{Applications}} of {{Artificial Intelligence}} ({{TAAI}})},
  author = {Zhu, Hanhua and Kaneko, Tomoyuki},
  year = {2018},
  month = nov,
  pages = {18--23},
  issn = {2376-6824},
  doi = {10.1109/TAAI.2018.00014},
  url = {https://ieeexplore.ieee.org/abstract/document/8588470?casa_token=VdYFRHjjBW0AAAAA:IuCvfctbF0dH5nK_FXUEaAzuhIzWrwSnh2Pq8mKZInUGjADDrYyGYf81FiLcM4EzHvAY4nonFA},
  urldate = {2023-11-02},
  abstract = {Evaluation functions are crucial for building strong computer players in two-player games, such as chess, Go, and shogi. Although a linear combination of a large number of features has been popular representation of an evaluation function in shogi, deep neural networks (DNNs) are recently considered to be more promising by the success of AlphaZero in multiple domains, chess, Go, and shogi. This paper shows that three loss functions, loss in comparison training, temporal difference (TD) errors and cross entropy loss in win prediction, are effective for the training of evaluation functions in shogi, presented in deep neural networks. For the training of DNNs in AlphaZero, the main loss function only consists of win prediction, though it is augmented with move prediction for regularization. On the other hand, for training in traditional shogi programs, various losses including loss in comparison training, TD errors, and cross entropy loss in win prediction, have contributed to yield accurate evaluation functions which are the linear combination of a large number of features. Therefore, it is promising to combine these loss functions and to apply them to the training of modern DNNs. In our experiments, we show that training with combinations of loss functions improved the accuracy of evaluation functions represented by DNNs. The performance of trained evaluation functions is tested through top-1 accuracy, 1-1 accuracy, and self-play.},
  keywords = {notion},
  file = {/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/Thesis/literature/Zotero/storage/EY34ZHHB/Zhu und Kaneko - 2018 - Comparison of Loss Functions for Training of Deep .pdf}
}
