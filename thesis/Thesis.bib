@online{2022Recap,
  title = {2022 {{Recap}}},
  url = {https://yearin.lol},
  urldate = {2023-12-19},
  abstract = {Your recap for the year 2022 in League of Legends. Check out your multikill performance, total playtime, overall damage dealt, and much more.},
  langid = {english},
  organization = {{YearIn.LoL}},
  file = {C:\Users\morit\Zotero\storage\9TWVLPMY\yearin.lol.html}
}

@article{aeschbachPsychologyEsportsPlayers2023,
  title = {The Psychology of Esports Players’ {{ELO Hell}}: {{Motivated}} Bias in {{League}} of {{Legends}} and Its Impact on Players’ Overestimation of Skill},
  shorttitle = {The Psychology of Esports Players’ {{ELO Hell}}},
  author = {Aeschbach, Lena Fanya and Kayser, Dominik and Berbert De Castro Hüsler, Antony and Opwis, Klaus and Brühlmann, Florian},
  date = {2023-10},
  journaltitle = {Computers in Human Behavior},
  shortjournal = {Computers in Human Behavior},
  volume = {147},
  pages = {107828},
  issn = {07475632},
  doi = {10.1016/j.chb.2023.107828},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0747563223001796},
  urldate = {2023-11-09},
  abstract = {This paper examines the folk theory of ELO Hell, which stems from the community of esports players. ELO Hell is a causal explanation for the failure to achieve which is prominent but controversial in esports. Within the community, the belief in the existence of ELO Hell associated with lower skill. We aim to explain the persistence of this folk theory despite the debate within the community using psychological theories. We find this folk theory relevant for investigation because the blame placed on other players could escalate to patterns of harmful behavior, known as toxicity. Given the association with lower-ranked players, we predict this could be an operationalization of the Dunning–Kruger effect, a tendency for lower-skilled performers to overestimate themselves, and its associated motivational biases. Surveying 267 players of the esports League of Legends and triangulating the quantitative, qualitative, and mined data collected, we find evidence of lowerskilled players overestimating their skills more so than higher-skilled players. Further, we find that motivational biases regarding causal attributions for failure and success did explain significant variance in the degree of overestimation. However, we also found some players withdraw their effort from competitive play and we use self-determination theory to categorize their reason for losing motivation. Taken together, we show the psychological mechanisms which lead to the formation of the folk theory of ELO Hell and the motivational biases that uphold the conflict about its existence.},
  langid = {english},
  keywords = {League of Legends,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\GN9T5QU6\Aeschbach et al. - 2023 - The psychology of esports players’ ELO Hell Motiv.pdf}
}

@article{ahnOneBillionDollar2020,
  title = {The One Billion Dollar Myth: {{Methods}} for Sizing the Massively Undervalued Esports Revenue Landscape},
  shorttitle = {The One Billion Dollar Myth},
  author = {Ahn, Joseph and Collis, William and Jenny, Seth},
  date = {2020-10-04},
  journaltitle = {International Journal of Esports},
  shortjournal = {IJE},
  volume = {1},
  number = {1},
  issn = {2634-1069},
  url = {https://www.ijesports.org/article/15/html},
  urldate = {2023-12-09},
  abstract = {It is our contention that the 2019 esports industry’s revenue size is massively undervalued at \$1.1B USD within the literature. This paper provides a more accurate sizing of the esports landscape, incorporating into the analysis six major sectors of the esports industry: 1) teams, professional players, and streamers, 2) game publishers, 3) streaming platforms, 4) physical products, 5) leagues and tournaments, and 6) digital tools. Each sector is discussed separately, with descriptions of the business models and corresponding revenue equations that drive each sector’s revenue estimates. Overall, we purport that \$24.9B USD is a more accurate estimation of the “true” market size of esports for 2019.},
  issue = {1},
  langid = {english},
  file = {C:\Users\morit\Zotero\storage\E5GNQZCI\Ahn et al. - 2020 - The one billion dollar myth Methods for sizing th.pdf}
}

@online{akhmedovMachineLearningModels2021,
  title = {Machine Learning Models for {{DOTA}} 2 Outcomes Prediction},
  author = {Akhmedov, Kodirjon and Phan, Anh Huy},
  date = {2021-06-03},
  eprint = {2106.01782},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2106.01782},
  urldate = {2023-11-14},
  abstract = {Prediction of the real-time multiplayer online battle arena (MOBA) games’ match outcome is one of the most important and exciting tasks in Esports analytical research. This research paper predominantly focuses on building predictive machine and deep learning models to identify the outcome of the Dota 2 MOBA game using the new method of multi-forward steps predictions. Three models were investigated and compared: Linear Regression (LR), Neural Networks (NN), and a type of recurrent neural network Long Short-Term Memory (LSTM). In order to achieve the goals, we developed a data collecting python server using Game State Integration (GSI) to track the real-time data of the players. Once the exploratory feature analysis and tuning hyper-parameters were done, our models’ experiments took place on different players with dissimilar backgrounds of playing experiences. The achieved accuracy scores depend on the multi-forward prediction parameters, which for the worse case in linear regression 69\% but on average 82\%, while in the deep learning models hit the utmost accuracy of prediction on average 88\% for NN, and 93\% for LSTM models.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Dota 2,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\57WTCEMB\Akhmedov und Phan - 2021 - Machine learning models for DOTA 2 outcomes predic.pdf}
}

@inproceedings{aniVictoryPredictionLeague2019,
  title = {Victory Prediction in {{League}} of {{Legends}} Using {{Feature Selection}} and {{Ensemble}} Methods},
  booktitle = {2019 {{International Conference}} on {{Intelligent Computing}} and {{Control Systems}} ({{ICCS}})},
  author = {Ani, R. and Harikumar, Vishnu and Devan, Arjun K. and Deepa, O.S.},
  date = {2019-05},
  pages = {74--77},
  doi = {10.1109/ICCS45141.2019.9065758},
  url = {https://ieeexplore.ieee.org/abstract/document/9065758},
  urldate = {2023-10-05},
  abstract = {Prediction of winners in the online video games has become an important application for machine learning based prediction models. The main goal of the present study is to achieve a good prediction rate for a popular Electronic sport called League of Legends. League of Legends is a Multiplayer Online Battle Arena (MOBA) game that combines intensity of a Real-time strategy with various Role-playing elements. Feature selection is done and only relevant features that affect the match outcomes are considered. Prediction is done by using ensemble models of classification algorithms and the performance was evaluated. The important performance metrics and their influence on each game model were also analyzed. The results show that the reliable match result prediction is possible in the League of Legends game.},
  eventtitle = {2019 {{International Conference}} on {{Intelligent Computing}} and {{Control Systems}} ({{ICCS}})},
  keywords = {League of Legends,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\WBKJXZVI\Ani et al. - 2019 - Victory prediction in League of Legends using Feat.pdf}
}

@online{aratBackpropagationTimeRecurrent2019,
  title = {Backpropagation {{Through Time}} for {{Recurrent Neural Network}}},
  author = {Arat, Mustafa Murat},
  date = {2019-02-07T00:00:00+00:00},
  url = {https://mmuratarat.github.io//2019-02-07/bptt-of-rnn},
  urldate = {2023-12-21},
  abstract = {Homepage},
  langid = {english},
  organization = {{Mustafa Murat ARAT}},
  file = {C:\Users\morit\Zotero\storage\WTR7U3TV\bptt-of-rnn.html}
}

@online{Asec4RNNs_notes_209b2019Pdf,
  title = {A-Sec4-{{RNNs}}\_notes\_209b2019.Pdf},
  url = {https://harvard-iacs.github.io/2019-CS109B/a-sections/a-section4/notes/a-sec4-RNNs_notes_209b2019.pdf},
  urldate = {2023-12-22}
}

@article{bahrololloomiESportsPlayerPerformance2023,
  title = {E-{{Sports Player Performance Metrics}} for {{Predicting}} the {{Outcome}} of {{League}} of {{Legends Matches Considering Player Roles}}},
  author = {Bahrololloomi, Farnod and Klonowski, Fabio and Sauer, Sebastian and Horst, Robin and Dörner, Ralf},
  date = {2023-03-02},
  journaltitle = {SN Computer Science},
  shortjournal = {SN COMPUT. SCI.},
  volume = {4},
  number = {3},
  pages = {238},
  issn = {2661-8907},
  doi = {10.1007/s42979-022-01660-6},
  url = {https://doi.org/10.1007/s42979-022-01660-6},
  urldate = {2023-10-05},
  abstract = {Predicting results in electronic sports (e-sports) matches is not an easy task. Different methods can be used for this purpose. A well-known video game in the field of Multiplayer Online Battle Arena (MOBA) is the game League of Legends (LoL), which has a relevant professional scene. An important part of professional gaming is analyzing past matches overall and an individual player’s performance to prepare for future matches. In this paper, we follow a design-oriented research methodology (analysis, design, and evaluation) and propose performance metrics that use data from past matches to evaluate a player’s performance. We analyze the necessary data which we acquire by selecting a player, analyzing the player’s latest games, and repeating the process recursively with the players found in his latest games. The data is utilized within a Machine Learning (ML) Model that computes an overall score from individual player variables. From this, we designed a heuristic approach and evaluated it by applying it to the challenge of winning predictions in e-sports. The difference in the influence of the individual player roles on the outcome of the game was also investigated. It was found that this difference is negligible and that the heuristic performance metric can predict the outcome of a game with an accuracy of 86\%. Furthermore, the concept of a match calculator is explored, which calculates the outcome of a match using the ML model and different player stats.},
  langid = {english},
  keywords = {League of Legends,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\953LIA25\Bahrololloomi et al. - 2023 - E-Sports Player Performance Metrics for Predicting.pdf}
}

@inproceedings{bahrololloomiMachineLearningBased2022,
  title = {A {{Machine Learning}} Based {{Analysis}} of E-{{Sports Player Performances}} in {{League}} of {{Legends}} for {{Winning Prediction}} Based on {{Player Roles}} and {{Performances}}.},
  booktitle = {{{VISIGRAPP}} (2: {{HUCAPP}})},
  author = {Bahrololloomi, Farnod and Sauer, Sebastian and Klonowski, Fabio and Horst, Robin and Dörner, Ralf},
  date = {2022},
  pages = {68--76},
  keywords = {League of Legends,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\FT3J4CE5\Bahrololloomi et al. - 2022 - A Machine Learning based Analysis of e-Sports Play.pdf}
}

@article{baileyStatisticalLearningEsports,
  title = {Statistical {{Learning}} for {{Esports Match Prediction}}},
  author = {Bailey, Kevin},
  langid = {english},
  keywords = {League of Legends,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\AGMXMZHG\Bailey - Statistical Learning for Esports Match Prediction.pdf}
}

@article{battitiUsingMutualInformation1994,
  title = {Using Mutual Information for Selecting Features in Supervised Neural Net Learning},
  author = {Battiti, R.},
  date = {1994-07},
  journaltitle = {IEEE Transactions on Neural Networks},
  volume = {5},
  number = {4},
  pages = {537--550},
  issn = {1941-0093},
  doi = {10.1109/72.298224},
  url = {https://ieeexplore.ieee.org/abstract/document/298224?casa_token=fEbzH5lqsegAAAAA:0qJA2Bd57gByZu8lV1uUXyqF9iRs1nv9_LEVNI07OqO9Rg0cb1D_IwYe1m-wnHk1vFPIRFSpLA},
  urldate = {2023-12-25},
  abstract = {This paper investigates the application of the mutual information criterion to evaluate a set of candidate features and to select an informative subset to be used as input data for a neural network classifier. Because the mutual information measures arbitrary dependencies between random variables, it is suitable for assessing the "information content" of features in complex classification tasks, where methods bases on linear relations (like the correlation) are prone to mistakes. The fact that the mutual information is independent of the coordinates chosen permits a robust estimation. Nonetheless, the use of the mutual information for tasks characterized by high input dimensionality requires suitable approximations because of the prohibitive demands on computation and samples. An algorithm is proposed that is based on a "greedy" selection of the features and that takes both the mutual information with respect to the output class and with respect to the already-selected features into account. Finally the results of a series of experiments are discussed.{$<>$}},
  eventtitle = {{{IEEE Transactions}} on {{Neural Networks}}},
  file = {C\:\\Users\\morit\\Zotero\\storage\\LWL9Q7KM\\Battiti - 1994 - Using mutual information for selecting features in.pdf;C\:\\Users\\morit\\Zotero\\storage\\67VPBKEC\\298224.html}
}

@article{bengioLearningLongtermDependencies1994,
  title = {Learning Long-Term Dependencies with Gradient Descent Is Difficult},
  author = {Bengio, Y. and Simard, P. and Frasconi, P.},
  date = {1994-03},
  journaltitle = {IEEE Transactions on Neural Networks},
  volume = {5},
  number = {2},
  pages = {157--166},
  issn = {1941-0093},
  doi = {10.1109/72.279181},
  url = {https://ieeexplore.ieee.org/abstract/document/279181?casa_token=f5w3HVDYejMAAAAA:oY_D8xnIsGbMdzLZuRzFwX-ED93aitQCWu85Y_VyBD1jmYf_KD9ILUZ8gknQ8ONf34w6LUU},
  urldate = {2023-11-07},
  abstract = {Recurrent neural networks can be used to map input sequences to output sequences, such as for recognition, production or prediction problems. However, practical difficulties have been reported in training recurrent neural networks to perform tasks in which the temporal contingencies present in the input/output sequences span long intervals. We show why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases. These results expose a trade-off between efficient learning by gradient descent and latching on information for long periods. Based on an understanding of this problem, alternatives to standard gradient descent are considered.{$<>$}},
  eventtitle = {{{IEEE Transactions}} on {{Neural Networks}}},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\IZCICZ59\Bengio et al. - 1994 - Learning long-term dependencies with gradient desc.pdf}
}

@inproceedings{bridleProbabilisticInterpretationFeedforward1990,
  title = {Probabilistic {{Interpretation}} of {{Feedforward Classification Network Outputs}}, with {{Relationships}} to {{Statistical Pattern Recognition}}},
  booktitle = {Neurocomputing},
  author = {Bridle, John S.},
  editor = {Soulié, Françoise Fogelman and Hérault, Jeanny},
  date = {1990},
  series = {{{NATO ASI Series}}},
  pages = {227--236},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-76153-9_28},
  abstract = {We are concerned with feed-forward non-linear networks (multi-layer perceptrons, or MLPs) with multiple outputs. We wish to treat the outputs of the network as probabilities of alternatives (e.g. pattern classes), conditioned on the inputs. We look for appropriate output non-linearities and for appropriate criteria for adaptation of the parameters of the network (e.g. weights). We explain two modifications: probability scoring, which is an alternative to squared error minimisation, and a normalised exponential (softmax) multi-input generalisation of the logistic non-linearity. The two modifications together result in quite simple arithmetic, and hardware implementation is not difficult either. The use of radial units (squared distance instead of dot product) immediately before the softmax output stage produces a network which computes posterior distributions over class labels based on an assumption of Gaussian within-class distributions. However the training, which uses cross-class information, can result in better performance at class discrimination than the usual within-class training method, unless the within-class distribution assumptions are actually correct.},
  isbn = {978-3-642-76153-9},
  langid = {english},
  keywords = {Boltzmann Machine,Class Label,Hide Markov Model,Posterior Distribution,Statistical Pattern Recognition}
}

@incollection{chanArtificialIntelligenceVideo2022,
  title = {Artificial {{Intelligence}} in {{Video Games}} and {{eSports}}},
  booktitle = {Applied {{Artificial Intelligence}} in {{Business}}: {{Concepts}} and {{Cases}}},
  author = {Chan, Leong and Hogaboam, Liliya and Cao, Renzhi},
  editor = {Chan, Leong and Hogaboam, Liliya and Cao, Renzhi},
  date = {2022},
  series = {Applied {{Innovation}} and {{Technology Management}}},
  pages = {335--352},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-031-05740-3_22},
  url = {https://doi.org/10.1007/978-3-031-05740-3_22},
  urldate = {2023-09-26},
  abstract = {This chapter starts with the introduction and the evolution of AI in gaming and esports. It explores the enabling technologies for AI in gaming (big data, virtual reality, AI chips and GPUs, online gaming, and cloud platforms). AI applications in video games and esports include AI Opponents, AI NPCs, procedural content generation, player experience modeling, antisocial behavior detection, win prediction, player telemetry analytics, intelligent tutoring, and training. Case studies section consists of DeepMind Alpha Go, Alpha Star, and Microsoft HoloLens.},
  isbn = {978-3-031-05740-3},
  langid = {english},
  keywords = {MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\IAFMRCVL\Chan et al. - 2022 - Artificial Intelligence in Video Games and eSports.pdf}
}

@article{chandrashekarSurveyFeatureSelection2014,
  title = {A Survey on Feature Selection Methods},
  author = {Chandrashekar, Girish and Sahin, Ferat},
  date = {2014-01},
  journaltitle = {Computers \& Electrical Engineering},
  shortjournal = {Computers \& Electrical Engineering},
  volume = {40},
  number = {1},
  pages = {16--28},
  issn = {00457906},
  doi = {10.1016/j.compeleceng.2013.11.024},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0045790613003066},
  urldate = {2023-12-01},
  abstract = {Plenty of feature selection methods are available in literature due to the availability of data with hundreds of variables leading to data with very high dimension. Feature selection methods provides us a way of reducing computation time, improving prediction performance, and a better understanding of the data in machine learning or pattern recognition applications. In this paper we provide an overview of some of the methods present in literature. The objective is to provide a generic introduction to variable elimination which can be applied to a wide array of machine learning problems. We focus on Filter, Wrapper and Embedded methods. We also apply some of the feature selection techniques on standard datasets to demonstrate the applicability of feature selection techniques.},
  langid = {english},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\CXWEB3I6\Chandrashekar und Sahin - 2014 - A survey on feature selection methods.pdf}
}

@inproceedings{chenXGBoostScalableTree2016,
  title = {{{XGBoost}}: {{A Scalable Tree Boosting System}}},
  shorttitle = {{{XGBoost}}},
  booktitle = {Proceedings of the 22nd {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Chen, Tianqi and Guestrin, Carlos},
  date = {2016-08-13},
  series = {{{KDD}} '16},
  pages = {785--794},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/2939672.2939785},
  url = {https://dl.acm.org/doi/10.1145/2939672.2939785},
  urldate = {2023-12-02},
  abstract = {Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.},
  isbn = {978-1-4503-4232-2},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\WS9PDQHT\Chen und Guestrin - 2016 - XGBoost A Scalable Tree Boosting System.pdf}
}

@online{choLearningPhraseRepresentations2014,
  title = {Learning {{Phrase Representations}} Using {{RNN Encoder-Decoder}} for {{Statistical Machine Translation}}},
  author = {Cho, Kyunghyun and family=Merrienboer, given=Bart, prefix=van, useprefix=true and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  date = {2014-09-02},
  eprint = {1406.1078},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1406.1078},
  url = {http://arxiv.org/abs/1406.1078},
  urldate = {2023-11-03},
  abstract = {In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-length vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.},
  pubstate = {preprint},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\SMU6BTJW\Cho et al. - 2014 - Learning Phrase Representations using RNN Encoder-.pdf}
}

@online{chungEmpiricalEvaluationGated2014,
  title = {Empirical {{Evaluation}} of {{Gated Recurrent Neural Networks}} on {{Sequence Modeling}}},
  author = {Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
  date = {2014-12-11},
  eprint = {1412.3555},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1412.3555},
  urldate = {2023-09-26},
  abstract = {In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM.},
  langid = {english},
  pubstate = {preprint},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\DCTY8S5M\Chung et al. - 2014 - Empirical Evaluation of Gated Recurrent Neural Net.pdf}
}

@inproceedings{cleghernPredictingFutureStates2017,
  title = {Predicting Future States in {{DotA}} 2 Using Value-Split Models of Time Series Attribute Data},
  booktitle = {Proceedings of the 12th {{International Conference}} on the {{Foundations}} of {{Digital Games}}},
  author = {Cleghern, Zach and Lahiri, Soumendra and Özaltin, Osman and Roberts, David L.},
  date = {2017-08-14},
  series = {{{FDG}} '17},
  pages = {1--10},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3102071.3102095},
  url = {https://dl.acm.org/doi/10.1145/3102071.3102095},
  urldate = {2023-10-05},
  abstract = {In Multiplayer Online Battle Arena (MOBA) games, teams of players compete in combat to complete an objective and defeat the opposing team. To stay alive, players must closely monitor their character's status, especially remaining health. Understanding how health may change in the near future can be vital in determining what tactics a player may use. We analyzed replay logs of the game Defense of the Ancients 2 (DotA 2) to discover methods to predict how players' health evolves over time. For DotA 2, our results suggest that forecasting changes in a player's health can be done by viewing gameplay as two separate processes: normal gameplay flow in which changes in health are smaller and more regular, and less frequent but higher-impact events in which players experience larger changes in their health, such as team battles. We accomplished this by considering health data as two separate, but interleaved, time series in which separate processes govern low magnitude changes in health from high magnitude changes. In this paper, we present a value-split approach to predicting changes in health and describe the results of our approach using autoregressive moving-average models for low magnitude health changes and a combination of statistical models for the larger changes.},
  isbn = {978-1-4503-5319-9},
  keywords = {Dota 2,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\8FVL6WXT\Cleghern et al. - 2017 - Predicting future states in DotA 2 using value-spl.pdf}
}

@inproceedings{costaFeatureAnalysisLeague2021,
  title = {Feature {{Analysis}} to {{League}} of {{Legends Victory Prediction}} on the {{Picks}} and {{Bans Phase}}},
  booktitle = {2021 {{IEEE Conference}} on {{Games}} ({{CoG}})},
  author = {Costa, Lincoln Magalhães and Mantovani, Rafael Gomes and Monteiro Souza, Francisco Carlos and Xexéo, Geraldo},
  date = {2021-08},
  pages = {01--05},
  issn = {2325-4289},
  doi = {10.1109/CoG52621.2021.9619019},
  url = {https://ieeexplore.ieee.org/abstract/document/9619019},
  urldate = {2023-10-05},
  abstract = {Victory prediction in online video games has become an important application for machine learning due to the large amount of data generated by these games and their growing popularity. The creation of professional leagues also drives these applications, as teams want to know their chances of victory and know what are the determining factors to achieve it. Thus, in this research, we analyze whether pre-game information can be explored for victory prediction of professional matches of League of Legends (LoL), one of the main MOBA games. In experiments, we benchmarked different feature sets and algorithms to assess the victory predictions in LoL. The results show that historical performance information is the most accurate features for performing this task. The induced models, especially Random Forest and Logistic Regression, achieved AUC values of 0.97.},
  eventtitle = {2021 {{IEEE Conference}} on {{Games}} ({{CoG}})},
  keywords = {League of Legends,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\XXV82RQE\Costa et al. - 2021 - Feature Analysis to League of Legends Victory Pred.pdf}
}

@inproceedings{deyGatevariantsGatedRecurrent2017,
  title = {Gate-Variants of {{Gated Recurrent Unit}} ({{GRU}}) Neural Networks},
  booktitle = {2017 {{IEEE}} 60th {{International Midwest Symposium}} on {{Circuits}} and {{Systems}} ({{MWSCAS}})},
  author = {Dey, Rahul and Salem, Fathi M.},
  date = {2017-08},
  pages = {1597--1600},
  issn = {1558-3899},
  doi = {10.1109/MWSCAS.2017.8053243},
  url = {https://ieeexplore.ieee.org/abstract/document/8053243?casa_token=aP9ZzK6D-7sAAAAA:FtaEMxjEzG7XgdwG6MKDiwSz1lZ2FDyft_3QzXh4WR8hI6TRH2o-WxoHZZ8DOIQHEM15C8U},
  urldate = {2023-11-07},
  abstract = {The paper evaluates three variants of the Gated Recurrent Unit (GRU) in recurrent neural networks (RNNs) by retaining the structure and systematically reducing parameters in the update and reset gates. We evaluate the three variant GRU models on MNIST and IMDB datasets and show that these GRU-RNN variant models perform as well as the original GRU RNN model while reducing the computational expense. In this comparative study, we simply refer to the three variants as, respectively, GRU1, GRU2, and GRU3 RNNs.},
  eventtitle = {2017 {{IEEE}} 60th {{International Midwest Symposium}} on {{Circuits}} and {{Systems}} ({{MWSCAS}})},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\L22XJBH5\Dey und Salem - 2017 - Gate-variants of Gated Recurrent Unit (GRU) neural.pdf}
}

@inproceedings{doUsingMachineLearning2021,
  title = {Using {{Machine Learning}} to {{Predict Game Outcomes Based}} on {{Player-Champion Experience}} in {{League}} of {{Legends}}},
  booktitle = {Proceedings of the 16th {{International Conference}} on the {{Foundations}} of {{Digital Games}}},
  author = {Do, Tiffany D. and Wang, Seong Ioi and Yu, Dylan S. and McMillian, Matthew G. and McMahan, Ryan P.},
  date = {2021-10-21},
  series = {{{FDG}} '21},
  pages = {1--5},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3472538.3472579},
  url = {https://dl.acm.org/doi/10.1145/3472538.3472579},
  urldate = {2023-11-14},
  abstract = {League of Legends (LoL) is the most widely played multiplayer online battle arena (MOBA) game in the world. An important aspect of LoL is competitive ranked play, which utilizes a skill-based matchmaking system to form fair teams. However, players’ skill levels vary widely depending on which champion, or hero, that they choose to play as. In this paper, we propose a method for predicting game outcomes in ranked LoL games based on players’ experience with their selected champion. Using a deep neural network, we found that game outcomes can be predicted with 75.1\% accuracy after all players have selected champions, which occurs before gameplay begins. Our results have important implications for playing LoL and matchmaking. Firstly, individual champion skill plays a significant role in the outcome of a match, regardless of team composition. Secondly, even after the skill-based matchmaking, there is still a wide variance in team skill before gameplay begins. Finally, players should only play champions that they have mastered, if they want to win games.},
  isbn = {978-1-4503-8422-3},
  keywords = {League of Legends,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\MIP3P348\Do et al. - 2021 - Using Machine Learning to Predict Game Outcomes Ba.pdf}
}

@inproceedings{drachenSkillbasedDifferencesSpatiotemporal2014,
  title = {Skill-Based Differences in Spatio-Temporal Team Behaviour in Defence of the {{Ancients}} 2 ({{DotA}} 2)},
  booktitle = {2014 {{IEEE Games Media Entertainment}}},
  author = {Drachen, Anders and Yancey, Matthew and Maguire, John and Chu, Derrek and Wang, Iris Yuhui and Mahlmann, Tobias and Schubert, Matthias and Klabajan, Diego},
  date = {2014-10},
  pages = {1--8},
  doi = {10.1109/GEM.2014.7048109},
  url = {https://ieeexplore.ieee.org/abstract/document/7048109},
  urldate = {2023-10-05},
  abstract = {Multiplayer Online Battle Arena (MOBA) games are among the most played digital games in the world. In these games, teams of players fight against each other in arena environments, and the gameplay is focussed on tactical combat. In this paper, we present three data-driven measures of spatio-temporal behaviour in Defence of the Ancients 2 (DotA 2): 1) Zone changes; 2) Distribution of team members and: 3) Time series clustering via a fuzzy approach. We present a method for obtaining accurate positional data from DotA 2. We investigate how behaviour varies across these measures as a function of the skill level of teams, using four tiers from novice to professional players. Results from three analyses indicate that spatio-temporal behaviour of MOBA teams is highly related to team skill.},
  eventtitle = {2014 {{IEEE Games Media Entertainment}}},
  keywords = {Dota 2,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\M4ZRY2DS\Drachen et al. - 2014 - Skill-based differences in spatio-temporal team be.pdf}
}

@article{dunnePairingSoftmaxActivation1997,
  title = {On {{The Pairing Of The Softmax Activation And Cross}}\{\vphantom\}{{Entropy Penalty Functions And The Derivation Of The Softmax Activation Function}}},
  author = {Dunne, R A and Campbell, N A},
  date = {1997},
  abstract = {It is suggested in the literature 2, 1] that there is a natural pairing between the softmax activation function and the cross\{entropy penalty function. We clarify a reason for this pairing and give an improved derivation of the softmax activation function. In addition, we empirically compare some penalty/activation function pairs.\vphantom\}},
  langid = {english},
  file = {C:\Users\morit\Zotero\storage\ATJEB5IA\Dunne und Campbell - 1997 - On The Pairing Of The Softmax Activation And Cross.pdf}
}

@inproceedings{eggertClassificationPlayerRoles2015,
  title = {Classification of {{Player Roles}} in the {{Team-Based Multi-player Game Dota}} 2},
  booktitle = {Entertainment {{Computing}} - {{ICEC}} 2015},
  author = {Eggert, Christoph and Herrlich, Marc and Smeddinck, Jan and Malaka, Rainer},
  editor = {Chorianopoulos, Konstantinos and Divitini, Monica and Baalsrud Hauge, Jannicke and Jaccheri, Letizia and Malaka, Rainer},
  date = {2015},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {112--125},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-24589-8_9},
  abstract = {Computer games are big business, which is also reflected in the growing interest in competitive gaming, the so-called electronic sports. Multi-player online battle arena games are among the most successful games in this regard. In order to execute complex team-based strategies, players take on very specific roles within a team. This paper investigates the applicability of supervised machine learning to classifying player behavior in terms of specific and commonly accepted but not formally well-defined roles within a team of players of the game Dota 2. We provide an in-depth discussion and novel approaches for constructing complex attributes from low-level data extracted from replay files. Using attribute evaluation techniques, we are able to reduce a larger set of candidate attributes down to a manageable number. Based on this resulting set of attributes, we compare and discuss the performance of a variety of supervised classification algorithms. Our results with a data set of 708 labeled players see logistic regression as the overall most stable and best performing classifier.},
  isbn = {978-3-319-24589-8},
  langid = {english},
  keywords = {Dota 2,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\PHUQSL6S\Eggert et al. - 2015 - Classification of Player Roles in the Team-Based M.pdf}
}

@article{elmanFindingStructureTime1990,
  title = {Finding {{Structure}} in {{Time}}},
  author = {Elman, Jeffrey L.},
  date = {1990},
  journaltitle = {Cognitive Science},
  volume = {14},
  number = {2},
  pages = {179--211},
  issn = {1551-6709},
  doi = {10.1207/s15516709cog1402_1},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1207/s15516709cog1402_1},
  urldate = {2023-11-03},
  abstract = {Time underlies many interesting human behaviors. Thus, the question of how to represent time in connectionist models is very important. One approach is to represent time implicitly by its effects on processing rather than explicitly (as in a spatial representation). The current report develops a proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory. In this approach, hidden unit patterns are fed back to themselves: the internal representations which develop thus reflect task demands in the context of prior internal states. A set of simulations is reported which range from relatively simple problems (temporal version of XOR) to discovering syntactic/semantic features for words. The networks are able to learn interesting internal representations which incorporate task demands with memory demands: indeed, in this approach the notion of memory is inextricably bound up with task processing. These representations reveal a rich structure, which allows them to be highly context-dependent, while also expressing generalizations across classes of items. These representations suggest a method for representing lexical categories and the type/token distinction.},
  langid = {english},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\5LLXR4N8\Elman - 1990 - Finding Structure in Time.pdf}
}

@online{estebanPredictingClinicalEvents2016,
  title = {Predicting {{Clinical Events}} by {{Combining Static}} and {{Dynamic Information Using Recurrent Neural Networks}}},
  author = {Esteban, Cristóbal and Staeck, Oliver and Yang, Yinchong and Tresp, Volker},
  date = {2016-11-17},
  eprint = {1602.02685},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1602.02685},
  urldate = {2023-11-28},
  abstract = {In clinical data sets we often find static information (e.g. patient gender, blood type, etc.) combined with sequences of data that are recorded during multiple hospital visits (e.g. medications prescribed, tests performed, etc.). Recurrent Neural Networks (RNNs) have proven to be very successful for modelling sequences of data in many areas of Machine Learning. In this work we present an approach based on RNNs, specifically designed for the clinical domain, that combines static and dynamic information in order to predict future events. We work with a database collected in the Charite´ Hospital in Berlin that contains complete information concerning patients that underwent a kidney transplantation. After the transplantation three main endpoints can occur: rejection of the kidney, loss of the kidney and death of the patient. Our goal is to predict, based on information recorded in the Electronic Health Record of each patient, whether any of those endpoints will occur within the next six or twelve months after each visit to the clinic. We compared different types of RNNs that we developed for this work, with a model based on a Feedforward Neural Network and a Logistic Regression model. We found that the RNN that we developed based on Gated Recurrent Units provides the best performance for this task. We also used the same models for a second task, i.e., next event prediction, and found that here the model based on a Feedforward Neural Network outperformed the other models. Our hypothesis is that long-term dependencies are not as relevant in this task.},
  langid = {english},
  pubstate = {preprint},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\DF2NVVYX\Esteban et al. - 2016 - Predicting Clinical Events by Combining Static and.pdf}
}

@article{fangSurveyResearchRNNBased2021,
  title = {Survey on {{Research}} of {{RNN-Based Spatio-Temporal Sequence Prediction Algorithms}}},
  author = {Fang, Wei and Chen, Yupeng and Xue, Qiongying},
  date = {2021},
  journaltitle = {Journal on Big Data},
  volume = {3},
  number = {3},
  pages = {97--110},
  issn = {2579-0056},
  doi = {10.32604/jbd.2021.016993},
  url = {https://www.techscience.com/jbd/v3n3/45671},
  urldate = {2023-11-03},
  abstract = {In the past few years, deep learning has developed rapidly, and many researchers try to combine their subjects with deep learning. The algorithm based on Recurrent Neural Network (RNN) has been successfully applied in the fields of weather forecasting, stock forecasting, action recognition, etc. because of its excellent performance in processing Spatio-temporal sequence data. Among them, algorithms based on LSTM and GRU have developed most rapidly because of their good design. This paper reviews the RNN-based Spatiotemporal sequence prediction algorithm, introduces the development history of RNN and the common application directions of the Spatio-temporal sequence prediction, and includes precipitation nowcasting algorithms and traffic flow forecasting algorithms. At the same time, it also compares the advantages and disadvantages, and innovations of each algorithm. The purpose of this article is to give readers a clear understanding of solutions to such problems. Finally, it prospects the future development of RNN in the Spatio-temporal sequence prediction algorithm.},
  langid = {english},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\TC2LZJBB\Fang et al. - 2021 - Survey on Research of RNN-Based Spatio-Temporal Se.pdf}
}

@article{gaoParallelFeatureFusion2022,
  title = {A {{Parallel Feature Fusion Network Combining GRU}} and {{CNN}} for {{Motor Imagery EEG Decoding}}},
  author = {Gao, Siheng and Yang, Jun and Shen, Tao and Jiang, Wen},
  date = {2022-09},
  journaltitle = {Brain Sciences},
  volume = {12},
  number = {9},
  pages = {1233},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2076-3425},
  doi = {10.3390/brainsci12091233},
  url = {https://www.mdpi.com/2076-3425/12/9/1233},
  urldate = {2023-11-28},
  abstract = {In recent years, deep-learning-based motor imagery (MI) electroencephalography (EEG) decoding methods have shown great potential in the field of the brain–computer interface (BCI). The existing literature is relatively mature in decoding methods for two classes of MI tasks. However, with the increase in MI task classes, decoding studies for four classes of MI tasks need to be further explored. In addition, it is difficult to obtain large-scale EEG datasets. When the training data are limited, deep-learning-based decoding models are prone to problems such as overfitting and poor robustness. In this study, we design a data augmentation method for MI-EEG. The original EEG is slid along the time axis and reconstructed to expand the size of the dataset. Second, we combine the gated recurrent unit (GRU) and convolutional neural network (CNN) to construct a parallel-structured feature fusion network to decode four classes of MI tasks. The parallel structure can avoid temporal, frequency and spatial features interfering with each other. Experimenting on the well-known four-class MI dataset BCI Competition IV 2a shows a global average classification accuracy of 80.7\% and a kappa value of 0.74. The proposed method improves the robustness of deep learning to decode small-scale EEG datasets and alleviates the overfitting phenomenon caused by insufficient data. The method can be applied to BCI systems with a small amount of daily recorded data.},
  issue = {9},
  langid = {english},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\VMB5JNC5\Gao et al. - 2022 - A Parallel Feature Fusion Network Combining GRU an.pdf}
}

@online{GGBestLeague,
  title = {U {{GG}}: {{The Best League}} of {{Legends Builds LoL Build Champion Probuilds LoL Runes Tier List Counters Guides}}},
  shorttitle = {U {{GG}}},
  url = {https://u.gg},
  urldate = {2023-12-15},
  abstract = {Best Builds from the Best Data. Riot-approved U.GG provides the best League of Legends builds, LoL runes, Probuilds, Tier List, Counters, and more.},
  langid = {english},
  file = {C:\Users\morit\Zotero\storage\7GLXVIPB\u.gg.html}
}

@inproceedings{gordon-rodriguezUsesAbusesCrossEntropy2020,
  title = {Uses and {{Abuses}} of the {{Cross-Entropy Loss}}: {{Case Studies}} in {{Modern Deep Learning}}},
  shorttitle = {Uses and {{Abuses}} of the {{Cross-Entropy Loss}}},
  author = {Gordon-Rodriguez, Elliott and Loaiza-Ganem, Gabriel and Pleiss, Geoff and Cunningham, John Patrick},
  date = {2020-02-08},
  pages = {1--10},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v137/gordon-rodriguez20a.html},
  urldate = {2023-11-02},
  abstract = {Modern deep learning is primarily an experimental science, in which empirical advances occasionally come at the expense of probabilistic rigor. Here we focus on one such example; namely the use of the categorical cross-entropy loss to model data that is not strictly categorical, but rather takes values on the simplex. This practice is standard in neural network architectures with label smoothing and actor-mimic reinforcement learning, amongst others. Drawing on the recently discovered continuous-categorical distribution, we propose probabilistically-inspired alternatives to these models, providing an approach that is more principled and theoretically appealing. Through careful experimentation, including an ablation study, we identify the potential for outperformance in these models, thereby highlighting the importance of a proper probabilistic treatment, as well as illustrating some of the failure modes thereof.},
  langid = {english},
  keywords = {notion},
  file = {C\:\\Users\\morit\\Zotero\\storage\\93N5Y4I8\\Gordon-Rodriguez et al. - 2020 - Uses and Abuses of the Cross-Entropy Loss Case St.pdf;C\:\\Users\\morit\\Zotero\\storage\\UH5JPJGP\\Gordon-Rodriguez et al. - 2020 - Uses and Abuses of the Cross-Entropy Loss Case St.pdf}
}

@online{goughLeagueLegendsChampionships,
  title = {League of {{Legends}} Championships Viewers 2022},
  author = {Gough, Christina},
  url = {https://www.statista.com/statistics/518126/league-of-legends-championship-viewers/},
  urldate = {2023-12-09},
  abstract = {The League of Legends World Championship is an annual tournament hosted by Riot Games which pits the best League of Legends eSports players against each other for the chance to win a large amount of money.},
  langid = {english},
  organization = {{Statista}},
  file = {C:\Users\morit\Zotero\storage\8EUC32GX\league-of-legends-championship-viewers.html}
}

@thesis{gravesSupervisedSequenceLabelling2012,
  title = {Supervised {{Sequence Labelling}} with {{Recurrent Neural Networks}}},
  author = {Graves, Alex},
  date = {2012},
  institution = {{Springer Berlin Heidelberg}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-24797-2},
  url = {https://link.springer.com/10.1007/978-3-642-24797-2},
  urldate = {2023-12-21},
  langid = {english},
  file = {C:\Users\morit\Zotero\storage\LH63U9IS\Graves - 2012 - Supervised Sequence Labelling with Recurrent Neura.pdf}
}

@article{greffLSTMSearchSpace2017,
  title = {{{LSTM}}: {{A Search Space Odyssey}}},
  shorttitle = {{{LSTM}}},
  author = {Greff, Klaus and Srivastava, Rupesh K. and Koutník, Jan and Steunebrink, Bas R. and Schmidhuber, Jürgen},
  date = {2017-10},
  journaltitle = {IEEE Transactions on Neural Networks and Learning Systems},
  volume = {28},
  number = {10},
  pages = {2222--2232},
  issn = {2162-2388},
  doi = {10.1109/TNNLS.2016.2582924},
  url = {https://ieeexplore.ieee.org/abstract/document/7508408?casa_token=wJar7bnjMcIAAAAA:_R37S3pOcLsctz574U-qLv5J7Ens-RNo7yJ-Kc0Vw_9aMA2cML0N3BlrrayKiWfdcL4gK5ZPJWg},
  urldate = {2023-11-01},
  abstract = {Several variants of the long short-term memory (LSTM) architecture for recurrent neural networks have been proposed since its inception in 1995. In recent years, these networks have become the state-of-the-art models for a variety of machine learning problems. This has led to a renewed interest in understanding the role and utility of various computational components of typical LSTM variants. In this paper, we present the first large-scale analysis of eight LSTM variants on three representative tasks: speech recognition, handwriting recognition, and polyphonic music modeling. The hyperparameters of all LSTM variants for each task were optimized separately using random search, and their importance was assessed using the powerful functional ANalysis Of VAriance framework. In total, we summarize the results of 5400 experimental runs ( \textbackslash approx 15 years of CPU time), which makes our study the largest of its kind on LSTM networks. Our results show that none of the variants can improve upon the standard LSTM architecture significantly, and demonstrate the forget gate and the output activation function to be its most critical components. We further observe that the studied hyperparameters are virtually independent and derive guidelines for their efficient adjustment.},
  eventtitle = {{{IEEE Transactions}} on {{Neural Networks}} and {{Learning Systems}}},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\YY6PEKEQ\Greff et al. - 2017 - LSTM A Search Space Odyssey.pdf}
}

@article{grosseLecture15Exploding,
  title = {Lecture 15: {{Exploding}} and {{Vanishing Gradients}}},
  author = {Grosse, Roger},
  langid = {english},
  file = {C:\Users\morit\Zotero\storage\4SLMAHYV\Grosse - Lecture 15 Exploding and Vanishing Gradients.pdf}
}

@article{guyonIntroductionVariableFeature,
  title = {An {{Introduction}} to {{Variable}} and {{Feature Selection}}},
  author = {Guyon, Isabelle and Elisseeff, Andre},
  abstract = {Variable and feature selection have become the focus of much research in areas of application for which datasets with tens or hundreds of thousands of variables are available. These areas include text processing of internet documents, gene expression array analysis, and combinatorial chemistry. The objective of variable selection is three-fold: improving the prediction performance of the predictors, providing faster and more cost-effective predictors, and providing a better understanding of the underlying process that generated the data. The contributions of this special issue cover a wide range of aspects of such problems: providing a better definition of the objective function, feature construction, feature ranking, multivariate feature selection, efficient search methods, and feature validity assessment methods.},
  langid = {english},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\ZEBH9EEP\Guyon und Elisseeff - An Introduction to Variable and Feature Selection.pdf}
}

@thesis{hallCorrelationbasedFeatureSelection1999,
  type = {Thesis},
  title = {Correlation-Based Feature Selection for Machine Learning},
  author = {Hall, Mark A.},
  date = {1999},
  institution = {{The University of Waikato}},
  url = {https://researchcommons.waikato.ac.nz/handle/10289/15043},
  urldate = {2023-10-05},
  abstract = {A central problem in machine learning is identifying a representative set of features from which to construct a classification model for a particular task. This thesis addresses the problem of feature selection for machine learning through a correlation based approach. The central hypothesis is that good feature sets contain features that are highly correlated with the class, yet uncorrelated with each other. A feature evaluation formula, based on ideas from test theory, provides an operational definition of this hypothesis. CFS (Correlation based Feature Selection) is an algorithm that couples this evaluation formula with an appropriate correlation measure and a heuristic search strategy.     CFS was evaluated by experiments on artificial and natural datasets. Three machine learning algorithms were used: C4.5 (a decision tree learner), IB 1 (an instance based learner), and naive Bayes. Experiments on artificial datasets showed that CFS quickly identifies and screens irrelevant, redundant, and noisy features, and identifies relevant features as long as their relevance does not strongly depend on other features. On natural domains, CFS typically eliminated well over half the features. In most cases, classification accuracy using the reduced feature set equaled or bettered accuracy using the complete feature set. Feature selection degraded machine learning performance in cases where some features were eliminated which were highly predictive of very small areas of the instance space.     Further experiments compared CFS with a wrapper - a well known approach to feature selection that employs the target learning algorithm to evaluate feature sets. In many cases CFS gave comparable results to the wrapper, and in general, outperformed the wrapper on small datasets. CFS executes many times faster than the wrapper, which allows it to scale to larger datasets.    Two methods of extending CFS to handle feature interaction are presented and experimentally evaluated. The first considers pairs of features and the second incorporates feature weights calculated by the RELIEF algorithm. Experiments on artificial domains showed that both methods were able to identify interacting features. On natural domains, the pairwise method gave more reliable results than using weights provided by RELIEF.},
  langid = {english},
  keywords = {notion},
  annotation = {Accepted: 2022-08-18T02:09:56Z},
  file = {C:\Users\morit\Zotero\storage\Q4GTGMYW\Hall - 1999 - Correlation-based feature selection for machine le.pdf}
}

@inproceedings{haymanMcCullochPittsModel1999,
  title = {The {{McCulloch-Pitts}} Model},
  booktitle = {{{IJCNN}}'99. {{International Joint Conference}} on {{Neural Networks}}. {{Proceedings}} ({{Cat}}. {{No}}.{{99CH36339}})},
  author = {Hayman, S.},
  date = {1999-07},
  volume = {6},
  pages = {4438-4439 vol.6},
  issn = {1098-7576},
  doi = {10.1109/IJCNN.1999.830886},
  url = {https://ieeexplore.ieee.org/abstract/document/830886?casa_token=ivTNFXKoCoIAAAAA:dbqsgVQhqCOH7LcbBz6ThI9ruzT6MKKc-G8P3jEvbnWZIk7ml5ZH9D0EqeSF8f5fvwRc0o7sa6c},
  urldate = {2023-11-01},
  abstract = {Neural net theory is founded on the model of McCulloch and Pitts (1943). The article discusses the principles of the model and the associated algebra. The adaptability comes from representing the synaptic action by a variable weight which determines the degree to which a neuron should 'take notice' of firing signals that take place at the synapse concerned. The neuron is thought to take firing signals at all its synapses into account by summing their effects, both excitatory and inhibitory, and thereby determining whether it should or should not fire. The effect of a synapse is represented by a weight in the range -1 to 1. The effect on a neuron of any particular synapse is the weight if the neuron fire, 0 if not, and the product of the weight and another number if it be not known whether the neuron fires.},
  eventtitle = {{{IJCNN}}'99. {{International Joint Conference}} on {{Neural Networks}}. {{Proceedings}} ({{Cat}}. {{No}}.{{99CH36339}})},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\HGKKDPJ7\Hayman - 1999 - The McCulloch-Pitts model.pdf}
}

@article{hewamalageRecurrentNeuralNetworks2021,
  title = {Recurrent {{Neural Networks}} for {{Time Series Forecasting}}: {{Current}} Status and Future Directions},
  shorttitle = {Recurrent {{Neural Networks}} for {{Time Series Forecasting}}},
  author = {Hewamalage, Hansika and Bergmeir, Christoph and Bandara, Kasun},
  date = {2021-01-01},
  journaltitle = {International Journal of Forecasting},
  shortjournal = {International Journal of Forecasting},
  volume = {37},
  number = {1},
  pages = {388--427},
  issn = {0169-2070},
  doi = {10.1016/j.ijforecast.2020.06.008},
  url = {https://www.sciencedirect.com/science/article/pii/S0169207020300996},
  urldate = {2023-11-03},
  abstract = {Recurrent Neural Networks (RNNs) have become competitive forecasting methods, as most notably shown in the winning method of the recent M4 competition. However, established statistical models such as exponential smoothing (ETS) and the autoregressive integrated moving average (ARIMA) gain their popularity not only from their high accuracy, but also because they are suitable for non-expert users in that they are robust, efficient, and automatic. In these areas, RNNs have still a long way to go. We present an extensive empirical study and an open-source software framework of existing RNN architectures for forecasting, and we develop guidelines and best practices for their use. For example, we conclude that RNNs are capable of modelling seasonality directly if the series in the dataset possess homogeneous seasonal patterns; otherwise, we recommend a deseasonalisation step. Comparisons against ETS and ARIMA demonstrate that (semi-) automatic RNN models are not silver bullets, but they are nevertheless competitive alternatives in many situations.},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\LHITQKAW\Hewamalage et al. - 2021 - Recurrent Neural Networks for Time Series Forecast.pdf}
}

@article{hitar-garciaMachineLearningMethods2023,
  title = {Machine {{Learning Methods}} for {{Predicting League}} of {{Legends Game Outcome}}},
  author = {Hitar-García, Juan Agustín and Morán-Fernández, Laura and Bolón-Canedo, Verónica},
  date = {2023-06},
  journaltitle = {IEEE Transactions on Games},
  volume = {15},
  number = {2},
  pages = {171--181},
  issn = {2475-1510},
  doi = {10.1109/TG.2022.3153086},
  url = {https://ieeexplore.ieee.org/abstract/document/9720122},
  urldate = {2023-10-05},
  abstract = {The video game League of Legends has several professional leagues and tournaments that offer prizes reaching several million dollars, making it one of the most followed games in the Esports scene. This article addresses the prediction of the winning team in professional matches of the game, using only pregame data. We propose to improve the accuracy of the models trained with the features offered by the game application programming interface (API). To this end, new features are built to collect interesting information, such as the skills of a player handling a certain champion, the synergies between players of the same team or the ability of a player to beat another player. Then, we perform feature selection and train different classification algorithms aiming at obtaining the best model. Experimental results show classification accuracy above 0.70, which is comparable to the results of other proposals presented in the literature, but with the added benefit of using few samples and not requiring the use of external sources to collect additional statistics.},
  eventtitle = {{{IEEE Transactions}} on {{Games}}},
  keywords = {League of Legends,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\TNHQVGCX\Hitar-García et al. - 2023 - Machine Learning Methods for Predicting League of .pdf}
}

@article{hochreiterLongShortTermMemory1997,
  title = {Long {{Short-Term Memory}}},
  author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
  date = {1997-11},
  journaltitle = {Neural Computation},
  volume = {9},
  number = {8},
  pages = {1735--1780},
  issn = {0899-7667},
  doi = {10.1162/neco.1997.9.8.1735},
  url = {https://ieeexplore.ieee.org/abstract/document/6795963},
  urldate = {2023-11-01},
  abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
  eventtitle = {Neural {{Computation}}},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\PIHAK9ST\lstm.pdf}
}

@article{hochreiterVanishingGradientProblem1998a,
  title = {The {{Vanishing Gradient Problem During Learning Recurrent Neural Nets}} and {{Problem Solutions}}},
  author = {Hochreiter, Sepp},
  date = {1998-04},
  journaltitle = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  shortjournal = {Int. J. Unc. Fuzz. Knowl. Based Syst.},
  volume = {06},
  number = {02},
  pages = {107--116},
  issn = {0218-4885, 1793-6411},
  doi = {10.1142/S0218488598000094},
  url = {https://www.worldscientific.com/doi/abs/10.1142/S0218488598000094},
  urldate = {2023-12-22},
  abstract = {Recurrent nets are in principle capable to store past inputs to produce the currently desired output. Because of this property recurrent nets are used in time series prediction and process control. Practical applications involve temporal dependencies spanning many time steps, e.g. between relevant inputs and desired outputs. In this case, however, gradient based learning methods take too much time. The extremely increased learning time arises because the error vanishes as it gets propagated back. In this article the de-caying error flow is theoretically analyzed. Then methods trying to overcome vanishing gradients are briefly discussed. Finally, experiments comparing conventional algorithms and alternative methods are presented. With advanced methods long time lag problems can be solved in reasonable time.},
  langid = {english},
  file = {C:\Users\morit\Zotero\storage\LS9TYJCH\Hochreiter - 1998 - The Vanishing Gradient Problem During Learning Rec.pdf}
}

@online{hodgeWinPredictionEsports2017,
  title = {Win {{Prediction}} in {{Esports}}: {{Mixed-Rank Match Prediction}} in {{Multi-player Online Battle Arena Games}}},
  shorttitle = {Win {{Prediction}} in {{Esports}}},
  author = {Hodge, Victoria and Devlin, Sam and Sephton, Nick and Block, Florian and Drachen, Anders and Cowling, Peter},
  date = {2017-11-17},
  eprint = {1711.06498},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1711.06498},
  urldate = {2023-09-25},
  abstract = {Esports has emerged as a popular genre for players as well as spectators, supporting a global entertainment industry. Esports analytics has evolved to address the requirement for data-driven feedback, and is focused on cyber-athlete evaluation, strategy and prediction. Towards the latter, previous work has used match data from a variety of player ranks from hobbyist to professional players. However, professional players have been shown to behave differently than lower ranked players. Given the comparatively limited supply of professional data, a key question is thus whether mixed-rank match datasets can be used to create data-driven models which predict winners in professional matches and provide a simple in-game statistic for viewers and broadcasters. Here we show that, although there is a slightly reduced accuracy, mixed-rank datasets can be used to predict the outcome of professional matches, with suitably optimized configurations.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Dota 2,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\ZCSJJK2E\Hodge et al. - 2017 - Win Prediction in Esports Mixed-Rank Match Predic.pdf}
}

@article{hodgeWinPredictionMultiplayer2021,
  title = {Win {{Prediction}} in {{Multiplayer Esports}}: {{Live Professional Match Prediction}}},
  shorttitle = {Win {{Prediction}} in {{Multiplayer Esports}}},
  author = {Hodge, Victoria J. and Devlin, Sam and Sephton, Nick and Block, Florian and Cowling, Peter I. and Drachen, Anders},
  date = {2021-12},
  journaltitle = {IEEE Transactions on Games},
  volume = {13},
  number = {4},
  pages = {368--379},
  issn = {2475-1510},
  doi = {10.1109/TG.2019.2948469},
  url = {https://ieeexplore.ieee.org/abstract/document/8906016},
  urldate = {2023-09-25},
  abstract = {Esports are competitive videogames watched by audiences. Most esports generate detailed data for each match that are publicly available. Esports analytics research is focused on predicting match outcomes. Previous research has emphasized prematch prediction and used data from amateur games, which are more easily available than those from professional level. However, the commercial value of win prediction exists at the professional level. Furthermore, predicting real-time data is unexplored, as is its potential for informing audiences. Here, we present the first comprehensive case study on live win prediction in a professional esport. We provide a literature review for win prediction in a multiplayer online battle arena (MOBA) esport. This article evaluates the first professional-level prediction models for live DotA 2 matches, one of the most popular MOBA games, and trials it at a major international esports tournament. Using standard machine learning models, feature engineering and optimization, our model is up to 85\% accurate after 5 min of gameplay. Our analyses highlight the need for algorithm evaluation and optimization. Finally, we present implications for the esports/game analytics domains, describe commercial opportunities and practical challenges, and propose a set of evaluation criteria for research on esports win prediction.},
  eventtitle = {{{IEEE Transactions}} on {{Games}}},
  keywords = {Dota 2,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\MEENXXI3\Hodge et al. - 2021 - Win Prediction in Multiplayer Esports Live Profes.pdf}
}

@article{hornikMultilayerFeedforwardNetworks1989,
  title = {Multilayer Feedforward Networks Are Universal Approximators},
  author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  date = {1989-01},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  volume = {2},
  number = {5},
  pages = {359--366},
  issn = {08936080},
  doi = {10.1016/0893-6080(89)90020-8},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0893608089900208},
  urldate = {2023-11-02},
  abstract = {This paper rigorously establishes thut standard rnultiluyer feedforward networks with as f\&v us one hidden layer using arbitrary squashing functions ure capable of upproximating uny Bore1 measurable function from one finite dimensional space to another to any desired degree of uccuracy, provided sujficirntly muny hidden units are available. In this sense, multilayer feedforward networks are u class of universul rlpproximators.},
  langid = {english},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\AGQTPNP4\Hornik et al. - 1989 - Multilayer feedforward networks are universal appr.pdf}
}

@inproceedings{irieLSTMGRUHighway2016,
  title = {{{LSTM}}, {{GRU}}, {{Highway}} and a {{Bit}} of {{Attention}}: {{An Empirical Overview}} for {{Language Modeling}} in {{Speech Recognition}}},
  shorttitle = {{{LSTM}}, {{GRU}}, {{Highway}} and a {{Bit}} of {{Attention}}},
  booktitle = {Interspeech 2016},
  author = {Irie, Kazuki and Tüske, Zoltán and Alkhouli, Tamer and Schlüter, Ralf and Ney, Hermann},
  date = {2016-09-08},
  pages = {3519--3523},
  publisher = {{ISCA}},
  doi = {10.21437/Interspeech.2016-491},
  url = {https://www.isca-speech.org/archive/interspeech_2016/irie16_interspeech.html},
  urldate = {2023-11-07},
  abstract = {Popularized by the long short-term memory (LSTM), multiplicative gates have become a standard means to design artificial neural networks with intentionally organized information flow. Notable examples of such architectures include gated recurrent units (GRU) and highway networks. In this work, we first focus on the evaluation of each of the classical gated architectures for language modeling for large vocabulary speech recognition. Namely, we evaluate the highway network, lateral network, LSTM and GRU. Furthermore, the motivation underlying the highway network also applies to LSTM and GRU. An extension specific to the LSTM has been recently proposed with an additional highway connection between the memory cells of adjacent LSTM layers. In contrast, we investigate an approach which can be used with both LSTM and GRU: a highway network in which the LSTM or GRU is used as the transformation function. We found that the highway connections enable both standalone feedforward and recurrent neural language models to benefit better from the deep structure and provide a slight improvement of recognition accuracy after interpolation with count models. To complete the overview, we include our initial investigations on the use of the attention mechanism for learning word triggers.},
  eventtitle = {Interspeech 2016},
  langid = {english},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\BLUSQ6UD\Irie et al. - 2016 - LSTM, GRU, Highway and a Bit of Attention An Empi.pdf}
}

@book{janssonNeuralNetworksStandardizing2022,
  title = {Neural {{Networks}} for {{Standardizing Ratings inLeague}} of {{Legends}}},
  author = {Jansson, Andréas and Karlsson, Erik},
  date = {2022},
  url = {https://urn.kb.se/resolve?urn=urn:nbn:se:oru:diva-102668},
  urldate = {2023-12-09},
  abstract = {DiVA portal is a finding tool for research publications and student theses written at the following 50 universities and research institutions.},
  langid = {english},
  file = {C:\Users\morit\Zotero\storage\LLJ4N74X\Jansson und Karlsson - 2022 - Neural Networks for Standardizing Ratings inLeague.pdf}
}

@book{johanssonResultPredictionMining2015,
  title = {Result {{Prediction}} by {{Mining Replays}} in {{Dota}} 2},
  author = {Johansson, Filip and Wikström, Jesper},
  date = {2015},
  url = {https://urn.kb.se/resolve?urn=urn:nbn:se:bth-2288},
  urldate = {2023-10-05},
  abstract = {DiVA portal is a finding tool for research publications and student theses written at the following 50 universities and research institutions.},
  langid = {english},
  keywords = {Dota 2,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\Y6MNG3CQ\Johansson und Wikström - 2015 - Result Prediction by Mining Replays in Dota 2.pdf}
}

@inproceedings{jovicReviewFeatureSelection2015,
  title = {A Review of Feature Selection Methods with Applications},
  booktitle = {2015 38th {{International Convention}} on {{Information}} and {{Communication Technology}}, {{Electronics}} and {{Microelectronics}} ({{MIPRO}})},
  author = {Jovic, A. and Brkic, K. and Bogunovic, N.},
  date = {2015-05},
  pages = {1200--1205},
  publisher = {{IEEE}},
  location = {{Opatija, Croatia}},
  doi = {10.1109/MIPRO.2015.7160458},
  url = {http://ieeexplore.ieee.org/document/7160458/},
  urldate = {2023-12-01},
  abstract = {Feature selection (FS) methods can be used in data pre-processing to achieve efficient data reduction. This is useful for finding accurate data models. Since exhaustive search for optimal feature subset is infeasible in most cases, many search strategies have been proposed in literature. The usual applications of FS are in classification, clustering, and regression tasks. This review considers most of the commonly used FS techniques. Particular emphasis is on the application aspects. In addition to standard filter, wrapper, and embedded methods, we also provide insight into FS for recent hybrid approaches and other advanced topics.},
  eventtitle = {2015 38th {{International Convention}} on {{Information}} and {{Communication Technology}}, {{Electronics}} and {{Microelectronics}} ({{MIPRO}})},
  isbn = {978-953-233-082-3},
  langid = {english},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\YTW4R424\Jovic et al. - 2015 - A review of feature selection methods with applica.pdf}
}

@inproceedings{katonaTimeDeathPrediction2019,
  title = {Time to {{Die}}: {{Death Prediction}} in {{Dota}} 2 Using {{Deep Learning}}},
  shorttitle = {Time to {{Die}}},
  booktitle = {2019 {{IEEE Conference}} on {{Games}} ({{CoG}})},
  author = {Katona, Adam and Spick, Ryan and Hodge, Victoria J. and Demediuk, Simon and Block, Florian and Drachen, Anders and Walker, James Alfred},
  date = {2019-08},
  pages = {1--8},
  issn = {2325-4289},
  doi = {10.1109/CIG.2019.8847997},
  url = {https://ieeexplore.ieee.org/abstract/document/8847997?casa_token=BdsiAxBSGpUAAAAA:cCCR9yP_2dKCinpYdBHkFsFcBBlZeP8sYlDFVGPX3EOP4zWrlxAnZqJCY-nkDRR9eqtkVxR3Hg},
  urldate = {2023-09-25},
  abstract = {Esports have become major international sports with hundreds of millions of spectators. Esports games generate massive amounts of telemetry data. Using these to predict the outcome of esports matches has received considerable attention, but micro-predictions, which seek to predict events inside a match, is as yet unknown territory. Micro-predictions are however of perennial interest across esports commentators and audience, because they provide the ability to observe events that might otherwise be missed: esports games are highly complex with fast-moving action where the balance of a game can change in the span of seconds, and where events can happen in multiple areas of the playing field at the same time. Such events can happen rapidly, and it is easy for commentators and viewers alike to miss an event and only observe the following impact of events. In Dota 2, a player hero being killed by the opposing team is a key event of interest to commentators and audience. We present a deep learning network with shared weights which provides accurate death predictions within a five-second window. The network is trained on a vast selection of Dota 2 gameplay features and professional/semi-professional level match dataset. Even though death events are rare within a game (1\% of the data), the model achieves 0.377 precision with 0.725 recall on test data when prompted to predict which of any of the 10 players of either team will die within 5 seconds. An example of the system applied to a Dota 2 match is presented. This model enables real-time micro-predictions of kills in Dota 2, one of the most played esports titles in the world, giving commentators and viewers time to move their attention to these key events.},
  eventtitle = {2019 {{IEEE Conference}} on {{Games}} ({{CoG}})},
  keywords = {Dota 2,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\C5JXRAR4\Katona et al. - 2019 - Time to Die Death Prediction in Dota 2 using Deep.pdf}
}

@inproceedings{kaurReviewDeepLearning2019,
  title = {A {{Review}} of {{Deep Learning}} with {{Recurrent Neural Network}}},
  booktitle = {2019 {{International Conference}} on {{Smart Systems}} and {{Inventive Technology}} ({{ICSSIT}})},
  author = {Kaur, Manjot and Mohta, Aakash},
  date = {2019-11},
  pages = {460--465},
  doi = {10.1109/ICSSIT46314.2019.8987837},
  url = {https://ieeexplore.ieee.org/document/8987837?denied=},
  urldate = {2023-11-05},
  abstract = {Recurrent Neural Network (RNN) is a deep learning model that uses the concept of supervised learning. Deep learning belongs to the family of machine learning. It is also called hierarchical learning or deep structured learning. The classic machine learning algorithms are definite, while the deep learning algorithms follow a chain of command. Deep learning has the capability to deal with more complex neural networks and it mainly deals with sequential data. Recurrent networks can process examples one at a time, preserving an element, that reflects over a long period of time.},
  eventtitle = {2019 {{International Conference}} on {{Smart Systems}} and {{Inventive Technology}} ({{ICSSIT}})},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\7RB5IA59\Kaur und Mohta - 2019 - A Review of Deep Learning with Recurrent Neural Ne.pdf}
}

@article{kimModelingLongtermHuman2017,
  title = {Modeling Long-Term Human Activeness Using Recurrent Neural Networks for Biometric Data},
  author = {Kim, Zae Myung and Oh, Hyung Rai and Kim, Han-Gyu and Lim, Chae-Gyun and Oh, Kyo-Joong and Choi, Ho-Jin},
  date = {2017-05-18},
  journaltitle = {BMC Medical Informatics and Decision Making},
  shortjournal = {BMC Medical Informatics and Decision Making},
  volume = {17},
  doi = {10.1186/s12911-017-0453-1},
  abstract = {Background With the invention of fitness trackers, it has been possible to continuously monitor a user’s biometric data such as heart rates, number of footsteps taken, and amount of calories burned. This paper names the time series of these three types of biometric data, the user’s “activeness”, and investigates the feasibility in modeling and predicting the long-term activeness of the user. Methods The dataset used in this study consisted of several months of biometric time-series data gathered by seven users independently. Four recurrent neural network (RNN) architectures–as well as a deep neural network and a simple regression model–were proposed to investigate the performance on predicting the activeness of the user under various length-related hyper-parameter settings. In addition, the learned model was tested to predict the time period when the user’s activeness falls below a certain threshold. Results A preliminary experimental result shows that each type of activeness data exhibited a short-term autocorrelation; and among the three types of data, the consumed calories and the number of footsteps were positively correlated, while the heart rate data showed almost no correlation with neither of them. It is probably due to this characteristic of the dataset that although the RNN models produced the best results on modeling the user’s activeness, the difference was marginal; and other baseline models, especially the linear regression model, performed quite admirably as well. Further experimental results show that it is feasible to predict a user’s future activeness with precision, for example, a trained RNN model could predict–with the precision of 84\%–when the user would be less active within the next hour given the latest 15 min of his activeness data. Conclusions This paper defines and investigates the notion of a user’s “activeness”, and shows that forecasting the long-term activeness of the user is indeed possible. Such information can be utilized by a health-related application to proactively recommend suitable events or services to the user.},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\Z4FLGST5\Kim et al. - 2017 - Modeling long-term human activeness using recurren.pdf}
}

@inproceedings{kimWhatMakesStrong2017,
  title = {What Makes a Strong Team? {{Using}} Collective Intelligence to Predict Team Performance in {{League}} of {{Legends}}},
  shorttitle = {What Makes a Strong Team?},
  booktitle = {Proceedings of the 2017 {{ACM}} Conference on Computer Supported Cooperative Work and Social Computing},
  author = {Kim, Young Ji and Engel, David and Woolley, Anita Williams and Lin, Jeffrey Yu-Ting and McArthur, Naomi and Malone, Thomas W.},
  date = {2017},
  pages = {2316--2329},
  keywords = {League of Legends,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\9PLECNWZ\Kim et al. - 2017 - What makes a strong team Using collective intelli.pdf}
}

@article{kinkade2015dota,
  title = {Dota 2 Win Prediction},
  author = {Kinkade, Nicholas and Lim, K},
  date = {2015},
  journaltitle = {Univ Calif},
  volume = {1},
  pages = {1--13},
  keywords = {Dota 2,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\QHY49G49\018.pdf}
}

@article{klineRevisitingSquarederrorCrossentropy2005,
  title = {Revisiting Squared-Error and Cross-Entropy Functions for Training Neural Network Classifiers},
  author = {Kline, Douglas M. and Berardi, Victor L.},
  date = {2005-12-01},
  journaltitle = {Neural Computing \& Applications},
  shortjournal = {Neural Comput \& Applic},
  volume = {14},
  number = {4},
  pages = {310--318},
  issn = {1433-3058},
  doi = {10.1007/s00521-005-0467-y},
  url = {https://doi.org/10.1007/s00521-005-0467-y},
  urldate = {2023-11-02},
  abstract = {This paper investigates the efficacy of cross-entropy and square-error objective functions used in training feed-forward neural networks to estimate posterior probabilities. Previous research has found no appreciable difference between neural network classifiers trained using cross-entropy or squared-error. The approach employed here, though, shows cross-entropy has significant, practical advantages over squared-error.},
  langid = {english},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\CG6GRRLQ\Kline und Berardi - 2005 - Revisiting squared-error and cross-entropy functio.pdf}
}

@article{kuglerHowAIDriving2022,
  title = {How {{AI}} Is Driving the Esports Boom},
  author = {Kugler, Logan},
  date = {2022-08-19},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {65},
  number = {9},
  pages = {17--18},
  issn = {0001-0782},
  doi = {10.1145/3546956},
  url = {https://dl.acm.org/doi/10.1145/3546956},
  urldate = {2023-10-05},
  abstract = {Artificial intelligence is helping the esports industry take the world by storm.},
  keywords = {MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\S8LFNHEN\Kugler - 2022 - How AI is driving the esports boom.pdf}
}

@article{lecunDeepLearning2015,
  title = {Deep Learning},
  author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  date = {2015-05-28},
  journaltitle = {Nature},
  shortjournal = {Nature},
  volume = {521},
  number = {7553},
  pages = {436--444},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature14539},
  url = {https://www.nature.com/articles/nature14539},
  urldate = {2023-11-01},
  langid = {english},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\TKSDZFUV\LeCun et al. - 2015 - Deep learning.pdf}
}

@inproceedings{leontjevaCombiningStaticDynamic2016,
  title = {Combining {{Static}} and {{Dynamic Features}} for {{Multivariate Sequence Classification}}},
  booktitle = {2016 {{IEEE International Conference}} on {{Data Science}} and {{Advanced Analytics}} ({{DSAA}})},
  author = {Leontjeva, Anna and Kuzovkin, Ilya},
  date = {2016-10},
  eprint = {1712.08160},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  pages = {21--30},
  doi = {10.1109/DSAA.2016.10},
  url = {http://arxiv.org/abs/1712.08160},
  urldate = {2023-11-28},
  abstract = {Model precision in a classification task is highly dependent on the feature space that is used to train the model. Moreover, whether the features are sequential or static will dictate which classification method can be applied as most of the machine learning algorithms are designed to deal with either one or another type of data. In real-life scenarios, however, it is often the case that both static and dynamic features are present, or can be extracted from the data. In this work, we demonstrate how generative models such as Hidden Markov Models (HMM) and Long Short-Term Memory (LSTM) artificial neural networks can be used to extract temporal information from the dynamic data. We explore how the extracted information can be combined with the static features in order to improve the classification performance. We evaluate the existing techniques and suggest a hybrid approach, which outperforms other methods on several public datasets.},
  langid = {english},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\NWMZGU3E\1712.08160.pdf}
}

@article{lianoRobustErrorMeasure1996,
  title = {Robust Error Measure for Supervised Neural Network Learning with Outliers},
  author = {Liano, K.},
  date = {1996-01},
  journaltitle = {IEEE Transactions on Neural Networks},
  volume = {7},
  number = {1},
  pages = {246--250},
  issn = {1941-0093},
  doi = {10.1109/72.478411},
  url = {https://ieeexplore.ieee.org/abstract/document/478411?casa_token=0jyPyVbllkwAAAAA:nhqXqLYr4A9ycR0tFERzxjz3SlQJSMw2oWs0J9qHkkEELwxnKsv2m2mDl_IkcFv8SD-q0ho1aA},
  urldate = {2023-11-02},
  abstract = {Most supervised neural networks (NNs) are trained by minimizing the mean squared error (MSE) of the training set. In the presence of outliers, the resulting NN model can differ significantly from the underlying system that generates the data. Two different approaches are used to study the mechanism by which outliers affect the resulting models: influence function and maximum likelihood. The mean log squared error (MLSE) is proposed as the error criteria that can be easily adapted by most supervised learning algorithms. Simulation results indicate that the proposed method is robust against outliers.},
  eventtitle = {{{IEEE Transactions}} on {{Neural Networks}}},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\B5TDN9QC\Liano - 1996 - Robust error measure for supervised neural network.pdf}
}

@inproceedings{liIntegratingStaticTimeSeries2021,
  title = {Integrating {{Static}} and {{Time-Series Data}} in {{Deep Recurrent Models}} for {{Oncology Early Warning Systems}}},
  booktitle = {Proceedings of the 30th {{ACM International Conference}} on {{Information}} \& {{Knowledge Management}}},
  author = {Li, Dingwen and Lyons, Patrick and Klaus, Jeff and Gage, Brian and Kollef, Marin and Lu, Chenyang},
  date = {2021-10-26},
  pages = {913--936},
  publisher = {{ACM}},
  location = {{Virtual Event Queensland Australia}},
  doi = {10.1145/3459637.3482441},
  url = {https://dl.acm.org/doi/10.1145/3459637.3482441},
  urldate = {2023-11-28},
  abstract = {Machine learning techniques have shown promise in predicting clinical deterioration of hospitalized patients based on electronic health record (EHR). However, building accurate early warning systems (EWS) remains challenging in practice. EHRs are heterogeneous, comprising both static and time-series data. Moreover, missing values are prevalent in both static and time-series data, and the missingness of certain data can be correlated to clinical outcomes. This paper proposes a novel approach for integrating static and time-series clinical data in deep recurrent models through multimodal fusion. Furthermore, we exploit the correlation of static and time-series data through cross-modal imputation in an integrated recurrent model. We apply the proposed approaches to a dataset extracted from the EHR of 20,700 hospitalizations of adult oncology patients in a research hospital. The experiments demonstrate the proposed approaches outperform the state-of-the-art models in terms of predictive accuracy in generating early warnings for clinical deterioration. A case study further establishes the efficacy of the predictive model for early warning systems under realistic clinical settings.},
  eventtitle = {{{CIKM}} '21: {{The}} 30th {{ACM International Conference}} on {{Information}} and {{Knowledge Management}}},
  isbn = {978-1-4503-8446-9},
  langid = {english},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\KQ34UJFR\Li et al. - 2021 - Integrating Static and Time-Series Data in Deep Re.pdf}
}

@inproceedings{liMOBAGameAnalysis2021,
  title = {{{MOBA Game Analysis System Based}} on {{Neural Networks}}},
  booktitle = {Web {{Information Systems Engineering}} – {{WISE}} 2021},
  author = {Li, Kangwei and Li, Mengwei and Tian, Jia and Cao, Xiaobo and Nie, Tiezheng and Kou, Yue and Shen, Derong},
  editor = {Zhang, Wenjie and Zou, Lei and Maamar, Zakaria and Chen, Lu},
  date = {2021},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {518--526},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-91560-5_40},
  abstract = {The domain of knowledge contained in Multiplayer Online Battle Arena (MOBA) is quite complex, which is of great research value. With the rapid development of E-sports, the impact of data analysis on MOBA games is increasing. For example, data mining and deep learning methods can be used to guide players and develop appropriate strategies to win games. This paper proposes a novel MOBA game analysis system. The system includes three individual modules, namely lineup recommendation, real-time win rate prediction, and trend forecasting. The lineup module is implemented using NSGA-II algorithm to recommend hero combinations according to the enemy lineup. Win rate module is a neural network for predicting the quantitative advantage between teams. Trend module is a sequence-to-sequence model that forecasts the future team gold and exp. Finally, the system is applied to Dota 2, one of the most popular MOBA games. Experiments on a large number of professional match replays show that the system works well on arbitrary matches.},
  isbn = {978-3-030-91560-5},
  langid = {english},
  keywords = {Dota 2,notion},
  file = {C:\Users\morit\Zotero\storage\IE3YTEVY\Li et al. - 2021 - MOBA Game Analysis System Based on Neural Networks.pdf}
}

@article{linDeterminingMatchFairness,
  title = {Determining {{Match Fairness}} from {{Skill Ratings}}},
  author = {Lin, Anthony},
  langid = {english},
  keywords = {MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\8ZFEIQ55\Lin - Determining Match Fairness from Skill Ratings.pdf}
}

@incollection{mattheakis2019recurrent,
  title = {Recurrent Neural Networks: {{Exploding}} Vanishing Gradients \& Reservoir Computing},
  booktitle = {Advanced Topics in Data Science},
  author = {Mattheakis, M and Protopapas, P},
  date = {2019},
  publisher = {{Harvard Press Cambridge, MA, USA}},
  file = {C:\Users\morit\Zotero\storage\966DHZFQ\a-sec4-RNNs_notes_209b2019.pdf}
}

@article{mccullochLogicalCalculusIdeas1943,
  title = {A Logical Calculus of the Ideas Immanent in Nervous Activity},
  author = {McCulloch, Warren S. and Pitts, Walter},
  date = {1943-12-01},
  journaltitle = {The bulletin of mathematical biophysics},
  shortjournal = {Bulletin of Mathematical Biophysics},
  volume = {5},
  number = {4},
  pages = {115--133},
  issn = {1522-9602},
  doi = {10.1007/BF02478259},
  url = {https://doi.org/10.1007/BF02478259},
  urldate = {2023-11-01},
  abstract = {Because of the “all-or-none” character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.},
  langid = {english},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\YECLVBD6\McCulloch und Pitts - 1943 - A logical calculus of the ideas immanent in nervou.pdf}
}

@article{minchenliTutorialBackwardPropagation2016,
  title = {A {{Tutorial On Backward Propagation Through Time}} ({{BPTT}}) {{In The Gated Recurrent Unit}} ({{GRU}}) {{RNN}}},
  author = {{Minchen Li}},
  date = {2016},
  publisher = {{Unpublished}},
  doi = {10.13140/RG.2.2.32858.98247},
  url = {http://rgdoi.net/10.13140/RG.2.2.32858.98247},
  urldate = {2023-11-07},
  abstract = {In this tutorial, we provide a thorough explanation of how BPTT in GRU1 is conducted. A MATLAB program which implements the entire BPTT for GRU and the pseudo-codes describing the algorithms explicitly will be presented. We provide two algorithms for BPTT, a direct but quadratic time algorithm for easy understanding, and an optimized linear time algorithm. This tutorial starts with a specification of the problem followed by a mathematical derivation before the computational solutions.},
  langid = {english},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\WRLT8ADF\Minchen Li - 2016 - A Tutorial On Backward Propagation Through Time (B.pdf}
}

@inproceedings{mondalDoesSupportRole2022,
  title = {Does {{A Support Role Player}} Really {{Create Difference}} towards {{Triumph}}? {{Analyzing Individual Performances}} of {{Specific Role Players}} to {{Predict Victory}} in {{League}} of {{Legends}}},
  shorttitle = {Does {{A Support Role Player}} Really {{Create Difference}} towards {{Triumph}}?},
  booktitle = {2022 25th {{International Conference}} on {{Computer}} and {{Information Technology}} ({{ICCIT}})},
  author = {Mondal, Joyanta Jyoti and Zahin, Abrar and Manab, Meem Arafat and Zahidul Hasan, Mohammad},
  date = {2022-12},
  pages = {768--773},
  doi = {10.1109/ICCIT57492.2022.10055689},
  url = {https://ieeexplore.ieee.org/abstract/document/10055689},
  urldate = {2023-10-05},
  abstract = {Players make comments like "Mid Diff", "Top Diff", "JG Diff", etc. in the in-game chat at the end of almost every match of League of Legends. It represents the relative difference in in-game abilities of players of the same position that leads to a significant difference between two teams in determining the loss/win of a particular match. However, no player seems to pay enough heed to if there is a difference between players who play the Support role (or "SP Diff" to be specific) which also may have also helped them to win a match. In most places, this role is considered insignificant among players. But do they really not contribute towards the winning of a match? In our research, we investigate the impact of a player who contributes in a Support role toward match victory. Previous researches show collective intelligence (CI) to be a factor in team games that helps to analyze their capacity to work and win collectively. To our knowledge, this is the first work that focuses on the contribution of any single particular role out of the full team of five players toward the victory of a match. We also create a custom dataset based on the match statistics and match-specific performances of different Support role players and evaluate if the outcomes and performance shown by a particular role are crucial enough to the world of teams in competitive online video games, where intensive, self-organized, and time-pressured cooperation takes place entirely online. The results show a stronger correlation between a certain support player’s performance and the match result than usually thought of. This points towards more reliable match result prediction in the game. We make the dataset publicly available at https://www.kaggle.com/datasets/joyanta180199/lol-sp},
  eventtitle = {2022 25th {{International Conference}} on {{Computer}} and {{Information Technology}} ({{ICCIT}})},
  keywords = {League of Legends,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\2B76SXH6\Mondal et al. - 2022 - Does A Support Role Player really Create Differenc.pdf}
}

@article{mora-cantallopsMOBAGamesLiterature2018,
  title = {{{MOBA}} Games: {{A}} Literature Review},
  shorttitle = {{{MOBA}} Games},
  author = {Mora-Cantallops, Marçal and Sicilia, Miguel-Ángel},
  date = {2018-05},
  journaltitle = {Entertainment Computing},
  shortjournal = {Entertainment Computing},
  volume = {26},
  pages = {128--138},
  issn = {18759521},
  doi = {10.1016/j.entcom.2018.02.005},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1875952117300149},
  urldate = {2023-10-05},
  abstract = {This article aims to perform a literature review of the available research that focuses strictly on MOBA (multiplayer online battle arena) games. First, a review identifying the relevant papers published since 2011 is conducted, exploring them systematically to extract similarities, gaps and main findings. Results show how League of Legends is the most explored game, with player experience and toxic behaviour as popular topics for research. Second, as MOBA games remain underexplored by researchers despite their vast, enthusiast community, as well as projection and influence on contemporary game designers, a proposal on future lines for research is provided.},
  langid = {english},
  keywords = {Dota 2,League of Legends,notion,Survey},
  file = {C:\Users\morit\Zotero\storage\3XA7UFLR\Mora-Cantallops und Sicilia - 2018 - MOBA games A literature review.pdf}
}

@inproceedings{myslakDevelopingGameStructureSensitive2015,
  title = {Developing {{Game-Structure Sensitive Matchmaking System}} for {{Massive-Multiplayer Online Games}}},
  booktitle = {Social {{Informatics}}},
  author = {Myślak, Mateusz and Deja, Dominik},
  editor = {Aiello, Luca Maria and McFarland, Daniel},
  date = {2015},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {200--208},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-15168-7_25},
  abstract = {Providing a fair matchmaking system is an essential issue, while developing every online video game. In the article, we show that the currently existing matchmaking system in League of Legends, one of the most popular online video games currently existing, is built on a base of conditions which do not hold true in the presence of empirical data. This, in short, decreases the effectiveness of the ranking system, and negatively affects users experience. Therefore, we propose a new ranking system, which genuinely answers the needs, which arise from League of Legends gameplay. As League of Legends gameplay model is nowadays highly popular amid online video games, the proposed system can be easily generalized and adopted by other online video games that are currently popular among gamers.},
  isbn = {978-3-319-15168-7},
  langid = {english},
  keywords = {MOBA,notion}
}

@book{nasrCrossEntropyError2002,
  title = {Cross Entropy Error Function in Neural Networks},
  author = {Nasr, G. E. and Badr, E. A. and Joun, C.},
  date = {2002},
  publisher = {{ACM}},
  url = {https://laur.lau.edu.lb:8443/xmlui/handle/10725/6723},
  urldate = {2023-11-02},
  abstract = {This paper applies artificial neural networks to forecast gasoline consumption. The ANN is implemented using the cross entropy error function in the training stage. The cross entropy function is proven to accelerate the backpropagation algorithm and to provide good overall network performance with relatively short stagnation periods. To forecast gasoline consumption (GC), the ANN uses previous GC data and its determinants in a training data set. The determinants of gasoline consumption employed in this study are the price (P) and car registration (CR). Two ANNs models are presented. The first model is a univariate model based on past GC values. The second model is a trivariate model based on GC, price and car registration time series. Forecasting performance measures such as mean square errors (MSE) and mean absolute deviations (MAD) are presented for both models.},
  isbn = {978-1-57735-141-2},
  langid = {english},
  keywords = {notion},
  annotation = {Accepted: 2017-12-05T14:09:40Z},
  file = {C:\Users\morit\Zotero\storage\NUWM5JI5\Nasr et al. - 2002 - Cross entropy error function in neural networks.pdf}
}

@inproceedings{pascanuDifficultyTrainingRecurrent2013a,
  title = {On the Difficulty of Training Recurrent Neural Networks},
  booktitle = {Proceedings of the 30th {{International Conference}} on {{Machine Learning}}},
  author = {Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
  date = {2013-05-26},
  pages = {1310--1318},
  publisher = {{PMLR}},
  issn = {1938-7228},
  url = {https://proceedings.mlr.press/v28/pascanu13.html},
  urldate = {2023-12-22},
  abstract = {There are two widely known issues with properly training recurrent neural networks, the vanishing and the exploding gradient problems detailed in Bengio et al. (1994). In this paper we attempt to improve the understanding of the underlying issues by exploring these problems from an analytical, a geometric and a dynamical systems perspective. Our analysis is used to justify a simple yet effective solution. We propose a gradient norm clipping strategy to deal with exploding gradients and a soft constraint for the vanishing gradients problem. We validate empirically our hypothesis and proposed solutions in the experimental section.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {C:\Users\morit\Zotero\storage\Q485DY59\Pascanu et al. - 2013 - On the difficulty of training recurrent neural net.pdf}
}

@online{PythonAPIReference,
  title = {Python {{API Reference}} — Xgboost 2.0.2 Documentation},
  url = {https://xgboost.readthedocs.io/en/stable/python/python_api.html},
  urldate = {2023-12-02},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\MPT7VSCX\python_api.html}
}

@online{RankDistributionLeague,
  title = {Rank Distribution - {{League}} of {{Legends}}},
  url = {https://www.leagueofgraphs.com/rankings/rank-distribution},
  urldate = {2023-11-09},
  abstract = {We track millions of LoL games played every day gathering champion stats, matchups, builds \& summoner rankings, as well as champion stats, popularity, winrate, teams rankings, best items and spells.},
  langid = {english},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\JLLI8QZR\rank-distribution.html}
}

@article{rehmerVanishingExplodingGradient2020,
  title = {On the Vanishing and Exploding Gradient Problem in {{Gated Recurrent Units}}},
  author = {Rehmer, Alexander and Kroll, Andreas},
  date = {2020-01-01},
  journaltitle = {IFAC-PapersOnLine},
  shortjournal = {IFAC-PapersOnLine},
  series = {21st {{IFAC World Congress}}},
  volume = {53},
  number = {2},
  pages = {1243--1248},
  issn = {2405-8963},
  doi = {10.1016/j.ifacol.2020.12.1342},
  url = {https://www.sciencedirect.com/science/article/pii/S2405896320317481},
  urldate = {2023-12-22},
  abstract = {Recurrent Neural Networks are applied in areas such as speech recognition, natural language and video processing, and the identification of nonlinear state space models. Conventional Recurrent Neural Networks, e.g. the Elman Network, are hard to train. A more recently developed class of recurrent neural networks, so-called Gated Units, outperform their counterparts on virtually every task. This paper aims to provide additional insights into the differences between RNNs and Gated Units in order to explain the superior perfomance of gated recurrent units. It is argued, that Gated Units are easier to optimize not because they solve the vanishing gradient problem, but because they circumvent the emergence of large local gradients.},
  keywords = {Gated Recurrent Units,Nonlinear system identification,Recurrent Neural Networks},
  file = {C\:\\Users\\morit\\Zotero\\storage\\9Y3SV8BL\\Rehmer und Kroll - 2020 - On the vanishing and exploding gradient problem in.pdf;C\:\\Users\\morit\\Zotero\\storage\\L7XAKX9J\\S2405896320317481.html}
}

@online{RiotDeveloperPortal,
  title = {Riot {{Developer Portal}}},
  url = {https://developer.riotgames.com/},
  urldate = {2023-12-19},
  file = {C:\Users\morit\Zotero\storage\2BHJRP2M\developer.riotgames.com.html}
}

@online{riotgamesDevBalanceFramework2020,
  title = {/Dev: {{Balance Framework Update}} - {{League}} of {{Legends}}},
  shorttitle = {/Dev},
  author = {Riot Games},
  date = {2020-06-30},
  url = {https://www.leagueoflegends.com/news/dev/dev-balance-framework-update/},
  urldate = {2023-11-09},
  abstract = {We introduced a more objective approach to champ balance last year. Here’s what we learned so far.},
  langid = {american},
  keywords = {League of Legends,notion},
  file = {C:\Users\morit\Zotero\storage\LLP2F79S\dev-balance-framework-update.html}
}

@online{riotgamesRanglistenklassenDivisionenUnd2023,
  title = {Ranglistenklassen, Divisionen und Warteschlangen},
  author = {Riot Games},
  date = {2023-08-15},
  url = {https://support-leagueoflegends.riotgames.com/hc/de/articles/4406004330643-Ranglistenklassen-Divisionen-und-Warteschlangen},
  urldate = {2023-11-09},
  abstract = {Von den Slums von Zhaun bis zur Spitze des Targon, Runeterra ist die Heimat der unterschiedlichsten Personen und Orte. Und das Gleiche gilt in gewisser Weise auch für League! Es spielt keine Rolle,...},
  langid = {ngerman},
  organization = {{League of Legends Support}},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\X6YF8VR4\4406004330643.html}
}

@online{riotgamesRankedTiersDivisions2023,
  title = {Ranked {{Tiers}}, {{Divisions}}, and {{Queues}}},
  author = {Riot Games},
  date = {2023-08-10},
  url = {https://support-leagueoflegends.riotgames.com/hc/en-us/articles/4406004330643-Ranked-Tiers-Divisions-and-Queues},
  urldate = {2023-11-09},
  abstract = {From the slums of Zaun to the peak of Targon, Runeterra holds a tremendous gradient of people and places. And in a lot of ways, League is no different! Whether you're a weekend warrior or dial in d...},
  langid = {american},
  organization = {{League of Legends Support}},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\FXKJ74HK\4406004330643-Ranked-Tiers-Divisions-and-Queues.html}
}

@article{rioultMiningTracksCompetitive2014,
  title = {Mining {{Tracks}} of {{Competitive Video Games}}},
  author = {Rioult, François and Métivier, Jean-Philippe and Helleu, Boris and Scelles, Nicolas and Durand, Christophe},
  date = {2014-01-01},
  journaltitle = {AASRI Procedia},
  shortjournal = {AASRI Procedia},
  series = {2014 {{AASRI Conference}} on {{Sports Engineering}} and {{Computer Science}} ({{SECS}} 2014)},
  volume = {8},
  pages = {82--87},
  issn = {2212-6716},
  doi = {10.1016/j.aasri.2014.08.014},
  url = {https://www.sciencedirect.com/science/article/pii/S221267161400081X},
  urldate = {2023-10-05},
  abstract = {The development and professionalization of a video game requires tools for analyzing the practice of the players and teams, their tactics and strategies. These games are very popular and by nature numerical, they provide many tracks that we analyzed in terms of team play. We studied Defense of the Ancients (DotA), a Multiplayer Online Battle Arena (MOBA), where two teams battle in a game very similar to rugby or American football. Through topological measures – area of polygon described by the players, inertia, diameter, distance to the base – that are independent of the exact nature of the game, we show that the outcome of the match can be relevantly predicted. Mining e-sport's tracks is opening interest in further application of these tools for analyzing real time sport.},
  keywords = {Dota 2,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\DKIDDVMN\Rioult et al. - 2014 - Mining Tracks of Competitive Video Games.pdf}
}

@article{rosenblattPerceptronProbabilisticModel1958,
  title = {The Perceptron: {{A}} Probabilistic Model for Information Storage and Organization in the Brain},
  shorttitle = {The Perceptron},
  author = {Rosenblatt, F.},
  date = {1958},
  journaltitle = {Psychological Review},
  volume = {65},
  number = {6},
  pages = {386--408},
  publisher = {{American Psychological Association}},
  location = {{US}},
  issn = {1939-1471},
  doi = {10.1037/h0042519},
  abstract = {To answer the questions of how information about the physical world is sensed, in what form is information remembered, and how does information retained in memory influence recognition and behavior, a theory is developed for a hypothetical nervous system called a perceptron. The theory serves as a bridge between biophysics and psychology. It is possible to predict learning curves from neurological variables and vice versa. The quantitative statistical approach is fruitful in the understanding of the organization of cognitive systems. 18 references. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\BDLV7JLH\Rosenblatt - 1958 - The perceptron A probabilistic model for informat.pdf}
}

@article{rumelhartLearningRepresentationsBackpropagating1986,
  title = {Learning Representations by Back-Propagating Errors},
  author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  date = {1986-10},
  journaltitle = {Nature},
  volume = {323},
  number = {6088},
  pages = {533--536},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/323533a0},
  url = {https://www.nature.com/articles/323533a0},
  urldate = {2023-11-02},
  abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal ‘hidden’ units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
  issue = {6088},
  langid = {english},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\9NH839CL\Rumelhart et al. - 1986 - Learning representations by back-propagating error.pdf}
}

@inproceedings{saputrarangkutiSentimentAnalysisMovie2018,
  title = {Sentiment {{Analysis}} on {{Movie Reviews Using Ensemble Features}} and {{Pearson Correlation Based Feature Selection}}},
  booktitle = {2018 {{International Conference}} on {{Sustainable Information Engineering}} and {{Technology}} ({{SIET}})},
  author = {Saputra Rangkuti, Fachrul Rozy and Fauzi, M. Ali and Sari, Yuita Arum and Sari, Eka Dewi Lukmana},
  date = {2018-11},
  pages = {88--91},
  doi = {10.1109/SIET.2018.8693211},
  url = {https://ieeexplore.ieee.org/abstract/document/8693211?casa_token=5__tibPUwjAAAAAA:bPmeWdzCSDIV5gN4czJIZok2ibpd0jsGfW6Vfl0rX617k4jJF_OL_JzDbgt_0VB9jwyTEIo},
  urldate = {2023-12-01},
  abstract = {Microblogging has become the media information that is very popular among internet users. Therefore, the microblogging became a source of rich data for opinions and reviews especially on movie reviews. We proposed, sentiment analysis on movie review using ensemble features and Bag of Words and selection Features Pearson's Correlation to reduce the dimension of the feature and get the optimal feature combinations. Use the feature selection is done to improve the performance of the classification, reducing the dimension of the feature and get the optimal feature combinations. The process of classification using several models of Naïve Bayes i.e. Bernoulli Naïve Bayes for binary data, Gaussian Naïve Bayes for continuous data and Multinomial Naïve Bayes for numeric data. The results of this study indicate that by using the non-standard word on tweet evaluation results obtained accuracy 82\%, precision 86\%, recall 79.62\% and f-measure 82.69\% using Feature Selection 20\%. Then after using manual standardization of word the evaluation results on the accuracy increased by 8\% and then the accuracy becomes 90\%, precision 92\%, recall 88.46\% and f-measure 90.19\% using 85\% feature selection. Based on these results it can be concluded that by using the standardization of word can improve the performance of classification and feature selection Pearson's provide optimal feature combinations and reducing the total number of dimensions' feature.},
  eventtitle = {2018 {{International Conference}} on {{Sustainable Information Engineering}} and {{Technology}} ({{SIET}})},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\2TI28SDN\Saputra Rangkuti et al. - 2018 - Sentiment Analysis on Movie Reviews Using Ensemble.pdf}
}

@article{sazliBriefReviewFeedforward2006,
  title = {A Brief Review of Feed-Forward Neural Networks},
  author = {Sazli, Murat H.},
  date = {2006-01-01},
  journaltitle = {Communications Faculty of Sciences University of Ankara Series A2-A3 Physical Sciences and Engineering},
  shortjournal = {Commun.Fac.Sci.Univ.Ank.Series A2-A3: Phys.Sci. and Eng.},
  volume = {50},
  number = {01},
  pages = {0--0},
  publisher = {{Ankara University}},
  issn = {2618-6462},
  doi = {10.1501/commua1-2_0000000026},
  url = {https://dergipark.org.tr/en/pub/aupse/issue/60555/890416},
  urldate = {2023-11-01},
  abstract = {Artificial neural networks, or shortly neural networks, find applications in a very wide spectrum. In this paper, following a brief presentation of the basic aspects of feed-forward neural netvvorks, their mostly used leaming/training algorithm, the so-called back-propagation algorithm, have been described.},
  issue = {01},
  langid = {english},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\EJMHXYGK\Sazli - 2006 - A brief review of feed-forward neural networks.pdf}
}

@misc{schubert2016esports,
  title = {Esports Analytics through Encounter Detection},
  author = {Schubert, Matthias and Drachen, Anders and Mahlmann, Tobias},
  date = {2016},
  keywords = {Dota 2,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\LFHI2MR9\Schubert et al. - 2016 - Esports analytics through encounter detection othe.pdf}
}

@inproceedings{semenovPerformanceMachineLearning2017,
  title = {Performance of {{Machine Learning Algorithms}} in {{Predicting Game Outcome}} from {{Drafts}} in {{Dota}} 2},
  booktitle = {Analysis of {{Images}}, {{Social Networks}} and {{Texts}}},
  author = {Semenov, Aleksandr and Romov, Peter and Korolev, Sergey and Yashkov, Daniil and Neklyudov, Kirill},
  editor = {Ignatov, Dmitry I. and Khachay, Mikhail Yu. and Labunets, Valeri G. and Loukachevitch, Natalia and Nikolenko, Sergey I. and Panchenko, Alexander and Savchenko, Andrey V. and Vorontsov, Konstantin},
  date = {2017},
  series = {Communications in {{Computer}} and {{Information Science}}},
  pages = {26--37},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-52920-2_3},
  abstract = {In this paper we suggest the first systematic review and compare performance of most frequently used machine learning algorithms for prediction of the match winner from the teams’ drafts in Dota 2 computer game. Although previous research attempted this task with simple models, weve made several improvements in our approach aiming to take into account interactions among heroes in the draft. For that purpose we’ve tested the following machine learning algorithms: Naive Bayes classifier, Logistic Regression and Gradient Boosted Decision Trees. We also introduced Factorization Machines for that task and got our best results from them. Besides that, we found that model’s prediction accuracy depends on skill level of the players. We’ve prepared publicly available dataset which takes into account shortcomings of data used in previous research and can be used further for algorithms development, testing and benchmarking.},
  isbn = {978-3-319-52920-2},
  langid = {english},
  keywords = {Dota 2,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\ZZMFWKJP\Semenov et al. - 2017 - Performance of Machine Learning Algorithms in Pred.pdf}
}

@article{shapiroAnalysisVarianceTest1965,
  title = {An {{Analysis}} of {{Variance Test}} for {{Normality}} ({{Complete Samples}})},
  author = {Shapiro, S. S. and Wilk, M. B.},
  date = {1965-12},
  journaltitle = {Biometrika},
  shortjournal = {Biometrika},
  volume = {52},
  number = {3/4},
  eprint = {2333709},
  eprinttype = {jstor},
  pages = {591},
  issn = {00063444},
  doi = {10.2307/2333709},
  url = {https://www.jstor.org/stable/2333709?origin=crossref},
  urldate = {2023-11-29},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\D2S8A48Z\Shapiro und Wilk - 1965 - An Analysis of Variance Test for Normality (Comple.pdf}
}

@inproceedings{sharmaEraDeepNeural2017,
  title = {Era of Deep Neural Networks: {{A}} Review},
  shorttitle = {Era of Deep Neural Networks},
  booktitle = {2017 8th {{International Conference}} on {{Computing}}, {{Communication}} and {{Networking Technologies}} ({{ICCCNT}})},
  author = {Sharma, Poonam and Singh, Akansha},
  date = {2017-07},
  pages = {1--5},
  doi = {10.1109/ICCCNT.2017.8203938},
  url = {https://ieeexplore.ieee.org/abstract/document/8203938},
  urldate = {2023-11-01},
  abstract = {Deep learning has achieved remarkable success in various machine learning and computer vision applications. The learning allows multiple processing layers to learn features by themselves opposite to conventional machine learning approaches which were not able to process the data in their natural form. Deep convolution networks have shown great performance in processing images and videos, whereas recurrent nets have shown great success for sequential data. This paper reviews all the aspects and researches done till now in this area along with their future possibilities.},
  eventtitle = {2017 8th {{International Conference}} on {{Computing}}, {{Communication}} and {{Networking Technologies}} ({{ICCCNT}})},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\YUQ5A6KQ\Sharma und Singh - 2017 - Era of deep neural networks A review.pdf}
}

@article{shenDeepLearningGated2018,
  title = {Deep {{Learning}} with {{Gated Recurrent Unit Networks}} for {{Financial Sequence Predictions}}},
  author = {Shen, Guizhu and Tan, Qingping and Zhang, Haoyu and Zeng, Ping and Xu, Jianjun},
  date = {2018-01-01},
  journaltitle = {Procedia Computer Science},
  shortjournal = {Procedia Computer Science},
  series = {Recent {{Advancement}} in {{Information}} and {{Communication Technology}}:},
  volume = {131},
  pages = {895--903},
  issn = {1877-0509},
  doi = {10.1016/j.procs.2018.04.298},
  url = {https://www.sciencedirect.com/science/article/pii/S1877050918306781},
  urldate = {2023-10-31},
  abstract = {Gated recurrent unit (GRU) networks perform well in sequence learning tasks and overcome the problems of vanishing and explosion of gradients in traditional recurrent neural networks (RNNs) when learning long-term dependencies. Although they apply essentially to financial time series predictions, they are seldom used in the field. To fill this void, we propose GRU networks and its improved version for predicting trading signals for stock indexes of the Hang Seng Indexes (HSI), the Deutscher Aktienindex (DAX) and the S\&P 500 Index from 1991 to 2017, and compare the GRU-based models with the traditional deep net and the benchmark classifier support vector machine (SVM). Experimental results show that the two GRU models proposed in this paper both obtain higher prediction accuracy on these data sets, and the improved version can effectively improve the learning ability of the model.},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\8JASP4TY\Shen et al. - 2018 - Deep Learning with Gated Recurrent Unit Networks f.pdf}
}

@inproceedings{shenMachineLearningApproach2022,
  title = {A Machine Learning Approach to Predict the Result of {{League}} of {{Legends}}},
  booktitle = {2022 {{International Conference}} on {{Machine Learning}} and {{Knowledge Engineering}} ({{MLKE}})},
  author = {Shen, Qiyuan},
  date = {2022-02},
  pages = {38--45},
  doi = {10.1109/MLKE55170.2022.00013},
  abstract = {Nowadays, the MOBA game is the game type with the most audiences and players around the world. Recently, the League of Legends has become an official sport as an e-sport among 37 events in the 2022 Asia Games held in Hangzhou. As the development in the e-sport, analytical skills are also involved in this field. The topic of this research is to use the machine learning approach to analyze the data of the League of Legends and make a prediction about the result of the game. In this research, the method of machine learning is applied to the dataset which records the first 10 minutes in diamond-ranked games. Several popular machine learning (AdaBoost, GradientBoost, RandomForest, ExtraTree, SVM, Naïve Bayes, KNN, LogisticRegression, and DecisionTree) are applied to test the performance by cross-validation. Then several algorithms that outperform others are selected to make a voting classifier to predict the game result. The accuracy of the voting classifier is 72.68\%.},
  eventtitle = {2022 {{International Conference}} on {{Machine Learning}} and {{Knowledge Engineering}} ({{MLKE}})},
  keywords = {League of Legends,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\2EIL2KT2\Shen - 2022 - A machine learning approach to predict the result .pdf}
}

@article{silvaContinuousOutcomePrediction2018,
  title = {Continuous Outcome Prediction of League of Legends Competitive Matches Using Recurrent Neural Networks},
  author = {Silva, Antonio Luis Cardoso and Pappa, Gisele Lobo and Chaimowicz, Luiz},
  date = {2018},
  journaltitle = {SBC-proceedings of SBCGames},
  pages = {2179--2259},
  keywords = {League of Legends,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\WAWXTCHA\Silva et al. - 2018 - Continuous outcome prediction of league of legends.pdf}
}

@article{songPredictingWinningSide,
  title = {Predicting the Winning Side of {{DotA2}}},
  author = {Song, Kuangyan and Zhang, Tianyi and Ma, Chao},
  abstract = {In this paper, we tried using logistic regression to predict the winning side of DotA2 games based on hero lineups. We collected data using API provided by the game developer. We find out that only based on hero lineup to predict the game result is not good enough. We also tried to select feature using stepwise regression and the result is better than using all the heroes and hero combos as features.},
  langid = {english},
  keywords = {Dota 2,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\ZT2WLQD8\Song et al. - Predicting the winning side of DotA2.pdf}
}

@thesis{sutskeverTrainingRecurrentNeural2013,
  type = {phdthesis},
  title = {Training Recurrent Neural Networks},
  author = {Sutskever, Ilya},
  date = {2013},
  institution = {{University of Toronto}},
  location = {{Toronto, ON, Canada}},
  url = {https://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf},
  urldate = {2023-11-01},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\ZHED2SV5\ilya_sutskever_phd_thesis.pdf}
}

@article{svozilIntroductionMultilayerFeedforward1997,
  title = {Introduction to Multi-Layer Feed-Forward Neural Networks},
  author = {Svozil, Daniel and Kvasnicka, Vladimír and Pospichal, Jir̂í},
  date = {1997-11-01},
  journaltitle = {Chemometrics and Intelligent Laboratory Systems},
  shortjournal = {Chemometrics and Intelligent Laboratory Systems},
  volume = {39},
  number = {1},
  pages = {43--62},
  issn = {0169-7439},
  doi = {10.1016/S0169-7439(97)00061-0},
  url = {https://www.sciencedirect.com/science/article/pii/S0169743997000610},
  urldate = {2023-11-01},
  abstract = {Basic definitions concerning the multi-layer feed-forward neural networks are given. The back-propagation training algorithm is explained. Partial derivatives of the objective function with respect to the weight and threshold coefficients are derived. These derivatives are valuable for an adaptation process of the considered neural network. Training and generalisation of multi-layer feed-forward neural networks are discussed. Improvements of the standard back-propagation algorithm are reviewed. Example of the use of multi-layer feed-forward neural networks for prediction of carbon-13 NMR chemical shifts of alkanes is given. Further applications of neural networks in chemistry are reviewed. Advantages and disadvantages of multilayer feed-forward neural networks are discussed.},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\7E7FYPZP\Svozil et al. - 1997 - Introduction to multi-layer feed-forward neural ne.pdf}
}

@article{tsoiDiscreteTimeRecurrent1997,
  title = {Discrete Time Recurrent Neural Network Architectures: {{A}} Unifying Review},
  shorttitle = {Discrete Time Recurrent Neural Network Architectures},
  author = {Tsoi, Ah Chung and Back, Andrew},
  date = {1997-06-01},
  journaltitle = {Neurocomputing},
  shortjournal = {Neurocomputing},
  series = {Recurrent {{Neural Networks}}},
  volume = {15},
  number = {3},
  pages = {183--223},
  issn = {0925-2312},
  doi = {10.1016/S0925-2312(97)00161-6},
  url = {https://www.sciencedirect.com/science/article/pii/S0925231297001616},
  urldate = {2023-10-31},
  abstract = {In this paper, after giving definitions for a set of commonly used terms in recurrent neural networks (RNNs), all possible RNN architectures based on these definitions are enumerated, and described. Then, most existing RNN architectures are categorized under these headings. Four general neural network architectures, in increasing degree of complexity, are introduced. It is shown that all the existing RNN architectures can be considered as special cases of the general RNN architectures. Furthermore, it is shown how these existing architectures can be transformed to the general RNN architectures. Some open issues concerning RNN architectures are discussed.},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\YURYBDVQ\Tsoi und Back - 1997 - Discrete time recurrent neural network architectur.pdf}
}

@incollection{tsoiRecurrentNeuralNetwork1998,
  title = {Recurrent Neural Network Architectures: {{An}} Overview},
  shorttitle = {Recurrent Neural Network Architectures},
  booktitle = {Adaptive {{Processing}} of {{Sequences}} and {{Data Structures}}: {{International Summer School}} on {{Neural Networks}} “{{E}}.{{R}}. {{Caianiello}}” {{Vietri}} Sul {{Mare}}, {{Salerno}}, {{Italy September}} 6–13, 1997 {{Tutorial Lectures}}},
  author = {Tsoi, Ah Chung},
  editor = {Giles, C. Lee and Gori, Marco},
  date = {1998},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {1--26},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/BFb0053993},
  url = {https://doi.org/10.1007/BFb0053993},
  urldate = {2023-10-31},
  abstract = {In this paper, we have first considered a number of popular recurrent neural network architectures. Then, two subclasses of general recurrent neural network architectures are introduced. It is shown that all these popular recurrent neural network architectures can be grouped under either of these two subclasses of general recurrent neural network architectures. It is also inferred that these two subclasses of recurrent neural network architectures are distinct, in that it is not possible to transform from one form to the other. Two recently introduced recurrent neural network architectures specifically designed for special purposes, viz., for overcoming long term temporal dependency, and for data structure classifications are also considered.},
  isbn = {978-3-540-69752-7},
  langid = {english},
  keywords = {notion}
}

@article{vanhoudtReviewLongShortterm2020,
  title = {A Review on the Long Short-Term Memory Model},
  author = {Van Houdt, Greg and Mosquera, Carlos and Nápoles, Gonzalo},
  date = {2020-12-01},
  journaltitle = {Artificial Intelligence Review},
  shortjournal = {Artif Intell Rev},
  volume = {53},
  number = {8},
  pages = {5929--5955},
  issn = {1573-7462},
  doi = {10.1007/s10462-020-09838-1},
  url = {https://doi.org/10.1007/s10462-020-09838-1},
  urldate = {2023-11-01},
  abstract = {Long short-term memory (LSTM) has transformed both machine learning and neurocomputing fields. According to several online sources, this model has improved Google’s speech recognition, greatly improved machine translations on Google Translate, and the answers of Amazon’s Alexa. This neural system is also employed by Facebook, reaching over 4 billion LSTM-based translations per day as of 2017. Interestingly, recurrent neural networks had shown a rather discrete performance until LSTM showed up. One reason for the success of this recurrent network lies in its ability to handle the exploding/vanishing gradient problem, which stands as a difficult issue to be circumvented when training recurrent or very deep neural networks. In this paper, we present a comprehensive review that covers LSTM’s formulation and training, relevant applications reported in the literature and code resources implementing this model for a toy example.},
  langid = {english},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\EB5JZJMH\Van Houdt et al. - 2020 - A review on the long short-term memory model.pdf}
}

@article{venkateshReviewFeatureSelection2019,
  title = {A {{Review}} of {{Feature Selection}} and {{Its Methods}}},
  author = {Venkatesh, B. and Anuradha, J.},
  date = {2019-03-01},
  journaltitle = {Cybernetics and Information Technologies},
  volume = {19},
  number = {1},
  pages = {3--26},
  doi = {10.2478/cait-2019-0001},
  url = {https://sciendo.com/article/10.2478/cait-2019-0001},
  urldate = {2023-12-01},
  abstract = {AbstractNowadays, being in digital era the data generated by various applications are increasing drastically both row-wise and column wise; this creates a bottleneck for analytics and also increases the burden of machine learning algorithms that work for pattern recognition. This cause of dimensionality can be handled through reduction techniques. The Dimensionality Reduction (DR) can be handled in two ways namely Feature Selection (FS) and Feature Extraction (FE). This paper focuses on a survey of feature selection methods, from this extensive survey we can conclude that most of the FS methods use static data. However, after the emergence of IoT and web-based applications, the data are generated dynamically and grow in a fast rate, so it is likely to have noisy data, it also hinders the performance of the algorithm. With the increase in the size of the data set, the scalability of the FS methods becomes jeopardized. So the existing DR algorithms do not address the issues with the dynamic data. Using FS methods not only reduces the burden of the data but also avoids overfitting of the model.},
  langid = {english},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\WZSX5FRG\Venkatesh und Anuradha - 2019 - A Review of Feature Selection and Its Methods.pdf}
}

@article{wangComprehensiveSurveyLoss2022,
  title = {A {{Comprehensive Survey}} of {{Loss Functions}} in {{Machine Learning}}},
  author = {Wang, Qi and Ma, Yue and Zhao, Kun and Tian, Yingjie},
  date = {2022-04-01},
  journaltitle = {Annals of Data Science},
  shortjournal = {Ann. Data. Sci.},
  volume = {9},
  number = {2},
  pages = {187--212},
  issn = {2198-5812},
  doi = {10.1007/s40745-020-00253-5},
  url = {https://doi.org/10.1007/s40745-020-00253-5},
  urldate = {2023-11-02},
  abstract = {As one of the important research topics in machine learning, loss function plays an important role in the construction of machine learning algorithms and the improvement of their performance, which has been concerned and explored by many researchers. But it still has a big gap to summarize, analyze and compare the classical loss functions. Therefore, this paper summarizes and analyzes 31 classical loss functions in machine learning. Specifically, we describe the loss functions from the aspects of traditional machine learning and deep learning respectively. The former is divided into classification problem, regression problem and unsupervised learning according to the task type. The latter is subdivided according to the application scenario, and here we mainly select object detection and face recognition to introduces their loss functions. In each task or application, in addition to analyzing each loss function from formula, meaning, image and algorithm, the loss functions under the same task or application are also summarized and compared to deepen the understanding and provide help for the selection and improvement of loss function.},
  langid = {english},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\3BXNBIKE\Wang et al. - 2022 - A Comprehensive Survey of Loss Functions in Machin.pdf}
}

@article{wangModelDrivenMethodQuality,
  title = {A {{Model-Driven Method}} for {{Quality Reviews Detection}}: {{An Ensemble Model}} of {{Feature Selection}}},
  author = {Wang, Hongwei and Meng, Yuan and Yin, Pei and Hua, Jin},
  abstract = {With the rapid growth of e-commerce and user-generated content online, the increasing product online reviews have significant influence on both buyers and sellers. However, among the thousands of online reviews, only the reviews of high-quality matters to the market, thus quality reviews detection rises in response to the requirement of retrieving authentic feedbacks from consumers. In this paper, a state-of-the-art ensemble model, gradient boosting decision trees (GBDT), is applied to select useful features for quality evaluation of online reviews. Firstly, four types of features are extracted based on information adoption theory. Then, the GBDT model is adopted to select useful features for quality reviews detection. At last, comparative experiments are conducted through online reviews of searching goods, based on two baseline models such as Decision Tree and Logistic Regression, and the results show that GBDT model achieves a better performance in detecting reviews of high-quality. This research indicates that product attributes, reviewer characteristics and objectiveness of reviews are key ingredients in high quality reviews.},
  langid = {english},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\D8V2GBX8\Wang et al. - A Model-Driven Method for Quality Reviews Detectio.pdf}
}

@thesis{wangPredictingMultiplayerOnline2016,
  type = {mathesis},
  title = {Predicting {{Multiplayer Online Battle Arena}} ({{MOBA}}) {{Game Outcome Based}} on {{Hero Draft Data}}},
  author = {Wang, Weiqi},
  date = {2016-12-21},
  institution = {{Dublin, National College of Ireland}},
  url = {https://norma.ncirl.ie/2523/},
  urldate = {2023-10-05},
  abstract = {DotA 2 is a popular multi-player online battle area (MOBA) game. A critical part of the game play involves choosing from a pool of more than one hundred heroes to form two five-players team. However, as different heroes have their unique attributes and skill sets, selecting a strong combination of heroes (i.e., hero drafting) is an challenging task for new players which requires extensive knowledge and experience. Previous studies have shown that using hero draft data alone can achieve as high as 69.8\% of accuracy in predicting game outcomes. However, many aspects in hero draft remains to be further investigated. In this study, we aimed to achieve higher accuracy by adding game length as an input feature. In addition, we used multi-layer feedforward neural networks to predict the game outcome with GPU enabled. However, the results showed that adding game length does not improve the performance significantly nor did neural networks outperform logistic regression significantly.},
  langid = {english},
  pagetotal = {16},
  keywords = {Dota 2,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\NK2SMRUC\Wang - 2016 - Predicting Multiplayer Online Battle Arena (MOBA) .pdf}
}

@article{whiteScalablePsychologicalMomentum2020,
  title = {Scalable {{Psychological Momentum Forecasting}} in {{Esports}}},
  author = {White, Alfonso and Romano, Daniela M},
  date = {2020},
  abstract = {The world of competitive Esports and video gaming has seen and continues to experience steady growth in popularity and complexity. Correspondingly, more research on the topic is being published, ranging from social network analyses to the benchmarking of advanced artificial intelligence systems in playing against humans. In this paper, we present ongoing work on an intelligent agent recommendation engine that suggests actions to players in order to maximise success and enjoyment, both in the space of in-game choices, as well as decisions made around play session timing in the broader context. By leveraging temporal data and appropriate models, we show that a learned representation of player psychological momentum, and of tilt, can be used, in combination with player expertise, to achieve state-of-the-art performance in preand post-draft win prediction. Our progress toward fulfilling the potential for deriving optimal recommendations is documented.},
  langid = {english},
  keywords = {League of Legends,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\GACNTEW4\White und Romano - 2020 - Scalable Psychological Momentum Forecasting in Esp.pdf}
}

@article{xiaWhatContributesSuccess2019,
  title = {What {{Contributes}} to {{Success}} in {{MOBA Games}}? {{An Empirical Study}} of {{Defense}} of the {{Ancients}} 2},
  shorttitle = {What {{Contributes}} to {{Success}} in {{MOBA Games}}?},
  author = {Xia, Bang and Wang, Huiwen and Zhou, Ronggang},
  date = {2019-07-01},
  journaltitle = {Games and Culture},
  volume = {14},
  number = {5},
  pages = {498--522},
  publisher = {{SAGE Publications}},
  issn = {1555-4120},
  doi = {10.1177/1555412017710599},
  url = {https://doi.org/10.1177/1555412017710599},
  urldate = {2023-10-05},
  abstract = {With the development of computer science and Internet technology, online games have become one of the most important sources of entertainment in daily life. Meanwhile, increasing attention has been paid to top international electronic sports (eSports) tournaments in which competitive pressure is becoming increasingly more serious. Therefore, how to win such games is a problem worth exploring. This article proposes a set of evaluation indicators for testing gameplay in Defense of the Ancients 2, which is a popular multiplayer online game. The analysis shows that the multiplayer killing indicator is an effective predictor of the game result. Furthermore, the evaluation indicators are divided into two categories: operational skills and tactical awareness. The functions of the indicators in each category are discussed. The results show that, for professional eSports teams, tactical awareness affects the multiplayer killing indicator and the game result more so than operational skills.},
  langid = {english},
  keywords = {Dota 2,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\EVE3TP9B\Xia et al. - 2019 - What Contributes to Success in MOBA Games An Empi.pdf}
}

@article{yangIdentifyingPatternsCombat,
  title = {Identifying {{Patterns}} in {{Combat}} That Are {{Predictive}} of {{Success}} in {{MOBA Games}}},
  author = {Yang, Pu and Harrison, Brent and Roberts, David L},
  abstract = {Multiplayer Online Battle Arena (MOBA) games rely primarily on combat to determine the ultimate outcome of the game. Combat in these types of games is highly-dynamic and can be difficult for novice players to learn. Typically, mastery of combat requires that players obtain expert knowledge through practice, which can be difficult to concisely describe. In this paper, we present a data-driven approach for discovering patterns in combat tactics that are common among winning teams in MOBA games. We model combat as a sequence of graphs and extract patterns that predict successful outcomes not just of combat, but of the entire game. To identify those patterns, we attribute features to these graphs using well known graph metrics. These features allow us to describe, in meaningful terms, how different combat tactics contribute to team success. We also present an evaluation of our methodology on the popular MOBA game, DotA 2 (Defense of the Ancients 2). Experiments show that extracted patterns achieve an 80\% prediction accuracy when testing on new game logs.},
  langid = {english},
  keywords = {Dota 2,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\BN78FU8J\Yang et al. - Identifying Patterns in Combat that are Predictive.pdf}
}

@article{yangPredictingEventsMOBA2023,
  title = {Predicting {{Events}} in {{MOBA Games}}: {{Prediction}}, {{Attribution}}, and {{Evaluation}}},
  shorttitle = {Predicting {{Events}} in {{MOBA Games}}},
  author = {Yang, Zelong and Wang, Yan and Li, Piji and Lin, Shaobin and Shi, Shuming and Huang, Shao-Lun and Bi, Wei},
  date = {2023-06},
  journaltitle = {IEEE Transactions on Games},
  volume = {15},
  number = {2},
  pages = {193--201},
  issn = {2475-1510},
  doi = {10.1109/TG.2022.3159704},
  url = {https://ieeexplore.ieee.org/abstract/document/9736637?casa_token=pGyrmu9M6zkAAAAA:bRG_TvNgtbgl297zcvJzStcZsQGOF0OFedkBUl2V7K11ZQMB4q6H3VO6tBzk2ZfB90CFsDXg},
  urldate = {2023-09-26},
  abstract = {The multiplayer online battle arena (MOBA) games have become increasingly popular in recent years. Consequently, many efforts have been devoted to providing pregame or in-game predictions for them. These predictions can be used in many MOBA esports-related applications, such as artificial intelligence commentator systems, in-game data analysis, and game-assistant bots. However, these works are limited in the following two aspects: the lack of sufficient in-game features and the absence of interpretability in the prediction results. These two limitations greatly restrict the practical performance and industrial application of the current works. In this work, we collect a large-scale dataset containing rich in-game features for the popular MOBA game Honor of Kings. We then propose to predict four types of prediction tasks in an interpretable way by attributing the predictions to the input features using two gradient-based attribution methods: Integrated Gradients and SmoothGrad. To evaluate the explanatory power of different models and attribution methods, a fidelity-based evaluation metric is further proposed. Finally, we evaluate the accuracy and fidelity of several competitive methods to assess how well machines predict events in MOBA games.},
  eventtitle = {{{IEEE Transactions}} on {{Games}}},
  keywords = {MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\QV6R7I8B\Yang et al. - 2023 - Predicting Events in MOBA Games Prediction, Attri.pdf}
}

@online{yangRealtimeESportsMatch2016,
  title = {Real-Time {{eSports Match Result Prediction}}},
  author = {Yang, Yifan and Qin, Tian and Lei, Yu-Heng},
  date = {2016-12-10},
  eprint = {1701.03162},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1701.03162},
  url = {http://arxiv.org/abs/1701.03162},
  urldate = {2023-09-25},
  abstract = {In this paper, we try to predict the winning team of a match in the multiplayer eSports game Dota 2. To address the weaknesses of previous work, we consider more aspects of prior (pre-match) features from individual players' match history, as well as real-time (during-match) features at each minute as the match progresses. We use logistic regression, the proposed Attribute Sequence Model, and their combinations as the prediction models. In a dataset of 78362 matches where 20631 matches contain replay data, our experiments show that adding more aspects of prior features improves accuracy from 58.69\% to 71.49\%, and introducing real-time features achieves up to 93.73\% accuracy when predicting at the 40th minute.},
  pubstate = {preprint},
  keywords = {Dota 2,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\XTNCHLIB\Yang et al. - 2016 - Real-time eSports Match Result Prediction.pdf}
}

@book{yuMOBASliceTimeSlice2018,
  title = {{{MOBA-Slice}}: {{A Time Slice Based Evaluation Framework}} of {{Relative Advantage}} between {{Teams}} in {{MOBA Games}}},
  shorttitle = {{{MOBA-Slice}}},
  author = {Yu, Lijun and Zhang, Dawei and Chen, Xiangqun and Xie, Xing},
  date = {2018-07-22},
  abstract = {Multiplayer Online Battle Arena (MOBA) is currently one of the most popular genres of digital games around the world. The domain of knowledge contained in these complicated games is large. It is hard for humans and algorithms to evaluate the real-time game situation or predict the game result. In this paper, we introduce MOBA-Slice, a time slice based evaluation framework of relative advantage between teams in MOBA games. MOBA-Slice is a quantitative evaluation method based on learning, similar to the value network of AlphaGo. It establishes a foundation for further MOBA related research including AI development. In MOBA-Slice, with an analysis of the deciding factors of MOBA game results, we design a neural network model to fit our discounted evaluation function. Then we apply MOBA-Slice to Defense of the Ancients 2 (DotA2), a typical and popular MOBA game. Experiments on a large number of match replays show that our model works well on arbitrary matches. MOBA-Slice not only has an accuracy 3.7\% higher than DotA Plus Assistant at result prediction, but also supports the prediction of the remaining time of the game, and then realizes the evaluation of relative advantage between teams.},
  keywords = {Dota 2,notion},
  file = {C:\Users\morit\Zotero\storage\U9PWHFP4\Yu et al. - 2018 - MOBA-Slice A Time Slice Based Evaluation Framewor.pdf}
}

@article{yuReviewRecurrentNeural2019,
  title = {A {{Review}} of {{Recurrent Neural Networks}}: {{LSTM Cells}} and {{Network Architectures}}},
  shorttitle = {A {{Review}} of {{Recurrent Neural Networks}}},
  author = {Yu, Yong and Si, Xiaosheng and Hu, Changhua and Zhang, Jianxun},
  date = {2019-07-01},
  journaltitle = {Neural Computation},
  shortjournal = {Neural Computation},
  volume = {31},
  number = {7},
  pages = {1235--1270},
  issn = {0899-7667},
  doi = {10.1162/neco_a_01199},
  url = {https://doi.org/10.1162/neco_a_01199},
  urldate = {2023-11-07},
  abstract = {Recurrent neural networks (RNNs) have been widely adopted in research areas concerned with sequential data, such as text, audio, and video. However, RNNs consisting of sigma cells or tanh cells are unable to learn the relevant information of input data when the input gap is large. By introducing gate functions into the cell structure, the long short-term memory (LSTM) could handle the problem of long-term dependencies well. Since its introduction, almost all the exciting results based on RNNs have been achieved by the LSTM. The LSTM has become the focus of deep learning. We review the LSTM cell and its variants to explore the learning capacity of the LSTM cell. Furthermore, the LSTM networks are divided into two broad categories: LSTM-dominated networks and integrated LSTM networks. In addition, their various applications are discussed. Finally, future research directions are presented for LSTM networks.},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\2MKNGEIB\A-Review-of-Recurrent-Neural-Networks-LSTM-Cells.html}
}

@inproceedings{zhangGeneralizedCrossEntropy2018,
  title = {Generalized {{Cross Entropy Loss}} for {{Training Deep Neural Networks}} with {{Noisy Labels}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Zhang, Zhilu and Sabuncu, Mert},
  date = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper_files/paper/2018/hash/f2925f97bc13ad2852a7a551802feea0-Abstract.html},
  urldate = {2023-11-02},
  abstract = {Deep neural networks (DNNs) have achieved tremendous success in a variety of applications across many disciplines. Yet, their superior performance comes with the expensive cost of requiring correctly annotated large-scale datasets. Moreover, due to DNNs' rich capacity, errors in training labels can hamper performance. To combat this problem, mean absolute error (MAE) has recently been proposed as a noise-robust alternative to the commonly-used categorical cross entropy (CCE) loss. However, as we show in this paper, MAE can perform poorly with DNNs and large-scale datasets. Here, we present a theoretically grounded set of noise-robust loss functions that can be seen as a generalization of MAE and CCE. Proposed loss functions can be readily applied with any existing DNN architecture and algorithm, while yielding good performance in a wide range of noisy label scenarios. We report results from experiments conducted with CIFAR-10, CIFAR-100 and FASHION-MNIST datasets and synthetically generated noisy labels.},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\KHNNGZH7\Zhang und Sabuncu - 2018 - Generalized Cross Entropy Loss for Training Deep N.pdf}
}

@inproceedings{zhangPredictionEsportsGame2021,
  title = {Prediction of {{Esports Game Results Using Early Game Datasets}}},
  booktitle = {{{ICMLCA}} 2021; 2nd {{International Conference}} on {{Machine Learning}} and {{Computer Application}}},
  author = {Zhang, Yunhai},
  date = {2021-12},
  pages = {1--6},
  url = {https://ieeexplore.ieee.org/abstract/document/9736891},
  urldate = {2023-10-05},
  abstract = {Large e-sports games are becoming prevailing at an unprecedented around the world in recent years. Thus, an increasing amount of effort is put into game-predictions for worldwide audiences. However, most of the game prediction results are restricted by both the high uncertainty at the early-game stage, and the hardship of interpreting them for audiences. In this paper, we mainly focus on predicting the game results for one of the most popular games, League of Legends, using the first ten minute in-game features. This research uses Active Learning as the main method to evaluate the dataset that contains approximately ten thousand high-Elo ranked games. Then, the research compares the results of prediction based on our active learning algorithms and the random selection methods. The research experiment finally presents that the prediction result of the active learning model is similar to that of the traditional machine learning methods and outweigh the accuracy of random selection. The paper can conclude that we may save a lot of human-needed work and use a relatively small amount of initial datasets to generate more accurate game predictions by implementing active learning in large data-based e-sports matches.},
  eventtitle = {{{ICMLCA}} 2021; 2nd {{International Conference}} on {{Machine Learning}} and {{Computer Application}}},
  keywords = {League of Legends,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\4ZFJA4YH\Zhang - 2021 - Prediction of Esports Game Results Using Early Gam.pdf}
}

@inproceedings{zhaoWinningTrackerNew2022,
  title = {Winning {{Tracker}}: {{A New Model}} for {{Real-time Winning Prediction}} in {{MOBA Games}}},
  shorttitle = {Winning {{Tracker}}},
  booktitle = {Proceedings of the {{ACM Web Conference}} 2022},
  author = {Zhao, Chuang and Zhao, Hongke and Ge, Yong and Wu, Runze and Shen, Xudong},
  date = {2022-04-25},
  pages = {3387--3395},
  publisher = {{ACM}},
  location = {{Virtual Event, Lyon France}},
  doi = {10.1145/3485447.3512274},
  url = {https://dl.acm.org/doi/10.1145/3485447.3512274},
  urldate = {2023-09-25},
  abstract = {With an increasing popularity, Multiplayer Online Battle Arena (MOBA) games where two opposing teams compete against each other, have played a major role in E-sports tournaments. Among game analysis, real-time winning prediction is an important but challenging problem, which is mainly due to the complicated coupling of the overall Confrontation1, the excessive noise of the player’s Movement, and unclear optimization goals. Existing research is difficult to solve this problem in a dynamic, comprehensive and systematic way. In this study, we design a unified framework, namely Winning Tracker (WT), for solving this problem. Specifically, offense and defense extractors are developed to extract the Confrontation of both sides. A well-designed trajectory representation algorithm is applied to extracting individual’s Movement information. Moreover, we design a hierarchical attention mechanism to capture team-level strategies and facilitate the interpretability of the framework. To optimize accurately, we adopt a multi-task learning method to design short-term and long-term goals, which are used to represent immediate state and make end-state prediction respectively. Intensive experiments on a real-world data set demonstrate that our proposed method WT outperforms state-of-the-art algorithms. Furthermore, our work has been practically deployed in real MOBA games, and provided case studies reflecting its outstanding commercial value.},
  eventtitle = {{{WWW}} '22: {{The ACM Web Conference}} 2022},
  isbn = {978-1-4503-9096-5},
  langid = {english},
  keywords = {Dota 2,MOBA,notion},
  file = {C:\Users\morit\Zotero\storage\FA98I9RA\Zhao et al. - 2022 - Winning Tracker A New Model for Real-time Winning.pdf}
}

@article{zhouServingDeepLearning2022,
  title = {Serving {{Deep Learning Models}} with {{Deduplication}} from {{Relational Databases}}},
  author = {Zhou, Lixi and Chen, Jiaqing and Das, Amitabh and Min, Hong and Yu, Lei and Zhao, Ming and Zou, Jia},
  date = {2022-06},
  journaltitle = {Proceedings of the VLDB Endowment},
  shortjournal = {Proc. VLDB Endow.},
  volume = {15},
  number = {10},
  eprint = {2201.10442},
  eprinttype = {arxiv},
  eprintclass = {cs},
  pages = {2230--2243},
  issn = {2150-8097},
  doi = {10.14778/3547305.3547325},
  url = {http://arxiv.org/abs/2201.10442},
  urldate = {2023-09-10},
  abstract = {There are significant benefits to serve deep learning models from relational databases. First, features extracted from databases do not need to be transferred to any decoupled deep learning systems for inferences, and thus the system management overhead can be significantly reduced. Second, in a relational database, data management along the storage hierarchy is fully integrated with query processing, and thus it can continue model serving even if the working set size exceeds the available memory. Applying model deduplication can greatly reduce the storage space, memory footprint, cache misses, and inference latency. However, existing data deduplication techniques are not applicable to the deep learning model serving applications in relational databases. They do not consider the impacts on model inference accuracy as well as the inconsistency between tensor blocks and database pages. This work proposed synergistic storage optimization techniques for duplication detection, page packing, and caching, to enhance database systems for model serving. We implemented the proposed approach in netsDB, an object-oriented relational database. Evaluation results show that our proposed techniques significantly improved the storage efficiency and the model inference latency, and serving models from relational databases outperformed existing deep learning frameworks when the working set size exceeds available memory.},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\244A35X9\Zhou et al. - 2022 - Serving Deep Learning Models with Deduplication fr.pdf}
}

@inproceedings{zhuComparisonLossFunctions2018,
  title = {Comparison of {{Loss Functions}} for {{Training}} of {{Deep Neural Networks}} in {{Shogi}}},
  booktitle = {2018 {{Conference}} on {{Technologies}} and {{Applications}} of {{Artificial Intelligence}} ({{TAAI}})},
  author = {Zhu, Hanhua and Kaneko, Tomoyuki},
  date = {2018-11},
  pages = {18--23},
  issn = {2376-6824},
  doi = {10.1109/TAAI.2018.00014},
  url = {https://ieeexplore.ieee.org/abstract/document/8588470?casa_token=VdYFRHjjBW0AAAAA:IuCvfctbF0dH5nK_FXUEaAzuhIzWrwSnh2Pq8mKZInUGjADDrYyGYf81FiLcM4EzHvAY4nonFA},
  urldate = {2023-11-02},
  abstract = {Evaluation functions are crucial for building strong computer players in two-player games, such as chess, Go, and shogi. Although a linear combination of a large number of features has been popular representation of an evaluation function in shogi, deep neural networks (DNNs) are recently considered to be more promising by the success of AlphaZero in multiple domains, chess, Go, and shogi. This paper shows that three loss functions, loss in comparison training, temporal difference (TD) errors and cross entropy loss in win prediction, are effective for the training of evaluation functions in shogi, presented in deep neural networks. For the training of DNNs in AlphaZero, the main loss function only consists of win prediction, though it is augmented with move prediction for regularization. On the other hand, for training in traditional shogi programs, various losses including loss in comparison training, TD errors, and cross entropy loss in win prediction, have contributed to yield accurate evaluation functions which are the linear combination of a large number of features. Therefore, it is promising to combine these loss functions and to apply them to the training of modern DNNs. In our experiments, we show that training with combinations of loss functions improved the accuracy of evaluation functions represented by DNNs. The performance of trained evaluation functions is tested through top-1 accuracy, 1-1 accuracy, and self-play.},
  eventtitle = {2018 {{Conference}} on {{Technologies}} and {{Applications}} of {{Artificial Intelligence}} ({{TAAI}})},
  keywords = {notion},
  file = {C:\Users\morit\Zotero\storage\EY34ZHHB\Zhu und Kaneko - 2018 - Comparison of Loss Functions for Training of Deep .pdf}
}
