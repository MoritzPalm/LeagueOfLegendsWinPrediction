{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-31T06:44:58.222508800Z",
     "start_time": "2023-10-31T06:44:58.035348300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from torch import optim, nn\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"architecture\": \"NN\",\n",
    "    \"dataset\": \"static_1.1\",\n",
    "    \"epochs\": 5,\n",
    "    \"classes\": 2,\n",
    "    \"batch_size\": 32,\n",
    "    \"num_layers\": 2,\n",
    "    \"hidden_size\": 128,\n",
    "    \"dropout_prob\": 0.3,\n",
    "    \"input_size\": 99,\n",
    "    \"output_size\": 1,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"loss\": \"CrossEntropyLoss\",\n",
    "    \"activation\": \"ReLU\",\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T06:44:58.229741700Z",
     "start_time": "2023-10-31T06:44:58.043486800Z"
    }
   },
   "id": "e13812e0d04c772b"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def model_pipeline(hyperparameters):\n",
    "    with wandb.init(project=\"leaguify\", config=hyperparameters):\n",
    "        # access all HPs through wandb.config, so logging matches execution!\n",
    "        config = wandb.config\n",
    "\n",
    "        # make the model, data, and optimization problem\n",
    "        model, train_loader, val_loader, test_loader, criterion, optimizer = make(config)\n",
    "        print(model)\n",
    "\n",
    "        # and use them to train the model\n",
    "        train(model, train_loader, val_loader, criterion, optimizer, config)\n",
    "\n",
    "        # and test its final performance\n",
    "        test(model, val_loader)\n",
    "        test(model, test_loader)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T06:44:58.230742300Z",
     "start_time": "2023-10-31T06:44:58.048460900Z"
    }
   },
   "id": "bbb0d7d96615b112"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class StaticDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None, target_transform=None):\n",
    "        self.data = torch.tensor(np.load(data_dir)[:, :-1], dtype=torch.float32, device=device)\n",
    "        self.labels = torch.tensor(np.load(data_dir)[:, -1], dtype=torch.int64, device=device)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.print_statistics()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx, 1:]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return sample, label\n",
    "\n",
    "    def print_statistics(self):\n",
    "        print(f'Number of samples: {len(self.data)}')\n",
    "        print(f'Number of features: {len(self.data[0])}')\n",
    "        print(f'Number of classes: {len(np.unique(self.labels.cpu().numpy()))}')\n",
    "        print(f'Number of samples per class: {np.bincount(self.labels.cpu().numpy())}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T06:44:58.315312600Z",
     "start_time": "2023-10-31T06:44:58.052984300Z"
    }
   },
   "id": "c843eaf2d2fe8be7"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def make(config):\n",
    "    train_data, val_data = get_train_data()\n",
    "    train_loader = make_loader(train_data, batch_size=config.batch_size)\n",
    "    val_loader = make_loader(val_data, batch_size=config.batch_size)\n",
    "    test_loader = make_loader(get_test_data(), batch_size=config.batch_size)\n",
    "    model = NeuralNetwork(config.input_size, config.hidden_size, config.num_layers, config.dropout_prob,\n",
    "                          config.classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if config.optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.learning_rate)\n",
    "    else:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "    return model, train_loader, val_loader, test_loader, criterion, optimizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T06:44:58.315312600Z",
     "start_time": "2023-10-31T06:44:58.059956400Z"
    }
   },
   "id": "3ccb742896a9db03"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def get_train_data(val_split=0.8):\n",
    "    dataset = StaticDataset('../data/processed/train_static.npy')\n",
    "    train_len = int(len(dataset) * val_split)\n",
    "    val_len = len(dataset) - train_len\n",
    "    print(f'train_len: {train_len}, val_len: {val_len}')\n",
    "    return torch.utils.data.random_split(dataset, [train_len, val_len])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T06:44:58.315312600Z",
     "start_time": "2023-10-31T06:44:58.063476600Z"
    }
   },
   "id": "7a0d955b1c217921"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def get_test_data():\n",
    "    return StaticDataset('../data/processed/test_static.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T06:44:58.315312600Z",
     "start_time": "2023-10-31T06:44:58.066019400Z"
    }
   },
   "id": "4ff9a0b79c444569"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def make_loader(dataset, batch_size=64):\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T06:44:58.315312600Z",
     "start_time": "2023-10-31T06:44:58.070061800Z"
    }
   },
   "id": "7feb26d9fd1afd97"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.0+cu121\n",
      "**********\n",
      "_CUDA version: \n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Tue_Aug_15_22:09:35_Pacific_Daylight_Time_2023\n",
      "Cuda compilation tools, release 12.2, V12.2.140\n",
      "Build cuda_12.2.r12.2/compiler.33191640_0\n",
      "**********\n",
      "CUDNN version: 8801\n",
      "Available GPU devices: 1\n",
      "Device Name: NVIDIA GeForce RTX 2080\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "if torch.cuda.is_available():\n",
    "    print(f'PyTorch version: {torch.__version__}')\n",
    "    print('*' * 10)\n",
    "    print(f'_CUDA version: ')\n",
    "    !nvcc --version\n",
    "    print('*' * 10)\n",
    "    print(f'CUDNN version: {torch.backends.cudnn.version()}')\n",
    "    print(f'Available GPU devices: {torch.cuda.device_count()}')\n",
    "    print(f'Device Name: {torch.cuda.get_device_name()}')\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T06:44:58.316310100Z",
     "start_time": "2023-10-31T06:44:58.079065500Z"
    }
   },
   "id": "aace44d3e59a63c3"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout_prob, num_classes=2):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            if i == 0:\n",
    "                self.linear_relu_stack.append(nn.Linear(input_size, hidden_size))\n",
    "            else:\n",
    "                self.linear_relu_stack.append(nn.Linear(hidden_size, hidden_size))\n",
    "            self.linear_relu_stack.append(nn.ReLU())\n",
    "            self.linear_relu_stack.append(self.dropout)\n",
    "        self.linear_relu_stack.append(nn.Linear(hidden_size, num_classes))\n",
    "        self.linear_relu_stack.append(nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T06:44:58.317310900Z",
     "start_time": "2023-10-31T06:44:58.219506800Z"
    }
   },
   "id": "3a87d27c212fc895"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, config):\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "    example_count = 0\n",
    "    batch_count = 0\n",
    "    for epoch in tqdm(range(config.epochs)):\n",
    "        model.train()\n",
    "        for _, (matches, labels) in enumerate(train_loader):\n",
    "            matches, labels = matches.to(device), labels.to(device)\n",
    "            loss = train_batch(matches, labels, model, optimizer, criterion)\n",
    "            example_count += len(matches)\n",
    "            batch_count += 1\n",
    "            if ((batch_count + 1) % 25) == 0:\n",
    "                train_log(loss, example_count, epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T06:44:58.317310900Z",
     "start_time": "2023-10-31T06:44:58.226717500Z"
    }
   },
   "id": "8639047e162f0756"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def train_batch(matches, labels, model, optimizer, criterion):\n",
    "    matches, labels = matches.to(device), labels.to(device)\n",
    "\n",
    "    # Forward pass ➡\n",
    "    outputs = model(matches)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Backward pass ⬅\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Step with optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T06:44:58.339839Z",
     "start_time": "2023-10-31T06:44:58.230742300Z"
    }
   },
   "id": "b21b9868aaeaebac"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def train_log(loss, example_count, epoch):\n",
    "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_count)\n",
    "    print(f\"Loss after {str(example_count).zfill(5)} examples: {loss:.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T06:44:58.340841700Z",
     "start_time": "2023-10-31T06:44:58.237113600Z"
    }
   },
   "id": "1d4afe9b0efd101a"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    # Run the model on some test examples\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for matches, labels in test_loader:\n",
    "            matches, labels = matches.to(device), labels.to(device)\n",
    "            outputs = model(matches)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        print(classification_report(y_pred, y_true))\n",
    "\n",
    "        print(f\"Accuracy of the model on the {total} \" +\n",
    "              f\"test matches: {correct / total:%}\")\n",
    "\n",
    "        wandb.log({\"test_accuracy\": correct / total})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T06:44:58.340841700Z",
     "start_time": "2023-10-31T06:44:58.245487700Z"
    }
   },
   "id": "7e2790071f2ec71e"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.12"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Users\\morit\\Documents\\Informatik\\Projekte\\LeagueOfLegendsWinPrediction\\Training\\wandb\\run-20231031_074458-7y4mu0ij</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/moritz-palm/leaguify/runs/7y4mu0ij' target=\"_blank\">phantom-spider-9439</a></strong> to <a href='https://wandb.ai/moritz-palm/leaguify' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/moritz-palm/leaguify' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/moritz-palm/leaguify/runs/7y4mu0ij' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify/runs/7y4mu0ij</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 15960\n",
      "Number of features: 100\n",
      "Number of classes: 2\n",
      "Number of samples per class: [7591 8369]\n",
      "train_len: 12768, val_len: 3192\n",
      "Number of samples: 3990\n",
      "Number of features: 100\n",
      "Number of classes: 2\n",
      "Number of samples per class: [1902 2088]\n",
      "NeuralNetwork(\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=99, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=2, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 00768 examples: 0.641\n",
      "Loss after 01568 examples: 0.672\n",
      "Loss after 02368 examples: 0.585\n",
      "Loss after 03168 examples: 0.568\n",
      "Loss after 03968 examples: 0.574\n",
      "Loss after 04768 examples: 0.561\n",
      "Loss after 05568 examples: 0.472\n",
      "Loss after 06368 examples: 0.566\n",
      "Loss after 07168 examples: 0.673\n",
      "Loss after 07968 examples: 0.603\n",
      "Loss after 08768 examples: 0.724\n",
      "Loss after 09568 examples: 0.585\n",
      "Loss after 10368 examples: 0.547\n",
      "Loss after 11168 examples: 0.619\n",
      "Loss after 11968 examples: 0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:01<00:05,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 12768 examples: 0.698\n",
      "Loss after 13568 examples: 0.665\n",
      "Loss after 14368 examples: 0.543\n",
      "Loss after 15168 examples: 0.569\n",
      "Loss after 15968 examples: 0.675\n",
      "Loss after 16768 examples: 0.596\n",
      "Loss after 17568 examples: 0.677\n",
      "Loss after 18368 examples: 0.536\n",
      "Loss after 19168 examples: 0.572\n",
      "Loss after 19968 examples: 0.563\n",
      "Loss after 20768 examples: 0.695\n",
      "Loss after 21568 examples: 0.604\n",
      "Loss after 22368 examples: 0.632\n",
      "Loss after 23168 examples: 0.606\n",
      "Loss after 23968 examples: 0.649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:02<00:03,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 24768 examples: 0.643\n",
      "Loss after 25568 examples: 0.566\n",
      "Loss after 26368 examples: 0.658\n",
      "Loss after 27168 examples: 0.637\n",
      "Loss after 27968 examples: 0.673\n",
      "Loss after 28768 examples: 0.723\n",
      "Loss after 29568 examples: 0.652\n",
      "Loss after 30368 examples: 0.798\n",
      "Loss after 31168 examples: 0.584\n",
      "Loss after 31968 examples: 0.763\n",
      "Loss after 32768 examples: 0.623\n",
      "Loss after 33568 examples: 0.681\n",
      "Loss after 34368 examples: 0.778\n",
      "Loss after 35168 examples: 0.632\n",
      "Loss after 35968 examples: 0.735\n",
      "Loss after 36768 examples: 0.775\n",
      "Loss after 37568 examples: 0.720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:03<00:02,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 38368 examples: 0.767\n",
      "Loss after 39168 examples: 0.630\n",
      "Loss after 39968 examples: 0.654\n",
      "Loss after 40768 examples: 0.681\n",
      "Loss after 41568 examples: 0.560\n",
      "Loss after 42368 examples: 0.774\n",
      "Loss after 43168 examples: 0.786\n",
      "Loss after 43968 examples: 0.704\n",
      "Loss after 44768 examples: 0.716\n",
      "Loss after 45568 examples: 0.615\n",
      "Loss after 46368 examples: 0.596\n",
      "Loss after 47168 examples: 0.716\n",
      "Loss after 47968 examples: 0.631\n",
      "Loss after 48768 examples: 0.694\n",
      "Loss after 49568 examples: 0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:04<00:01,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 50368 examples: 0.581\n",
      "Loss after 51168 examples: 0.710\n",
      "Loss after 51968 examples: 0.737\n",
      "Loss after 52768 examples: 0.526\n",
      "Loss after 53568 examples: 0.725\n",
      "Loss after 54368 examples: 0.549\n",
      "Loss after 55168 examples: 0.581\n",
      "Loss after 55968 examples: 0.588\n",
      "Loss after 56768 examples: 0.710\n",
      "Loss after 57568 examples: 0.624\n",
      "Loss after 58368 examples: 0.587\n",
      "Loss after 59168 examples: 0.709\n",
      "Loss after 59968 examples: 0.673\n",
      "Loss after 60768 examples: 0.634\n",
      "Loss after 61568 examples: 0.599\n",
      "Loss after 62368 examples: 0.829\n",
      "Loss after 63168 examples: 0.568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:06<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63      1480\n",
      "           1       0.68      0.66      0.67      1712\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.256892%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.63      1821\n",
      "           1       0.69      0.66      0.67      2169\n",
      "\n",
      "    accuracy                           0.65      3990\n",
      "   macro avg       0.65      0.65      0.65      3990\n",
      "weighted avg       0.65      0.65      0.65      3990\n",
      "\n",
      "Accuracy of the model on the 3990 test matches: 65.037594%\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆████████</td></tr><tr><td>loss</td><td>▅▄▃▁▆▇▃▅▅▃▄▂▃▄▄▅▅▆▅▄▄█▇▇▅▆█▆▄▇▆▃▇▇▃▆▄▆▄▃</td></tr><tr><td>test_accuracy</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>0.56763</td></tr><tr><td>test_accuracy</td><td>0.65038</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">phantom-spider-9439</strong> at: <a href='https://wandb.ai/moritz-palm/leaguify/runs/7y4mu0ij' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify/runs/7y4mu0ij</a><br/> View job at <a href='https://wandb.ai/moritz-palm/leaguify/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwNTk5NjA5Nw==/version_details/v48' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwNTk5NjA5Nw==/version_details/v48</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20231031_074458-7y4mu0ij\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = model_pipeline(config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T06:45:15.057531200Z",
     "start_time": "2023-10-31T06:44:58.247486Z"
    }
   },
   "id": "63223f3b223d001a"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T06:45:15.071281800Z",
     "start_time": "2023-10-31T06:45:15.058767200Z"
    }
   },
   "id": "7797f9f08cbc4ded"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
