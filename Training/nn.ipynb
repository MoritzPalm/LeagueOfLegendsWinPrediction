{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-20T10:36:25.651042800Z",
     "start_time": "2023-10-20T10:36:19.935155500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mmoritz-palm\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import Tensor, optim, nn\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"architecture\": \"NN\",\n",
    "    \"dataset\": \"static_1.1\",\n",
    "    \"epochs\": 100,\n",
    "    \"classes\": 2,\n",
    "    \"batch_size\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"hidden_size\": 64,\n",
    "    \"dropout_prob\": 0.2,\n",
    "    \"input_size\": 229,\n",
    "    \"output_size\": 2,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"loss\": \"CrossEntropyLoss\",\n",
    "    \"activation\": \"ReLU\",\n",
    "    \"initializer\": \"Xavier\",\n",
    "    \"regularization\": \"L2\",\n",
    "    \"regularization_lambda\": 0.01,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e13812e0d04c772b"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def model_pipeline(hyperparameters):\n",
    "    with wandb.init(project=\"leaguify\", config=hyperparameters):\n",
    "        # access all HPs through wandb.config, so logging matches execution!\n",
    "        config = wandb.config\n",
    "\n",
    "        # make the model, data, and optimization problem\n",
    "        model, train_loader, test_loader, criterion, optimizer = make(config)\n",
    "        print(model)\n",
    "\n",
    "        # and use them to train the model\n",
    "        train(model, train_loader, criterion, optimizer, config)\n",
    "\n",
    "        # and test its final performance\n",
    "        test(model, test_loader)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T10:36:27.910624900Z",
     "start_time": "2023-10-20T10:36:27.907624200Z"
    }
   },
   "id": "bbb0d7d96615b112"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class StaticDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None, target_transform=None):\n",
    "        self.data = torch.tensor(np.load(data_dir)[:, :-1], dtype=torch.float32, device=device)\n",
    "        self.labels = torch.tensor(np.load(data_dir)[:, -1], dtype=torch.int64, device=device)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx, 1:]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return sample, label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T10:36:27.918165300Z",
     "start_time": "2023-10-20T10:36:27.910624900Z"
    }
   },
   "id": "c843eaf2d2fe8be7"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def make(config):\n",
    "    train, test = get_data(train=True), get_data(train=False)\n",
    "    train_loader = make_loader(train, batch_size=config.batch_size)\n",
    "    test_loader = make_loader(test, batch_size=config.batch_size)\n",
    "\n",
    "    model = NeuralNetwork(config.input_size, config.hidden_size, config.num_layers, config.dropout_prob,\n",
    "                          config.classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if config.optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.learning_rate)\n",
    "    else:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "    return model, train_loader, test_loader, criterion, optimizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T10:36:27.923975100Z",
     "start_time": "2023-10-20T10:36:27.919182400Z"
    }
   },
   "id": "3ccb742896a9db03"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def get_data(slice=1, train=True):\n",
    "    if train:\n",
    "        full_dataset = StaticDataset('../data/processed/train_static.npy')\n",
    "    else:\n",
    "        full_dataset = StaticDataset('../data/processed/test_static.npy')\n",
    "    sub_dataset = torch.utils.data.Subset(full_dataset, range(0, len(full_dataset), slice))\n",
    "    return sub_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T10:36:27.931207Z",
     "start_time": "2023-10-20T10:36:27.923975100Z"
    }
   },
   "id": "7a0d955b1c217921"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def make_loader(dataset, batch_size=64):\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T10:36:27.958251Z",
     "start_time": "2023-10-20T10:36:27.927572600Z"
    }
   },
   "id": "7feb26d9fd1afd97"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.0\n",
      "**********\n",
      "_CUDA version: \n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Tue_Aug_15_22:09:35_Pacific_Daylight_Time_2023\n",
      "Cuda compilation tools, release 12.2, V12.2.140\n",
      "Build cuda_12.2.r12.2/compiler.33191640_0\n",
      "**********\n",
      "CUDNN version: 8801\n",
      "Available GPU devices: 1\n",
      "Device Name: NVIDIA GeForce RTX 2080\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "if torch.cuda.is_available():\n",
    "    print(f'PyTorch version: {torch.__version__}')\n",
    "    print('*' * 10)\n",
    "    print(f'_CUDA version: ')\n",
    "    !nvcc --version\n",
    "    print('*' * 10)\n",
    "    print(f'CUDNN version: {torch.backends.cudnn.version()}')\n",
    "    print(f'Available GPU devices: {torch.cuda.device_count()}')\n",
    "    print(f'Device Name: {torch.cuda.get_device_name()}')\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T10:36:28.691121700Z",
     "start_time": "2023-10-20T10:36:27.935206200Z"
    }
   },
   "id": "aace44d3e59a63c3"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout_prob, num_classes=2):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            if i == 0:\n",
    "                self.linear_relu_stack.append(nn.Linear(input_size, hidden_size))\n",
    "            else:\n",
    "                self.linear_relu_stack.append(nn.Linear(hidden_size, hidden_size))\n",
    "            self.linear_relu_stack.append(nn.ReLU())\n",
    "            self.linear_relu_stack.append(self.dropout)\n",
    "        self.linear_relu_stack.append(nn.Linear(hidden_size, num_classes))\n",
    "        self.linear_relu_stack.append(nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T10:36:28.697134400Z",
     "start_time": "2023-10-20T10:36:28.691121700Z"
    }
   },
   "id": "3a87d27c212fc895"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer, config):\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "\n",
    "    total_batches = len(loader) * config.epochs\n",
    "    example_count = 0\n",
    "    batch_count = 0\n",
    "    for epoch in tqdm(range(config.epochs)):\n",
    "        for _, (matches, labels) in enumerate(loader):\n",
    "            loss = train_batch(matches, labels, model, optimizer, criterion)\n",
    "            example_count += len(matches)\n",
    "            batch_count += 1\n",
    "            if (batch_count + 1) % 25 == 0:\n",
    "                train_log(loss, example_count, epoch)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T10:36:28.703681400Z",
     "start_time": "2023-10-20T10:36:28.697134400Z"
    }
   },
   "id": "8639047e162f0756"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def train_batch(matches, labels, model, optimizer, criterion):\n",
    "    output = model(matches)\n",
    "    loss = criterion(output, labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T10:36:28.704678400Z",
     "start_time": "2023-10-20T10:36:28.702143900Z"
    }
   },
   "id": "8d1908015ffa8f78"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def train_log(loss, example_count, epoch):\n",
    "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_count)\n",
    "    print(f\"Loss after {str(example_count).zfill(5)} examples: {loss:.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T10:36:28.720418300Z",
     "start_time": "2023-10-20T10:36:28.707678800Z"
    }
   },
   "id": "1d4afe9b0efd101a"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    # Run the model on some test examples\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        for matches, labels in test_loader:\n",
    "            matches, labels = matches.to(device), labels.to(device)\n",
    "            outputs = model(matches)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f\"Accuracy of the model on the {total} \" +\n",
    "              f\"test matches: {correct / total:%}\")\n",
    "\n",
    "        wandb.log({\"test_accuracy\": correct / total})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T10:36:28.720418300Z",
     "start_time": "2023-10-20T10:36:28.713211300Z"
    }
   },
   "id": "7e2790071f2ec71e"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.12"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Users\\morit\\Documents\\Informatik\\Projekte\\LeagueOfLegendsWinPrediction\\Training\\wandb\\run-20231020_123628-q8fq2g62</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/moritz-palm/leaguify/runs/q8fq2g62' target=\"_blank\">dulcet-dew-49</a></strong> to <a href='https://wandb.ai/moritz-palm/leaguify' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/moritz-palm/leaguify' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/moritz-palm/leaguify/runs/q8fq2g62' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify/runs/q8fq2g62</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\morit\\anaconda3\\envs\\leaguify\\Lib\\site-packages\\wandb\\sdk\\wandb_config.py\", line 162, in __getattr__\n",
      "    return self.__getitem__(key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\morit\\anaconda3\\envs\\leaguify\\Lib\\site-packages\\wandb\\sdk\\wandb_config.py\", line 130, in __getitem__\n",
      "    return self._items[key]\n",
      "           ~~~~~~~~~~~^^^^^\n",
      "KeyError: 'batch_size'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\morit\\AppData\\Local\\Temp\\ipykernel_43456\\1943455027.py\", line 8, in model_pipeline\n",
      "    model, train_loader, test_loader, criterion, optimizer = make(config)\n",
      "                                                             ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\morit\\AppData\\Local\\Temp\\ipykernel_43456\\4240853044.py\", line 3, in make\n",
      "    train_loader = make_loader(train, batch_size=config.batch_size)\n",
      "                                                 ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\morit\\anaconda3\\envs\\leaguify\\Lib\\site-packages\\wandb\\sdk\\wandb_config.py\", line 164, in __getattr__\n",
      "    raise AttributeError(\n",
      "AttributeError: <class 'wandb.sdk.wandb_config.Config'> object has no attribute 'batch_size'\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "536ed79c4fde4ca4a58f4f4c62beddfa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">dulcet-dew-49</strong> at: <a href='https://wandb.ai/moritz-palm/leaguify/runs/q8fq2g62' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify/runs/q8fq2g62</a><br/> View job at <a href='https://wandb.ai/moritz-palm/leaguify/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwNTk5NjA5Nw==/version_details/v13' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwNTk5NjA5Nw==/version_details/v13</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20231020_123628-q8fq2g62\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "<class 'wandb.sdk.wandb_config.Config'> object has no attribute 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\envs\\leaguify\\Lib\\site-packages\\wandb\\sdk\\wandb_config.py:162\u001B[0m, in \u001B[0;36mConfig.__getattr__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 162\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__getitem__\u001B[39m(key)\n\u001B[0;32m    163\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m ke:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\leaguify\\Lib\\site-packages\\wandb\\sdk\\wandb_config.py:130\u001B[0m, in \u001B[0;36mConfig.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[1;32m--> 130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_items[key]\n",
      "\u001B[1;31mKeyError\u001B[0m: 'batch_size'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m wandb\u001B[38;5;241m.\u001B[39magent(sweep_id, model_pipeline(), count\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m)\n",
      "Cell \u001B[1;32mIn[5], line 8\u001B[0m, in \u001B[0;36mmodel_pipeline\u001B[1;34m(config)\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconfig: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# make the model, data, and optimization problem\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m model, train_loader, test_loader, criterion, optimizer \u001B[38;5;241m=\u001B[39m make(config)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(model)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# and use them to train the model\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[7], line 3\u001B[0m, in \u001B[0;36mmake\u001B[1;34m(config)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmake\u001B[39m(config):\n\u001B[0;32m      2\u001B[0m     train, test \u001B[38;5;241m=\u001B[39m get_data(train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m), get_data(train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m----> 3\u001B[0m     train_loader \u001B[38;5;241m=\u001B[39m make_loader(train, batch_size\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mbatch_size)\n\u001B[0;32m      4\u001B[0m     test_loader \u001B[38;5;241m=\u001B[39m make_loader(test, batch_size\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mbatch_size)\n\u001B[0;32m      6\u001B[0m     model \u001B[38;5;241m=\u001B[39m NeuralNetwork(config\u001B[38;5;241m.\u001B[39minput_size, config\u001B[38;5;241m.\u001B[39mhidden_size, config\u001B[38;5;241m.\u001B[39mnum_layers, config\u001B[38;5;241m.\u001B[39mdropout_prob,\n\u001B[0;32m      7\u001B[0m                           config\u001B[38;5;241m.\u001B[39mclasses)\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\leaguify\\Lib\\site-packages\\wandb\\sdk\\wandb_config.py:164\u001B[0m, in \u001B[0;36mConfig.__getattr__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    162\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__getitem__\u001B[39m(key)\n\u001B[0;32m    163\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m ke:\n\u001B[1;32m--> 164\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[0;32m    165\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    166\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mke\u001B[39;00m\n",
      "\u001B[1;31mAttributeError\u001B[0m: <class 'wandb.sdk.wandb_config.Config'> object has no attribute 'batch_size'"
     ]
    }
   ],
   "source": [
    "model = model_pipeline(config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T10:36:38.281989900Z",
     "start_time": "2023-10-20T10:36:28.717416300Z"
    }
   },
   "id": "63223f3b223d001a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-20T10:36:38.283989800Z"
    }
   },
   "id": "e8aa2dd3954d7316"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
