{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:18:09.373460900Z",
     "start_time": "2023-11-06T09:18:08.484420700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from torch import optim, nn\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"learning_rate\": 0.005,\n",
    "    \"architecture\": \"NN\",\n",
    "    \"dataset\": \"static_1.1\",\n",
    "    \"epochs\": 50,\n",
    "    \"classes\": 2,\n",
    "    \"batch_size\": 64,\n",
    "    \"num_layers\": 4,\n",
    "    \"hidden_size\": 128,\n",
    "    \"dropout_prob\": 0.1,\n",
    "    \"input_size\": 89,\n",
    "    \"output_size\": 1,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"loss\": \"CrossEntropyLoss\",\n",
    "    \"activation\": \"ReLU\",\n",
    "    \"decrease_size\": True,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:18:09.373460900Z",
     "start_time": "2023-11-06T09:18:08.488330100Z"
    }
   },
   "id": "e13812e0d04c772b"
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "def model_pipeline(hyperparameters):\n",
    "    with wandb.init(project=\"leaguify\", config=hyperparameters):\n",
    "        # access all HPs through wandb.config, so logging matches execution!\n",
    "        config = wandb.config\n",
    "        # make the model, data, and optimization problem\n",
    "        model, train_loader, val_loader, test_loader, criterion, optimizer = make(config)\n",
    "        print(model)\n",
    "\n",
    "        # and use them to train the model\n",
    "        train(model, train_loader, val_loader, criterion, optimizer, config)\n",
    "\n",
    "        # and test its final performance\n",
    "        test(model, val_loader)\n",
    "        test(model, test_loader)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:18:09.373460900Z",
     "start_time": "2023-11-06T09:18:08.496459100Z"
    }
   },
   "id": "bbb0d7d96615b112"
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "def get_activation(name):\n",
    "    if name == 'ReLU':\n",
    "        return nn.ReLU()\n",
    "    elif name == 'LeakyReLU':\n",
    "        return nn.LeakyReLU()\n",
    "    elif name == 'ELU':\n",
    "        return nn.ELU()\n",
    "    elif name == 'SELU':\n",
    "        return nn.SELU()\n",
    "    elif name == 'Tanh':\n",
    "        return nn.Tanh()\n",
    "    elif name == 'Sigmoid':\n",
    "        return nn.Sigmoid()\n",
    "    else:\n",
    "        raise ValueError(f'Activation {name} not supported')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:18:09.807124800Z",
     "start_time": "2023-11-06T09:18:08.502717200Z"
    }
   },
   "id": "2c0e42859ee4428f"
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "class StaticDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None, target_transform=None):\n",
    "        self.data = torch.tensor(np.load(data_dir)[:, :-1], dtype=torch.float32, device=device)\n",
    "        self.labels = torch.tensor(np.load(data_dir)[:, -1], dtype=torch.int64, device=device)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.print_statistics()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx, 1:]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return sample, label\n",
    "\n",
    "    def print_statistics(self):\n",
    "        print(f'Number of samples: {len(self.data)}')\n",
    "        print(f'Number of features: {len(self.data[0])}')\n",
    "        print(f'Number of classes: {len(np.unique(self.labels.cpu().numpy()))}')\n",
    "        print(f'Number of samples per class: {np.bincount(self.labels.cpu().numpy())}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:18:09.807124800Z",
     "start_time": "2023-11-06T09:18:08.510236100Z"
    }
   },
   "id": "c843eaf2d2fe8be7"
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "def make(config):\n",
    "    train_data, val_data = get_train_data()\n",
    "    train_loader = make_loader(train_data, batch_size=config.batch_size)\n",
    "    val_loader = make_loader(val_data, batch_size=config.batch_size)\n",
    "    test_loader = make_loader(get_test_data(), batch_size=config.batch_size)\n",
    "    activation = get_activation(config.activation)\n",
    "\n",
    "    model = NeuralNetwork(config.input_size, config.hidden_size, config.num_layers, config.dropout_prob,\n",
    "                          config.classes, activation, config.decrease_size).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if config.optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.learning_rate)\n",
    "    else:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    return model, train_loader, val_loader, test_loader, criterion, optimizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:18:09.807124800Z",
     "start_time": "2023-11-06T09:18:08.515903700Z"
    }
   },
   "id": "3ccb742896a9db03"
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "def get_train_data(val_split=0.8):\n",
    "    dataset = StaticDataset('../data/processed/train_static.npy')\n",
    "    train_len = int(len(dataset) * val_split)\n",
    "    val_len = len(dataset) - train_len\n",
    "    print(f'train_len: {train_len}, val_len: {val_len}')\n",
    "    return torch.utils.data.random_split(dataset, [train_len, val_len])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:18:09.807124800Z",
     "start_time": "2023-11-06T09:18:08.520677300Z"
    }
   },
   "id": "7a0d955b1c217921"
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [
    "def get_test_data():\n",
    "    return StaticDataset('../data/processed/test_static.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:18:09.807124800Z",
     "start_time": "2023-11-06T09:18:08.525703100Z"
    }
   },
   "id": "4ff9a0b79c444569"
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "def make_loader(dataset, batch_size=64):\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:18:09.807124800Z",
     "start_time": "2023-11-06T09:18:08.530144400Z"
    }
   },
   "id": "7feb26d9fd1afd97"
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.0+cu121\n",
      "**********\n",
      "_CUDA version: \n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Tue_Aug_15_22:09:35_Pacific_Daylight_Time_2023\n",
      "Cuda compilation tools, release 12.2, V12.2.140\n",
      "Build cuda_12.2.r12.2/compiler.33191640_0\n",
      "**********\n",
      "CUDNN version: 8801\n",
      "Available GPU devices: 1\n",
      "Device Name: NVIDIA GeForce RTX 2080\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "if torch.cuda.is_available():\n",
    "    print(f'PyTorch version: {torch.__version__}')\n",
    "    print('*' * 10)\n",
    "    print(f'_CUDA version: ')\n",
    "    !nvcc --version\n",
    "    print('*' * 10)\n",
    "    print(f'CUDNN version: {torch.backends.cudnn.version()}')\n",
    "    print(f'Available GPU devices: {torch.cuda.device_count()}')\n",
    "    print(f'Device Name: {torch.cuda.get_device_name()}')\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:18:09.808125100Z",
     "start_time": "2023-11-06T09:18:08.538271700Z"
    }
   },
   "id": "aace44d3e59a63c3"
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout_prob, output_size=1, activation=nn.ReLU(),\n",
    "                 decrease_size=False):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential()\n",
    "        self.linear_relu_stack.append(nn.Linear(input_size, hidden_size))\n",
    "        for i in range(num_layers - 1):\n",
    "            if decrease_size:\n",
    "                next_hidden_size = int(self.hidden_size // 2)\n",
    "            else:\n",
    "                next_hidden_size = self.hidden_size\n",
    "            self.linear_relu_stack.append(self.dropout)\n",
    "            self.linear_relu_stack.append(nn.BatchNorm1d(self.hidden_size))\n",
    "            self.linear_relu_stack.append(nn.Linear(self.hidden_size, next_hidden_size))\n",
    "            self.linear_relu_stack.append(activation)\n",
    "            self.hidden_size = next_hidden_size\n",
    "        self.linear_relu_stack.append(nn.Linear(self.hidden_size, self.output_size))\n",
    "        self.linear_relu_stack.append(nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:18:09.808125100Z",
     "start_time": "2023-11-06T09:18:08.606159Z"
    }
   },
   "id": "3a87d27c212fc895"
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, config):\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "    example_count = 0\n",
    "    batch_count = 0\n",
    "    for epoch in tqdm(range(config.epochs)):\n",
    "        model.train()\n",
    "        for _, (matches, labels) in enumerate(train_loader):\n",
    "            matches, labels = matches.to(device), labels.to(device)\n",
    "            loss = train_batch(matches, labels, model, optimizer, criterion)\n",
    "            example_count += len(matches)\n",
    "            batch_count += 1\n",
    "            if ((batch_count + 1) % 25) == 0:\n",
    "                train_log(loss, example_count, epoch)\n",
    "                test(model, val_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:18:09.808125100Z",
     "start_time": "2023-11-06T09:18:08.611898600Z"
    }
   },
   "id": "8639047e162f0756"
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [],
   "source": [
    "def train_batch(matches, labels, model, optimizer, criterion):\n",
    "    matches, labels = matches.to(device), labels.to(device)\n",
    "\n",
    "    # Forward pass ➡\n",
    "    outputs = model(matches)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Backward pass ⬅\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Step with optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:18:09.808125100Z",
     "start_time": "2023-11-06T09:18:08.618418600Z"
    }
   },
   "id": "b21b9868aaeaebac"
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [
    "def train_log(loss, example_count, epoch):\n",
    "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_count)\n",
    "    print(f\"Loss after {str(example_count).zfill(5)} examples: {loss:.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:18:09.808125100Z",
     "start_time": "2023-11-06T09:18:08.625102600Z"
    }
   },
   "id": "1d4afe9b0efd101a"
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    # Run the model on some test examples\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for matches, labels in test_loader:\n",
    "            matches, labels = matches.to(device), labels.to(device)\n",
    "            outputs = model(matches)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        print(classification_report(y_pred, y_true))\n",
    "\n",
    "        print(f\"Accuracy of the model on the {total} \" +\n",
    "              f\"test matches: {correct / total:%}\")\n",
    "\n",
    "        wandb.log({\"test_accuracy\": correct / total})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:18:09.808125100Z",
     "start_time": "2023-11-06T09:18:08.631889900Z"
    }
   },
   "id": "7e2790071f2ec71e"
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.12"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Users\\morit\\Documents\\Informatik\\Projekte\\LeagueOfLegendsWinPrediction\\Training\\wandb\\run-20231106_101808-bpme26xw</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/moritz-palm/leaguify/runs/bpme26xw' target=\"_blank\">rose-thunder-9459</a></strong> to <a href='https://wandb.ai/moritz-palm/leaguify' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/moritz-palm/leaguify' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/moritz-palm/leaguify/runs/bpme26xw' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify/runs/bpme26xw</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 15960\n",
      "Number of features: 90\n",
      "Number of classes: 2\n",
      "Number of samples per class: [7591 8369]\n",
      "train_len: 12768, val_len: 3192\n",
      "Number of samples: 3990\n",
      "Number of features: 90\n",
      "Number of classes: 2\n",
      "Number of samples per class: [1902 2088]\n",
      "NeuralNetwork(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=89, out_features=128, bias=True)\n",
      "    (1): Dropout(p=0.1, inplace=False)\n",
      "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (8): ReLU()\n",
      "    (9): Dropout(p=0.1, inplace=False)\n",
      "    (10): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (12): ReLU()\n",
      "    (13): Linear(in_features=16, out_features=2, bias=True)\n",
      "    (14): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 01536 examples: 0.643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.64      0.62      1416\n",
      "           1       0.70      0.66      0.68      1776\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.66      0.65      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.476190%\n",
      "Loss after 03136 examples: 0.631\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.64      1570\n",
      "           1       0.65      0.67      0.66      1622\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.974937%\n",
      "Loss after 04736 examples: 0.703\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64      1456\n",
      "           1       0.70      0.67      0.68      1736\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.228070%\n",
      "Loss after 06336 examples: 0.605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.66      0.62      1357\n",
      "           1       0.72      0.66      0.69      1835\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.67      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.071429%\n",
      "Loss after 07936 examples: 0.591\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65      1462\n",
      "           1       0.71      0.69      0.70      1730\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.731830%\n",
      "Loss after 09536 examples: 0.618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65      1453\n",
      "           1       0.71      0.68      0.70      1739\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.324561%\n",
      "Loss after 11136 examples: 0.574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.66      1474\n",
      "           1       0.71      0.69      0.70      1718\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.794486%\n",
      "Loss after 12736 examples: 0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:02<01:54,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65      1537\n",
      "           1       0.68      0.69      0.68      1655\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.635338%\n",
      "Loss after 14304 examples: 0.630\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66      1570\n",
      "           1       0.67      0.70      0.68      1622\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.167920%\n",
      "Loss after 15904 examples: 0.619\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.69      0.63      1247\n",
      "           1       0.77      0.67      0.72      1945\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.67      0.68      0.67      3192\n",
      "weighted avg       0.69      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.700501%\n",
      "Loss after 17504 examples: 0.665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.67      0.64      1388\n",
      "           1       0.72      0.68      0.70      1804\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.68      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.105263%\n",
      "Loss after 19104 examples: 0.559\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65      1462\n",
      "           1       0.71      0.69      0.70      1730\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.67      0.68      0.67      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.606516%\n",
      "Loss after 20704 examples: 0.574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.69      0.62      1241\n",
      "           1       0.77      0.67      0.72      1951\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.67      0.68      0.67      3192\n",
      "weighted avg       0.69      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.575188%\n",
      "Loss after 22304 examples: 0.622\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66      1567\n",
      "           1       0.67      0.69      0.68      1625\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.011278%\n",
      "Loss after 23904 examples: 0.615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.64      0.67      1678\n",
      "           1       0.64      0.71      0.67      1514\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.105263%\n",
      "Loss after 25504 examples: 0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:04<01:47,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.65      0.67      1591\n",
      "           1       0.67      0.70      0.68      1601\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.67      3192\n",
      "weighted avg       0.68      0.68      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.512531%\n",
      "Loss after 27072 examples: 0.594\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.67      0.64      1371\n",
      "           1       0.73      0.68      0.70      1821\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.67      0.68      0.67      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.575188%\n",
      "Loss after 28672 examples: 0.625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65      1452\n",
      "           1       0.71      0.69      0.70      1740\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.68      0.67      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.481203%\n",
      "Loss after 30272 examples: 0.640\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.68      0.62      1264\n",
      "           1       0.76      0.66      0.71      1928\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.66      0.67      0.66      3192\n",
      "weighted avg       0.68      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.917293%\n",
      "Loss after 31872 examples: 0.611\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.67      0.63      1340\n",
      "           1       0.74      0.67      0.70      1852\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.68      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.230576%\n",
      "Loss after 33472 examples: 0.667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.65      1420\n",
      "           1       0.72      0.68      0.70      1772\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.68      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.418546%\n",
      "Loss after 35072 examples: 0.603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.64      0.66      1600\n",
      "           1       0.66      0.69      0.68      1592\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.729323%\n",
      "Loss after 36672 examples: 0.583\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.68      0.64      1358\n",
      "           1       0.74      0.68      0.71      1834\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.67      0.68      0.67      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.731830%\n",
      "Loss after 38272 examples: 0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:06<01:45,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.70      0.63      1233\n",
      "           1       0.78      0.67      0.72      1959\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.67      3192\n",
      "weighted avg       0.70      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 68.076441%\n",
      "Loss after 39840 examples: 0.585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.66      1537\n",
      "           1       0.68      0.69      0.69      1655\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.199248%\n",
      "Loss after 41440 examples: 0.619\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.65      0.67      1631\n",
      "           1       0.66      0.71      0.68      1561\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.575188%\n",
      "Loss after 43040 examples: 0.557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.71      0.63      1225\n",
      "           1       0.79      0.67      0.72      1967\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.69      0.68      3192\n",
      "weighted avg       0.70      0.68      0.69      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 68.452381%\n",
      "Loss after 44640 examples: 0.530\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67      1599\n",
      "           1       0.67      0.70      0.68      1593\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.575188%\n",
      "Loss after 46240 examples: 0.556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.67      0.65      1450\n",
      "           1       0.71      0.69      0.70      1742\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.794486%\n",
      "Loss after 47840 examples: 0.589\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.61      0.68      1879\n",
      "           1       0.57      0.73      0.64      1313\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.67      0.67      0.66      3192\n",
      "weighted avg       0.68      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.134085%\n",
      "Loss after 49440 examples: 0.613\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.66      1537\n",
      "           1       0.68      0.69      0.69      1655\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.449875%\n",
      "Loss after 51040 examples: 0.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:09<01:43,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.72      0.62      1146\n",
      "           1       0.81      0.66      0.73      2046\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.69      0.67      3192\n",
      "weighted avg       0.71      0.68      0.69      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 68.295739%\n",
      "Loss after 52608 examples: 0.599\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.69      0.62      1233\n",
      "           1       0.77      0.66      0.72      1959\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.67      0.68      0.67      3192\n",
      "weighted avg       0.69      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.512531%\n",
      "Loss after 54208 examples: 0.545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.65      0.68      1633\n",
      "           1       0.66      0.71      0.69      1559\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 68.139098%\n",
      "Loss after 55808 examples: 0.610\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.62      0.68      1829\n",
      "           1       0.59      0.72      0.65      1363\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.66      3192\n",
      "weighted avg       0.68      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.510025%\n",
      "Loss after 57408 examples: 0.709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.65      0.68      1689\n",
      "           1       0.64      0.72      0.68      1503\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.69      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 68.076441%\n",
      "Loss after 59008 examples: 0.591\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.65      0.66      1578\n",
      "           1       0.67      0.70      0.68      1614\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.355890%\n",
      "Loss after 60608 examples: 0.647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.69      0.63      1252\n",
      "           1       0.77      0.67      0.72      1940\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.67      0.68      0.67      3192\n",
      "weighted avg       0.70      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.982456%\n",
      "Loss after 62208 examples: 0.639\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.68      0.65      1386\n",
      "           1       0.73      0.68      0.71      1806\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.69      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 68.170426%\n",
      "Loss after 63808 examples: 0.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:11<01:39,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.67      0.63      1356\n",
      "           1       0.73      0.67      0.70      1836\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.68      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.167920%\n",
      "Loss after 65376 examples: 0.569\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.67      0.64      1372\n",
      "           1       0.73      0.68      0.70      1820\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.68      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.355890%\n",
      "Loss after 66976 examples: 0.611\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.67      0.66      1491\n",
      "           1       0.70      0.70      0.70      1701\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 68.201754%\n",
      "Loss after 68576 examples: 0.635\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.67      0.66      1466\n",
      "           1       0.71      0.70      0.70      1726\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.69      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 68.421053%\n",
      "Loss after 70176 examples: 0.580\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.65      0.66      1558\n",
      "           1       0.68      0.70      0.69      1634\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.794486%\n",
      "Loss after 71776 examples: 0.646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66      1506\n",
      "           1       0.70      0.70      0.70      1686\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.982456%\n",
      "Loss after 73376 examples: 0.534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.67      0.66      1488\n",
      "           1       0.70      0.70      0.70      1704\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 68.170426%\n",
      "Loss after 74976 examples: 0.649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.65      1414\n",
      "           1       0.73      0.69      0.71      1778\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 68.107769%\n",
      "Loss after 76576 examples: 0.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:13<01:37,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66      1507\n",
      "           1       0.69      0.69      0.69      1685\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.575188%\n",
      "Loss after 78144 examples: 0.514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1542\n",
      "           1       0.69      0.70      0.69      1650\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.919799%\n",
      "Loss after 79744 examples: 0.559\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.66      0.64      1418\n",
      "           1       0.72      0.68      0.70      1774\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.68      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.293233%\n",
      "Loss after 81344 examples: 0.615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.65      0.67      1642\n",
      "           1       0.65      0.71      0.68      1550\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.731830%\n",
      "Loss after 82944 examples: 0.541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.64      0.68      1696\n",
      "           1       0.64      0.72      0.67      1496\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.68      0.68      0.67      3192\n",
      "weighted avg       0.68      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.481203%\n",
      "Loss after 84544 examples: 0.615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.65      0.68      1677\n",
      "           1       0.65      0.72      0.68      1515\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 68.076441%\n",
      "Loss after 86144 examples: 0.531\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.66      0.67      1585\n",
      "           1       0.68      0.71      0.69      1607\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 68.389724%\n",
      "Loss after 87744 examples: 0.571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.67      0.66      1454\n",
      "           1       0.72      0.70      0.71      1738\n",
      "\n",
      "    accuracy                           0.69      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.69      0.69      0.69      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 68.546366%\n",
      "Loss after 89344 examples: 0.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:15<01:36,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67      1554\n",
      "           1       0.68      0.70      0.69      1638\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 68.107769%\n",
      "Loss after 90912 examples: 0.623\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.65      0.67      1625\n",
      "           1       0.66      0.71      0.68      1567\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.700501%\n",
      "Loss after 92512 examples: 0.582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.68      0.64      1321\n",
      "           1       0.75      0.68      0.71      1871\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.69      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.951128%\n",
      "Loss after 94112 examples: 0.530\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.64      0.68      1671\n",
      "           1       0.65      0.72      0.68      1521\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.825815%\n",
      "Loss after 95712 examples: 0.622\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.65      0.68      1640\n",
      "           1       0.66      0.71      0.68      1552\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 68.045113%\n",
      "Loss after 97312 examples: 0.605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.63      0.68      1805\n",
      "           1       0.60      0.73      0.66      1387\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.68      0.67      3192\n",
      "weighted avg       0.68      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.073935%\n",
      "Loss after 98912 examples: 0.532\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.68      0.66      1436\n",
      "           1       0.72      0.69      0.71      1756\n",
      "\n",
      "    accuracy                           0.69      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.69      0.69      0.69      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 68.546366%\n",
      "Loss after 100512 examples: 0.598\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.65      0.68      1673\n",
      "           1       0.65      0.72      0.68      1519\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.951128%\n",
      "Loss after 102112 examples: 0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [00:17<01:33,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.67      1541\n",
      "           1       0.69      0.70      0.69      1651\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 68.013784%\n",
      "Loss after 103680 examples: 0.601\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66      1531\n",
      "           1       0.69      0.69      0.69      1661\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.67      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.575188%\n",
      "Loss after 105280 examples: 0.584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.66      1628\n",
      "           1       0.65      0.70      0.67      1564\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.917293%\n",
      "Loss after 106880 examples: 0.590\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.65      1482\n",
      "           1       0.70      0.69      0.69      1710\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.293233%\n",
      "Loss after 108480 examples: 0.631\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.61      0.67      1803\n",
      "           1       0.58      0.71      0.64      1389\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.66      0.66      0.65      3192\n",
      "weighted avg       0.67      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.319549%\n",
      "Loss after 110080 examples: 0.599\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65      1470\n",
      "           1       0.70      0.69      0.69      1722\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.293233%\n",
      "Loss after 111680 examples: 0.639\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.65      0.67      1630\n",
      "           1       0.66      0.71      0.68      1562\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.982456%\n",
      "Loss after 113280 examples: 0.613\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.67      0.66      1502\n",
      "           1       0.70      0.70      0.70      1690\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 68.233083%\n",
      "Loss after 114880 examples: 0.560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [00:20<01:30,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66      1511\n",
      "           1       0.69      0.69      0.69      1681\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.637845%\n",
      "Loss after 116448 examples: 0.568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67      1594\n",
      "           1       0.67      0.71      0.69      1598\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 68.170426%\n",
      "Loss after 118048 examples: 0.640\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.67      0.66      1482\n",
      "           1       0.71      0.70      0.70      1710\n",
      "\n",
      "    accuracy                           0.69      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.69      0.69      0.69      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 68.546366%\n",
      "Loss after 119648 examples: 0.619\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.67      1631\n",
      "           1       0.65      0.70      0.68      1561\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.324561%\n",
      "Loss after 121248 examples: 0.509\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.64      0.68      1693\n",
      "           1       0.64      0.72      0.67      1499\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.512531%\n",
      "Loss after 122848 examples: 0.661\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67      1613\n",
      "           1       0.66      0.70      0.68      1579\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.68      0.67      0.67      3192\n",
      "weighted avg       0.68      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.449875%\n",
      "Loss after 124448 examples: 0.537\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67      1662\n",
      "           1       0.64      0.71      0.67      1530\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.68      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.230576%\n",
      "Loss after 126048 examples: 0.537\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.66      1488\n",
      "           1       0.70      0.69      0.69      1704\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.67      0.68      0.67      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.606516%\n",
      "Loss after 127648 examples: 0.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:22<01:27,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.68      0.64      1355\n",
      "           1       0.74      0.68      0.71      1837\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.67      0.68      0.67      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.575188%\n",
      "Loss after 129216 examples: 0.579\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.65      0.67      1632\n",
      "           1       0.66      0.71      0.68      1560\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.794486%\n",
      "Loss after 130816 examples: 0.631\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.66      1532\n",
      "           1       0.68      0.69      0.69      1660\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.418546%\n",
      "Loss after 132416 examples: 0.624\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66      1558\n",
      "           1       0.68      0.70      0.69      1634\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.418546%\n",
      "Loss after 134016 examples: 0.496\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67      1551\n",
      "           1       0.68      0.70      0.69      1641\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 68.076441%\n",
      "Loss after 135616 examples: 0.631\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.65      0.67      1577\n",
      "           1       0.67      0.70      0.69      1615\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.637845%\n",
      "Loss after 137216 examples: 0.565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.65      1544\n",
      "           1       0.68      0.69      0.68      1648\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.979950%\n",
      "Loss after 138816 examples: 0.559\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.67      0.63      1326\n",
      "           1       0.74      0.67      0.70      1866\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.66      0.67      0.66      3192\n",
      "weighted avg       0.68      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.791980%\n",
      "Loss after 140416 examples: 0.571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:24<01:25,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.65      1430\n",
      "           1       0.72      0.68      0.70      1762\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.543860%\n",
      "Loss after 141984 examples: 0.565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.69      0.64      1323\n",
      "           1       0.76      0.68      0.72      1869\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.69      0.68      3192\n",
      "weighted avg       0.69      0.68      0.69      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 68.452381%\n",
      "Loss after 143584 examples: 0.557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.65      0.67      1626\n",
      "           1       0.66      0.71      0.68      1566\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.543860%\n",
      "Loss after 145184 examples: 0.598\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.67      0.66      1494\n",
      "           1       0.70      0.70      0.70      1698\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 68.358396%\n",
      "Loss after 146784 examples: 0.584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66      1549\n",
      "           1       0.68      0.69      0.69      1643\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.324561%\n",
      "Loss after 148384 examples: 0.518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.65      1431\n",
      "           1       0.72      0.68      0.70      1761\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.67      0.68      0.67      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.637845%\n",
      "Loss after 149984 examples: 0.593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65      1463\n",
      "           1       0.71      0.69      0.70      1729\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.575188%\n",
      "Loss after 151584 examples: 0.632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.63      0.67      1724\n",
      "           1       0.62      0.71      0.67      1468\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.68      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.979950%\n",
      "Loss after 153184 examples: 0.580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:26<01:23,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66      1496\n",
      "           1       0.70      0.69      0.70      1696\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.982456%\n",
      "Loss after 154752 examples: 0.575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67      1567\n",
      "           1       0.68      0.71      0.69      1625\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 68.264411%\n",
      "Loss after 156352 examples: 0.603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.66      0.64      1440\n",
      "           1       0.71      0.68      0.69      1752\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.042607%\n",
      "Loss after 157952 examples: 0.542\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66      1513\n",
      "           1       0.69      0.69      0.69      1679\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.449875%\n",
      "Loss after 159552 examples: 0.598\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.65      1533\n",
      "           1       0.68      0.69      0.68      1659\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.948622%\n",
      "Loss after 161152 examples: 0.571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.65      0.66      1573\n",
      "           1       0.67      0.70      0.68      1619\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.387218%\n",
      "Loss after 162752 examples: 0.581\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67      1601\n",
      "           1       0.66      0.70      0.68      1591\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.387218%\n",
      "Loss after 164352 examples: 0.604\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.63      0.68      1773\n",
      "           1       0.61      0.72      0.66      1419\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.68      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.885965%\n",
      "Loss after 165952 examples: 0.542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:28<01:21,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.63      0.67      1724\n",
      "           1       0.62      0.71      0.66      1468\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.729323%\n",
      "Loss after 167520 examples: 0.566\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.66      1621\n",
      "           1       0.65      0.70      0.68      1571\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.948622%\n",
      "Loss after 169120 examples: 0.500\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.63      0.67      1730\n",
      "           1       0.62      0.71      0.66      1462\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.541353%\n",
      "Loss after 170720 examples: 0.590\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.66      1533\n",
      "           1       0.68      0.69      0.69      1659\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.136591%\n",
      "Loss after 172320 examples: 0.532\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.65      0.66      1586\n",
      "           1       0.67      0.70      0.68      1606\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.167920%\n",
      "Loss after 173920 examples: 0.583\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66      1514\n",
      "           1       0.69      0.69      0.69      1678\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.418546%\n",
      "Loss after 175520 examples: 0.530\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.66      1552\n",
      "           1       0.67      0.69      0.68      1640\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.917293%\n",
      "Loss after 177120 examples: 0.567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65      1511\n",
      "           1       0.68      0.68      0.68      1681\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.760652%\n",
      "Loss after 178720 examples: 0.536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [00:31<01:19,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.66      1643\n",
      "           1       0.65      0.70      0.67      1549\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.823308%\n",
      "Loss after 180288 examples: 0.523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.66      0.63      1371\n",
      "           1       0.73      0.67      0.70      1821\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.66      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.823308%\n",
      "Loss after 181888 examples: 0.535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67      1689\n",
      "           1       0.63      0.71      0.67      1503\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.885965%\n",
      "Loss after 183488 examples: 0.597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.64      0.66      1580\n",
      "           1       0.67      0.69      0.68      1612\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.979950%\n",
      "Loss after 185088 examples: 0.559\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66      1518\n",
      "           1       0.69      0.69      0.69      1674\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.731830%\n",
      "Loss after 186688 examples: 0.526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.63      0.68      1750\n",
      "           1       0.61      0.72      0.66      1442\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.68      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.854637%\n",
      "Loss after 188288 examples: 0.593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.66      0.65      1433\n",
      "           1       0.71      0.68      0.70      1759\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.68      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.387218%\n",
      "Loss after 189888 examples: 0.650\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.64      0.67      1666\n",
      "           1       0.64      0.71      0.67      1526\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.68      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.230576%\n",
      "Loss after 191488 examples: 0.570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:33<01:17,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.66      1767\n",
      "           1       0.60      0.70      0.64      1425\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.66      0.66      0.65      3192\n",
      "weighted avg       0.66      0.65      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.444862%\n",
      "Loss after 193056 examples: 0.603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.63      0.67      1677\n",
      "           1       0.63      0.70      0.67      1515\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.697995%\n",
      "Loss after 194656 examples: 0.552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.66      1498\n",
      "           1       0.70      0.69      0.69      1694\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.669173%\n",
      "Loss after 196256 examples: 0.523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66      1558\n",
      "           1       0.68      0.70      0.69      1634\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.355890%\n",
      "Loss after 197856 examples: 0.515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65      1558\n",
      "           1       0.67      0.69      0.68      1634\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.478697%\n",
      "Loss after 199456 examples: 0.510\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.64      0.66      1576\n",
      "           1       0.67      0.69      0.68      1616\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.917293%\n",
      "Loss after 201056 examples: 0.520\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67      1662\n",
      "           1       0.64      0.70      0.67      1530\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.917293%\n",
      "Loss after 202656 examples: 0.502\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65      1457\n",
      "           1       0.71      0.69      0.70      1735\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.67      0.68      0.67      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.637845%\n",
      "Loss after 204256 examples: 0.481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [00:35<01:14,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67      1650\n",
      "           1       0.65      0.71      0.67      1542\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.167920%\n",
      "Loss after 205824 examples: 0.535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.65      0.67      1593\n",
      "           1       0.67      0.70      0.68      1599\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.575188%\n",
      "Loss after 207424 examples: 0.593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67      1664\n",
      "           1       0.64      0.71      0.67      1528\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.042607%\n",
      "Loss after 209024 examples: 0.557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.65      1426\n",
      "           1       0.72      0.69      0.70      1766\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.857143%\n",
      "Loss after 210624 examples: 0.547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.65      1408\n",
      "           1       0.73      0.68      0.70      1784\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.857143%\n",
      "Loss after 212224 examples: 0.551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.63      0.66      1664\n",
      "           1       0.63      0.70      0.67      1528\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.67      0.66      0.66      3192\n",
      "weighted avg       0.67      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.353383%\n",
      "Loss after 213824 examples: 0.521\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.63      0.66      1685\n",
      "           1       0.63      0.70      0.66      1507\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.67      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.196742%\n",
      "Loss after 215424 examples: 0.565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66      1540\n",
      "           1       0.68      0.70      0.69      1652\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.606516%\n",
      "Loss after 217024 examples: 0.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [00:37<01:12,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67      1708\n",
      "           1       0.63      0.71      0.66      1484\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.729323%\n",
      "Loss after 218592 examples: 0.596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.63      0.67      1741\n",
      "           1       0.62      0.71      0.66      1451\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.68      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.760652%\n",
      "Loss after 220192 examples: 0.561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.63      0.67      1678\n",
      "           1       0.63      0.70      0.67      1514\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.666667%\n",
      "Loss after 221792 examples: 0.641\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.66      1531\n",
      "           1       0.68      0.69      0.69      1661\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.387218%\n",
      "Loss after 223392 examples: 0.576\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.64      0.66      1597\n",
      "           1       0.66      0.70      0.68      1595\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.011278%\n",
      "Loss after 224992 examples: 0.536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.66      1486\n",
      "           1       0.70      0.69      0.70      1706\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.669173%\n",
      "Loss after 226592 examples: 0.549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.62      0.67      1770\n",
      "           1       0.60      0.71      0.65      1422\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.67      0.67      0.66      3192\n",
      "weighted avg       0.67      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.228070%\n",
      "Loss after 228192 examples: 0.603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.67      1750\n",
      "           1       0.61      0.71      0.65      1442\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.67      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.040100%\n",
      "Loss after 229792 examples: 0.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [00:39<01:09,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.66      1547\n",
      "           1       0.68      0.69      0.68      1645\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.011278%\n",
      "Loss after 231360 examples: 0.596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67      1604\n",
      "           1       0.66      0.70      0.68      1588\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.355890%\n",
      "Loss after 232960 examples: 0.534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.65      1518\n",
      "           1       0.69      0.69      0.69      1674\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.167920%\n",
      "Loss after 234560 examples: 0.522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.66      0.65      1448\n",
      "           1       0.71      0.68      0.69      1744\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.230576%\n",
      "Loss after 236160 examples: 0.523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65      1496\n",
      "           1       0.69      0.69      0.69      1696\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.042607%\n",
      "Loss after 237760 examples: 0.582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65      1502\n",
      "           1       0.69      0.69      0.69      1690\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.167920%\n",
      "Loss after 239360 examples: 0.585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66      1548\n",
      "           1       0.68      0.70      0.69      1644\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.669173%\n",
      "Loss after 240960 examples: 0.553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.64      0.68      1706\n",
      "           1       0.63      0.72      0.67      1486\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.68      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.543860%\n",
      "Loss after 242560 examples: 0.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [00:41<01:08,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.65      1481\n",
      "           1       0.70      0.69      0.69      1711\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.449875%\n",
      "Loss after 244128 examples: 0.582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.65      0.65      1478\n",
      "           1       0.70      0.68      0.69      1714\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.917293%\n",
      "Loss after 245728 examples: 0.577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.66      0.64      1422\n",
      "           1       0.72      0.68      0.70      1770\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.68      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.293233%\n",
      "Loss after 247328 examples: 0.606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.63      0.66      1632\n",
      "           1       0.64      0.69      0.67      1560\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.67      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.353383%\n",
      "Loss after 248928 examples: 0.627\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.63      0.66      1640\n",
      "           1       0.64      0.70      0.67      1552\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.67      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.353383%\n",
      "Loss after 250528 examples: 0.523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.64      0.65      1569\n",
      "           1       0.67      0.69      0.68      1623\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.697995%\n",
      "Loss after 252128 examples: 0.553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.63      0.66      1702\n",
      "           1       0.62      0.70      0.66      1490\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.67      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.040100%\n",
      "Loss after 253728 examples: 0.502\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.66      1550\n",
      "           1       0.67      0.69      0.68      1642\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.979950%\n",
      "Loss after 255328 examples: 0.567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:44<01:06,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.63      0.66      1662\n",
      "           1       0.63      0.70      0.66      1530\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.67      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.228070%\n",
      "Loss after 256896 examples: 0.668\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.67      0.65      1439\n",
      "           1       0.71      0.69      0.70      1753\n",
      "\n",
      "    accuracy                           0.68      3192\n",
      "   macro avg       0.67      0.68      0.68      3192\n",
      "weighted avg       0.68      0.68      0.68      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 67.700501%\n",
      "Loss after 258496 examples: 0.552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.64      0.66      1595\n",
      "           1       0.66      0.69      0.67      1597\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.66      3192\n",
      "weighted avg       0.67      0.67      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.510025%\n",
      "Loss after 260096 examples: 0.539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.64      0.66      1571\n",
      "           1       0.67      0.69      0.68      1621\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.823308%\n",
      "Loss after 261696 examples: 0.582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.62      0.66      1710\n",
      "           1       0.61      0.70      0.65      1482\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.66      0.66      0.65      3192\n",
      "weighted avg       0.66      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.476190%\n",
      "Loss after 263296 examples: 0.517\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64      1454\n",
      "           1       0.70      0.68      0.69      1738\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.66      0.67      0.66      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.666667%\n",
      "Loss after 264896 examples: 0.562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.67      1751\n",
      "           1       0.60      0.71      0.65      1441\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.67      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.820802%\n",
      "Loss after 266496 examples: 0.531\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65      1519\n",
      "           1       0.68      0.68      0.68      1673\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.572682%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:46<01:04,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 268096 examples: 0.581\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.63      0.66      1689\n",
      "           1       0.62      0.70      0.66      1503\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.008772%\n",
      "Loss after 269664 examples: 0.536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.66      1629\n",
      "           1       0.65      0.70      0.67      1563\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.510025%\n",
      "Loss after 271264 examples: 0.580\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.64      0.66      1607\n",
      "           1       0.65      0.69      0.67      1585\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.572682%\n",
      "Loss after 272864 examples: 0.546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64      1517\n",
      "           1       0.68      0.68      0.68      1675\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.322055%\n",
      "Loss after 274464 examples: 0.560\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65      1567\n",
      "           1       0.66      0.69      0.68      1625\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.384712%\n",
      "Loss after 276064 examples: 0.600\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.63      0.66      1646\n",
      "           1       0.64      0.70      0.67      1546\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.604010%\n",
      "Loss after 277664 examples: 0.573\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.62      0.66      1701\n",
      "           1       0.62      0.70      0.66      1491\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.758145%\n",
      "Loss after 279264 examples: 0.558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65      1520\n",
      "           1       0.68      0.69      0.69      1672\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.979950%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [00:48<01:02,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 280864 examples: 0.609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.63      0.66      1620\n",
      "           1       0.65      0.69      0.67      1572\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.353383%\n",
      "Loss after 282432 examples: 0.540\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.67      0.63      1359\n",
      "           1       0.73      0.67      0.70      1833\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.66      0.67      0.66      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.760652%\n",
      "Loss after 284032 examples: 0.489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.68      0.61      1237\n",
      "           1       0.77      0.66      0.71      1955\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.66      0.67      0.66      3192\n",
      "weighted avg       0.69      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.760652%\n",
      "Loss after 285632 examples: 0.595\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65      1508\n",
      "           1       0.69      0.68      0.69      1684\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.791980%\n",
      "Loss after 287232 examples: 0.485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64      1534\n",
      "           1       0.67      0.68      0.67      1658\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.852130%\n",
      "Loss after 288832 examples: 0.515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.67      1750\n",
      "           1       0.61      0.71      0.65      1442\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.67      0.66      3192\n",
      "weighted avg       0.67      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.102757%\n",
      "Loss after 290432 examples: 0.525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64      1511\n",
      "           1       0.68      0.68      0.68      1681\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.259398%\n",
      "Loss after 292032 examples: 0.591\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.63      0.66      1668\n",
      "           1       0.63      0.70      0.67      1524\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.67      0.67      0.66      3192\n",
      "weighted avg       0.67      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.416040%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [00:50<01:00,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 293632 examples: 0.603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.64      0.66      1603\n",
      "           1       0.65      0.69      0.67      1589\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.66      3192\n",
      "weighted avg       0.67      0.67      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.510025%\n",
      "Loss after 295200 examples: 0.579\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.64      0.66      1610\n",
      "           1       0.65      0.69      0.67      1582\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.416040%\n",
      "Loss after 296800 examples: 0.588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.63      0.65      1612\n",
      "           1       0.65      0.69      0.67      1580\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.102757%\n",
      "Loss after 298400 examples: 0.575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64      1522\n",
      "           1       0.68      0.68      0.68      1670\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.228070%\n",
      "Loss after 300000 examples: 0.550\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.66      0.63      1373\n",
      "           1       0.73      0.67      0.70      1819\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.66      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.823308%\n",
      "Loss after 301600 examples: 0.460\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.65      0.64      1488\n",
      "           1       0.69      0.68      0.68      1704\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.416040%\n",
      "Loss after 303200 examples: 0.565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64      1506\n",
      "           1       0.67      0.67      0.67      1686\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.601504%\n",
      "Loss after 304800 examples: 0.567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64      1458\n",
      "           1       0.70      0.67      0.68      1734\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.228070%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [00:53<00:59,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 306400 examples: 0.604\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65      1463\n",
      "           1       0.70      0.68      0.69      1729\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.948622%\n",
      "Loss after 307968 examples: 0.557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.65      1528\n",
      "           1       0.68      0.68      0.68      1664\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.416040%\n",
      "Loss after 309568 examples: 0.577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.63      0.66      1622\n",
      "           1       0.65      0.69      0.67      1570\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.228070%\n",
      "Loss after 311168 examples: 0.600\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.65      0.65      1506\n",
      "           1       0.68      0.68      0.68      1686\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.478697%\n",
      "Loss after 312768 examples: 0.609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.63      0.65      1657\n",
      "           1       0.63      0.69      0.66      1535\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.695489%\n",
      "Loss after 314368 examples: 0.547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.63      0.66      1668\n",
      "           1       0.63      0.69      0.66      1524\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.852130%\n",
      "Loss after 315968 examples: 0.641\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.65      1522\n",
      "           1       0.68      0.68      0.68      1670\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.290727%\n",
      "Loss after 317568 examples: 0.580\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.62      0.66      1677\n",
      "           1       0.63      0.69      0.66      1515\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.758145%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:55<00:57,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 319168 examples: 0.624\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.63      0.65      1617\n",
      "           1       0.65      0.69      0.67      1575\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.946115%\n",
      "Loss after 320736 examples: 0.593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.66      0.63      1381\n",
      "           1       0.72      0.67      0.69      1811\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.67      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.259398%\n",
      "Loss after 322336 examples: 0.536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.65      1544\n",
      "           1       0.67      0.68      0.67      1648\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.040100%\n",
      "Loss after 323936 examples: 0.507\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.61      0.65      1725\n",
      "           1       0.60      0.68      0.64      1467\n",
      "\n",
      "    accuracy                           0.64      3192\n",
      "   macro avg       0.65      0.65      0.64      3192\n",
      "weighted avg       0.65      0.64      0.64      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.254386%\n",
      "Loss after 325536 examples: 0.473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64      1547\n",
      "           1       0.66      0.68      0.67      1645\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.66      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.507519%\n",
      "Loss after 327136 examples: 0.548\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.64      1591\n",
      "           1       0.65      0.68      0.66      1601\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.382206%\n",
      "Loss after 328736 examples: 0.582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.62      0.66      1678\n",
      "           1       0.63      0.69      0.66      1514\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.789474%\n",
      "Loss after 330336 examples: 0.512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.64      1594\n",
      "           1       0.65      0.68      0.66      1598\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.413534%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [00:57<00:54,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 331936 examples: 0.522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.66      0.62      1317\n",
      "           1       0.73      0.66      0.69      1875\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.67      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.008772%\n",
      "Loss after 333504 examples: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.63      1484\n",
      "           1       0.68      0.67      0.68      1708\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.601504%\n",
      "Loss after 335104 examples: 0.563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65      1646\n",
      "           1       0.63      0.69      0.66      1546\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.66      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.350877%\n",
      "Loss after 336704 examples: 0.505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.65      1591\n",
      "           1       0.65      0.68      0.67      1601\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.695489%\n",
      "Loss after 338304 examples: 0.577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.63      0.65      1632\n",
      "           1       0.64      0.69      0.66      1560\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.538847%\n",
      "Loss after 339904 examples: 0.558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65      1594\n",
      "           1       0.65      0.69      0.67      1598\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.102757%\n",
      "Loss after 341504 examples: 0.521\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65      1676\n",
      "           1       0.62      0.68      0.65      1516\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.849624%\n",
      "Loss after 343104 examples: 0.558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.63      1536\n",
      "           1       0.66      0.67      0.67      1656\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.100251%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [01:00<00:52,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 344704 examples: 0.555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.65      0.63      1444\n",
      "           1       0.70      0.67      0.68      1748\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.102757%\n",
      "Loss after 346272 examples: 0.632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64      1466\n",
      "           1       0.69      0.67      0.68      1726\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.040100%\n",
      "Loss after 347872 examples: 0.509\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.62      0.65      1689\n",
      "           1       0.61      0.69      0.65      1503\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.880952%\n",
      "Loss after 349472 examples: 0.601\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.64      1624\n",
      "           1       0.63      0.68      0.65      1568\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.849624%\n",
      "Loss after 351072 examples: 0.553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64      1508\n",
      "           1       0.68      0.67      0.67      1684\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.726817%\n",
      "Loss after 352672 examples: 0.511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.61      0.66      1755\n",
      "           1       0.60      0.70      0.64      1437\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.66      0.66      0.65      3192\n",
      "weighted avg       0.66      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.256892%\n",
      "Loss after 354272 examples: 0.539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.61      0.66      1750\n",
      "           1       0.60      0.70      0.64      1442\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.66      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.037594%\n",
      "Loss after 355872 examples: 0.578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.64      0.62      1414\n",
      "           1       0.70      0.66      0.68      1778\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.66      0.65      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.476190%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [01:02<00:49,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 357472 examples: 0.486\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.65      1645\n",
      "           1       0.63      0.68      0.65      1547\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.943609%\n",
      "Loss after 359040 examples: 0.621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.64      1496\n",
      "           1       0.68      0.67      0.68      1696\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.852130%\n",
      "Loss after 360640 examples: 0.544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.63      1542\n",
      "           1       0.66      0.67      0.66      1650\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.974937%\n",
      "Loss after 362240 examples: 0.562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65      1636\n",
      "           1       0.63      0.69      0.66      1556\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.66      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.350877%\n",
      "Loss after 363840 examples: 0.604\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64      1561\n",
      "           1       0.66      0.68      0.67      1631\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.256892%\n",
      "Loss after 365440 examples: 0.535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64      1547\n",
      "           1       0.67      0.68      0.67      1645\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.883459%\n",
      "Loss after 367040 examples: 0.515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63      1456\n",
      "           1       0.69      0.67      0.68      1736\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.66      0.65      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.476190%\n",
      "Loss after 368640 examples: 0.515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64      1489\n",
      "           1       0.69      0.68      0.68      1703\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.196742%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [01:04<00:47,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 370240 examples: 0.453\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.63      0.66      1648\n",
      "           1       0.64      0.69      0.66      1544\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.914787%\n",
      "Loss after 371808 examples: 0.527\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65      1546\n",
      "           1       0.67      0.68      0.68      1646\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.353383%\n",
      "Loss after 373408 examples: 0.594\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64      1513\n",
      "           1       0.68      0.68      0.68      1679\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.071429%\n",
      "Loss after 375008 examples: 0.469\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.62      0.65      1677\n",
      "           1       0.62      0.69      0.65      1515\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.068922%\n",
      "Loss after 376608 examples: 0.529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.65      1580\n",
      "           1       0.66      0.68      0.67      1612\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.852130%\n",
      "Loss after 378208 examples: 0.501\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.64      0.65      1587\n",
      "           1       0.66      0.69      0.67      1605\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.134085%\n",
      "Loss after 379808 examples: 0.560\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64      1515\n",
      "           1       0.68      0.68      0.68      1677\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.071429%\n",
      "Loss after 381408 examples: 0.512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64      1563\n",
      "           1       0.66      0.68      0.67      1629\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.632832%\n",
      "Loss after 383008 examples: 0.560\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.62      0.65      1703\n",
      "           1       0.61      0.69      0.65      1489\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.66      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.131579%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [01:07<00:46,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 384576 examples: 0.589\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.64      1500\n",
      "           1       0.68      0.67      0.68      1692\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.726817%\n",
      "Loss after 386176 examples: 0.562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.64      1576\n",
      "           1       0.65      0.68      0.67      1616\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.538847%\n",
      "Loss after 387776 examples: 0.503\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.65      0.65      1474\n",
      "           1       0.70      0.68      0.69      1718\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.917293%\n",
      "Loss after 389376 examples: 0.496\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64      1504\n",
      "           1       0.68      0.68      0.68      1688\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.102757%\n",
      "Loss after 390976 examples: 0.566\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65      1604\n",
      "           1       0.65      0.69      0.67      1588\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.102757%\n",
      "Loss after 392576 examples: 0.543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65      1522\n",
      "           1       0.68      0.69      0.68      1670\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.666667%\n",
      "Loss after 394176 examples: 0.501\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65      1617\n",
      "           1       0.64      0.69      0.66      1575\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.570175%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [01:09<00:44,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 395776 examples: 0.493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.63      1478\n",
      "           1       0.68      0.67      0.67      1714\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.037594%\n",
      "Loss after 397344 examples: 0.547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63      1469\n",
      "           1       0.69      0.67      0.68      1723\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.65      0.66      0.65      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.632832%\n",
      "Loss after 398944 examples: 0.574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64      1529\n",
      "           1       0.67      0.68      0.67      1663\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.883459%\n",
      "Loss after 400544 examples: 0.508\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.63      1486\n",
      "           1       0.68      0.67      0.67      1706\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.66      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.476190%\n",
      "Loss after 402144 examples: 0.486\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64      1520\n",
      "           1       0.67      0.68      0.68      1672\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.040100%\n",
      "Loss after 403744 examples: 0.568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.61      0.66      1741\n",
      "           1       0.60      0.70      0.65      1451\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.66      0.65      3192\n",
      "weighted avg       0.66      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.194236%\n",
      "Loss after 405344 examples: 0.510\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.63      1600\n",
      "           1       0.63      0.67      0.65      1592\n",
      "\n",
      "    accuracy                           0.64      3192\n",
      "   macro avg       0.64      0.64      0.64      3192\n",
      "weighted avg       0.64      0.64      0.64      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.348371%\n",
      "Loss after 406944 examples: 0.525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64      1563\n",
      "           1       0.65      0.67      0.66      1629\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.131579%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [01:11<00:41,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 408544 examples: 0.567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.65      1629\n",
      "           1       0.63      0.68      0.66      1563\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.131579%\n",
      "Loss after 410112 examples: 0.583\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65      1563\n",
      "           1       0.67      0.69      0.68      1629\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.572682%\n",
      "Loss after 411712 examples: 0.524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.65      1624\n",
      "           1       0.64      0.68      0.66      1568\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.225564%\n",
      "Loss after 413312 examples: 0.516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63      1523\n",
      "           1       0.66      0.67      0.67      1669\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.006266%\n",
      "Loss after 414912 examples: 0.563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.63      1529\n",
      "           1       0.66      0.67      0.67      1663\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.194236%\n",
      "Loss after 416512 examples: 0.568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.64      0.66      1613\n",
      "           1       0.66      0.70      0.68      1579\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.885965%\n",
      "Loss after 418112 examples: 0.540\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65      1621\n",
      "           1       0.64      0.69      0.66      1571\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.758145%\n",
      "Loss after 419712 examples: 0.588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65      1659\n",
      "           1       0.63      0.69      0.66      1533\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.507519%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [01:13<00:38,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 421312 examples: 0.545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.65      0.64      1485\n",
      "           1       0.69      0.68      0.68      1707\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.322055%\n",
      "Loss after 422880 examples: 0.520\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.65      1565\n",
      "           1       0.66      0.68      0.67      1627\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.820802%\n",
      "Loss after 424480 examples: 0.477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.65      1545\n",
      "           1       0.67      0.68      0.68      1647\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.196742%\n",
      "Loss after 426080 examples: 0.470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.62      0.66      1674\n",
      "           1       0.63      0.69      0.66      1518\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.664160%\n",
      "Loss after 427680 examples: 0.483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.65      1592\n",
      "           1       0.65      0.68      0.66      1600\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.538847%\n",
      "Loss after 429280 examples: 0.542\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.64      1490\n",
      "           1       0.68      0.67      0.68      1702\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.789474%\n",
      "Loss after 430880 examples: 0.513\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.61      0.65      1714\n",
      "           1       0.60      0.69      0.64      1478\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.724311%\n",
      "Loss after 432480 examples: 0.582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.60      0.64      1730\n",
      "           1       0.59      0.68      0.63      1462\n",
      "\n",
      "    accuracy                           0.64      3192\n",
      "   macro avg       0.64      0.64      0.64      3192\n",
      "weighted avg       0.64      0.64      0.64      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 63.784461%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [01:16<00:37,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 434080 examples: 0.496\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65      1612\n",
      "           1       0.65      0.69      0.67      1580\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.977444%\n",
      "Loss after 435648 examples: 0.611\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64      1554\n",
      "           1       0.66      0.68      0.67      1638\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.852130%\n",
      "Loss after 437248 examples: 0.589\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64      1476\n",
      "           1       0.69      0.68      0.68      1716\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.353383%\n",
      "Loss after 438848 examples: 0.519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64      1546\n",
      "           1       0.67      0.68      0.67      1646\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.914787%\n",
      "Loss after 440448 examples: 0.555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.62      0.65      1665\n",
      "           1       0.63      0.69      0.66      1527\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.570175%\n",
      "Loss after 442048 examples: 0.506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.64      1496\n",
      "           1       0.68      0.67      0.68      1696\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.789474%\n",
      "Loss after 443648 examples: 0.511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.62      0.64      1605\n",
      "           1       0.64      0.68      0.66      1587\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.755639%\n",
      "Loss after 445248 examples: 0.547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63      1453\n",
      "           1       0.69      0.67      0.68      1739\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.507519%\n",
      "Loss after 446848 examples: 0.532\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.61      0.64      1661\n",
      "           1       0.62      0.68      0.65      1531\n",
      "\n",
      "    accuracy                           0.64      3192\n",
      "   macro avg       0.65      0.65      0.64      3192\n",
      "weighted avg       0.65      0.64      0.64      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.379699%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [01:18<00:36,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 448416 examples: 0.530\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.63      0.65      1649\n",
      "           1       0.63      0.69      0.66      1543\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.820802%\n",
      "Loss after 450016 examples: 0.430\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.61      0.64      1665\n",
      "           1       0.62      0.68      0.65      1527\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.630326%\n",
      "Loss after 451616 examples: 0.556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64      1551\n",
      "           1       0.66      0.67      0.67      1641\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.131579%\n",
      "Loss after 453216 examples: 0.568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.64      1554\n",
      "           1       0.65      0.67      0.66      1638\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.974937%\n",
      "Loss after 454816 examples: 0.516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.64      1596\n",
      "           1       0.64      0.68      0.66      1596\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.225564%\n",
      "Loss after 456416 examples: 0.490\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.64      1584\n",
      "           1       0.65      0.68      0.66      1608\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.225564%\n",
      "Loss after 458016 examples: 0.517\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.64      1647\n",
      "           1       0.62      0.68      0.65      1545\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.755639%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [01:21<00:33,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 459616 examples: 0.636\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65      1662\n",
      "           1       0.62      0.68      0.65      1530\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.786967%\n",
      "Loss after 461184 examples: 0.546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.62      1488\n",
      "           1       0.67      0.66      0.67      1704\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.724311%\n",
      "Loss after 462784 examples: 0.556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63      1464\n",
      "           1       0.68      0.67      0.68      1728\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.288221%\n",
      "Loss after 464384 examples: 0.564\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.62      0.65      1679\n",
      "           1       0.62      0.69      0.65      1513\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.66      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.194236%\n",
      "Loss after 465984 examples: 0.544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.63      1490\n",
      "           1       0.67      0.67      0.67      1702\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.037594%\n",
      "Loss after 467584 examples: 0.500\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.64      1584\n",
      "           1       0.65      0.68      0.66      1608\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.162907%\n",
      "Loss after 469184 examples: 0.525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64      1561\n",
      "           1       0.66      0.68      0.67      1631\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.66      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.507519%\n",
      "Loss after 470784 examples: 0.551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.64      1550\n",
      "           1       0.66      0.67      0.66      1642\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.100251%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [01:23<00:30,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 472384 examples: 0.534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64      1576\n",
      "           1       0.65      0.68      0.66      1616\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.225564%\n",
      "Loss after 473952 examples: 0.523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64      1550\n",
      "           1       0.66      0.67      0.67      1642\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.162907%\n",
      "Loss after 475552 examples: 0.479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.63      1514\n",
      "           1       0.67      0.67      0.67      1678\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.413534%\n",
      "Loss after 477152 examples: 0.576\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.64      1529\n",
      "           1       0.66      0.67      0.67      1663\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.256892%\n",
      "Loss after 478752 examples: 0.488\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.63      0.65      1626\n",
      "           1       0.64      0.69      0.66      1566\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.852130%\n",
      "Loss after 480352 examples: 0.509\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65      1669\n",
      "           1       0.62      0.69      0.65      1523\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.66      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.194236%\n",
      "Loss after 481952 examples: 0.528\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.64      1523\n",
      "           1       0.67      0.67      0.67      1669\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.444862%\n",
      "Loss after 483552 examples: 0.608\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.65      0.63      1399\n",
      "           1       0.71      0.67      0.69      1793\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.67      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.196742%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [01:25<00:27,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 485152 examples: 0.501\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.64      1616\n",
      "           1       0.64      0.68      0.66      1576\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.100251%\n",
      "Loss after 486720 examples: 0.514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64      1456\n",
      "           1       0.70      0.68      0.69      1736\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.67      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.416040%\n",
      "Loss after 488320 examples: 0.561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64      1563\n",
      "           1       0.65      0.68      0.66      1629\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.194236%\n",
      "Loss after 489920 examples: 0.472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65      1677\n",
      "           1       0.62      0.69      0.65      1515\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.880952%\n",
      "Loss after 491520 examples: 0.575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.63      0.61      1414\n",
      "           1       0.69      0.66      0.67      1778\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.64      0.64      0.64      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.598997%\n",
      "Loss after 493120 examples: 0.497\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.64      1628\n",
      "           1       0.63      0.68      0.66      1564\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.037594%\n",
      "Loss after 494720 examples: 0.614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.65      1563\n",
      "           1       0.66      0.68      0.67      1629\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.883459%\n",
      "Loss after 496320 examples: 0.578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.65      0.62      1403\n",
      "           1       0.71      0.66      0.69      1789\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.65      0.66      0.65      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.758145%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [01:28<00:25,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 497920 examples: 0.531\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63      1500\n",
      "           1       0.67      0.67      0.67      1692\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.100251%\n",
      "Loss after 499488 examples: 0.623\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.63      0.62      1447\n",
      "           1       0.68      0.66      0.67      1745\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.818296%\n",
      "Loss after 501088 examples: 0.530\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.64      1633\n",
      "           1       0.63      0.68      0.65      1559\n",
      "\n",
      "    accuracy                           0.64      3192\n",
      "   macro avg       0.65      0.65      0.64      3192\n",
      "weighted avg       0.65      0.64      0.64      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.442356%\n",
      "Loss after 502688 examples: 0.520\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63      1442\n",
      "           1       0.70      0.67      0.68      1750\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.789474%\n",
      "Loss after 504288 examples: 0.539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.63      1481\n",
      "           1       0.68      0.67      0.67      1711\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.068922%\n",
      "Loss after 505888 examples: 0.461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63      1483\n",
      "           1       0.68      0.67      0.67      1709\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.319549%\n",
      "Loss after 507488 examples: 0.476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.63      1570\n",
      "           1       0.65      0.67      0.66      1622\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.661654%\n",
      "Loss after 509088 examples: 0.535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.65      0.63      1403\n",
      "           1       0.71      0.67      0.69      1789\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.883459%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [01:30<00:23,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 510688 examples: 0.539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64      1528\n",
      "           1       0.67      0.68      0.68      1664\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.102757%\n",
      "Loss after 512256 examples: 0.580\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63      1467\n",
      "           1       0.69      0.67      0.68      1725\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.820802%\n",
      "Loss after 513856 examples: 0.574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.64      1590\n",
      "           1       0.65      0.68      0.66      1602\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.288221%\n",
      "Loss after 515456 examples: 0.446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.62      1438\n",
      "           1       0.69      0.66      0.67      1754\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.974937%\n",
      "Loss after 517056 examples: 0.458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64      1547\n",
      "           1       0.66      0.67      0.67      1645\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.319549%\n",
      "Loss after 518656 examples: 0.484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64      1504\n",
      "           1       0.68      0.67      0.68      1688\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.789474%\n",
      "Loss after 520256 examples: 0.528\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.63      1525\n",
      "           1       0.66      0.67      0.67      1667\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.006266%\n",
      "Loss after 521856 examples: 0.502\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64      1461\n",
      "           1       0.69      0.67      0.68      1731\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.134085%\n",
      "Loss after 523456 examples: 0.479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.61      0.65      1774\n",
      "           1       0.58      0.69      0.63      1418\n",
      "\n",
      "    accuracy                           0.64      3192\n",
      "   macro avg       0.65      0.65      0.64      3192\n",
      "weighted avg       0.66      0.64      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.473684%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [01:33<00:21,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 525024 examples: 0.558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.64      0.61      1396\n",
      "           1       0.70      0.65      0.67      1796\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.64      0.64      0.64      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.536341%\n",
      "Loss after 526624 examples: 0.495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64      1571\n",
      "           1       0.65      0.68      0.67      1621\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.382206%\n",
      "Loss after 528224 examples: 0.555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.62      0.64      1586\n",
      "           1       0.65      0.68      0.66      1606\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.100251%\n",
      "Loss after 529824 examples: 0.570\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.62      1447\n",
      "           1       0.69      0.66      0.67      1745\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.068922%\n",
      "Loss after 531424 examples: 0.513\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.65      1612\n",
      "           1       0.64      0.68      0.66      1580\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.288221%\n",
      "Loss after 533024 examples: 0.649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.64      1620\n",
      "           1       0.63      0.68      0.66      1572\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.912281%\n",
      "Loss after 534624 examples: 0.558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.61      0.65      1711\n",
      "           1       0.60      0.68      0.64      1481\n",
      "\n",
      "    accuracy                           0.64      3192\n",
      "   macro avg       0.65      0.65      0.64      3192\n",
      "weighted avg       0.65      0.64      0.64      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.317043%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [01:35<00:19,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 536224 examples: 0.497\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64      1547\n",
      "           1       0.67      0.68      0.67      1645\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.883459%\n",
      "Loss after 537792 examples: 0.545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.63      0.65      1642\n",
      "           1       0.64      0.69      0.66      1550\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.914787%\n",
      "Loss after 539392 examples: 0.585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.64      1575\n",
      "           1       0.65      0.68      0.67      1617\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.570175%\n",
      "Loss after 540992 examples: 0.518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.65      0.65      1478\n",
      "           1       0.70      0.68      0.69      1714\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.67      0.67      0.67      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.979950%\n",
      "Loss after 542592 examples: 0.572\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64      1546\n",
      "           1       0.66      0.68      0.67      1646\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.789474%\n",
      "Loss after 544192 examples: 0.514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.63      0.65      1613\n",
      "           1       0.65      0.69      0.67      1579\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.196742%\n",
      "Loss after 545792 examples: 0.542\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.61      0.62      1571\n",
      "           1       0.64      0.66      0.65      1621\n",
      "\n",
      "    accuracy                           0.64      3192\n",
      "   macro avg       0.64      0.64      0.64      3192\n",
      "weighted avg       0.64      0.64      0.64      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 63.690476%\n",
      "Loss after 547392 examples: 0.513\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.63      1531\n",
      "           1       0.66      0.67      0.67      1661\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.006266%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [01:38<00:17,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 548992 examples: 0.547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.63      0.65      1614\n",
      "           1       0.65      0.69      0.67      1578\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.165414%\n",
      "Loss after 550560 examples: 0.644\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.64      1530\n",
      "           1       0.67      0.68      0.67      1662\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.601504%\n",
      "Loss after 552160 examples: 0.508\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63      1516\n",
      "           1       0.67      0.67      0.67      1676\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.100251%\n",
      "Loss after 553760 examples: 0.474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.65      0.62      1413\n",
      "           1       0.70      0.66      0.68      1779\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.570175%\n",
      "Loss after 555360 examples: 0.487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.65      0.63      1428\n",
      "           1       0.70      0.67      0.68      1764\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.977444%\n",
      "Loss after 556960 examples: 0.407\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.65      1612\n",
      "           1       0.64      0.68      0.66      1580\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.288221%\n",
      "Loss after 558560 examples: 0.569\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.62      1484\n",
      "           1       0.67      0.66      0.67      1708\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.786967%\n",
      "Loss after 560160 examples: 0.618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64      1473\n",
      "           1       0.69      0.68      0.68      1719\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.384712%\n",
      "Loss after 561760 examples: 0.518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.63      0.65      1625\n",
      "           1       0.64      0.69      0.66      1567\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.883459%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [01:40<00:14,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 563328 examples: 0.656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64      1498\n",
      "           1       0.68      0.67      0.68      1694\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.852130%\n",
      "Loss after 564928 examples: 0.480\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64      1531\n",
      "           1       0.67      0.68      0.68      1661\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.008772%\n",
      "Loss after 566528 examples: 0.556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.63      1479\n",
      "           1       0.68      0.67      0.68      1713\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.507519%\n",
      "Loss after 568128 examples: 0.536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.64      0.62      1389\n",
      "           1       0.71      0.66      0.68      1803\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.66      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.194236%\n",
      "Loss after 569728 examples: 0.488\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.61      0.66      1745\n",
      "           1       0.60      0.70      0.64      1447\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.66      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.068922%\n",
      "Loss after 571328 examples: 0.468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64      1540\n",
      "           1       0.67      0.68      0.67      1652\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.914787%\n",
      "Loss after 572928 examples: 0.593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.62      0.65      1675\n",
      "           1       0.62      0.69      0.65      1517\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.66      0.66      0.65      3192\n",
      "weighted avg       0.66      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.382206%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [01:42<00:12,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 574528 examples: 0.530\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.63      0.62      1477\n",
      "           1       0.67      0.66      0.66      1715\n",
      "\n",
      "    accuracy                           0.64      3192\n",
      "   macro avg       0.64      0.64      0.64      3192\n",
      "weighted avg       0.64      0.64      0.64      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.317043%\n",
      "Loss after 576096 examples: 0.596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63      1475\n",
      "           1       0.68      0.67      0.68      1717\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.570175%\n",
      "Loss after 577696 examples: 0.454\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.63      1471\n",
      "           1       0.69      0.67      0.68      1721\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.820802%\n",
      "Loss after 579296 examples: 0.548\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.63      1427\n",
      "           1       0.70      0.67      0.68      1765\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.65      0.66      0.65      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.632832%\n",
      "Loss after 580896 examples: 0.428\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63      1471\n",
      "           1       0.68      0.67      0.68      1721\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.570175%\n",
      "Loss after 582496 examples: 0.495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.62      0.64      1617\n",
      "           1       0.63      0.68      0.65      1575\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.630326%\n",
      "Loss after 584096 examples: 0.519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.63      1561\n",
      "           1       0.65      0.67      0.66      1631\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.818296%\n",
      "Loss after 585696 examples: 0.568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64      1506\n",
      "           1       0.68      0.68      0.68      1686\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.852130%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [01:45<00:09,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 587296 examples: 0.445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.63      0.62      1456\n",
      "           1       0.68      0.66      0.67      1736\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.724311%\n",
      "Loss after 588864 examples: 0.561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.63      1538\n",
      "           1       0.66      0.67      0.67      1654\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.037594%\n",
      "Loss after 590464 examples: 0.504\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63      1523\n",
      "           1       0.66      0.67      0.66      1669\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.755639%\n",
      "Loss after 592064 examples: 0.477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.63      1503\n",
      "           1       0.67      0.67      0.67      1689\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.444862%\n",
      "Loss after 593664 examples: 0.516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.64      1520\n",
      "           1       0.67      0.67      0.67      1672\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.413534%\n",
      "Loss after 595264 examples: 0.580\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63      1455\n",
      "           1       0.69      0.67      0.68      1737\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.758145%\n",
      "Loss after 596864 examples: 0.560\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63      1470\n",
      "           1       0.68      0.67      0.67      1722\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.225564%\n",
      "Loss after 598464 examples: 0.470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65      1609\n",
      "           1       0.65      0.69      0.67      1583\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.883459%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [01:47<00:07,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 600064 examples: 0.555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.64      1567\n",
      "           1       0.66      0.68      0.67      1625\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.632832%\n",
      "Loss after 601632 examples: 0.474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.63      1433\n",
      "           1       0.70      0.67      0.68      1759\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.507519%\n",
      "Loss after 603232 examples: 0.475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.65      1622\n",
      "           1       0.64      0.68      0.66      1570\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.350877%\n",
      "Loss after 604832 examples: 0.566\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.62      0.65      1672\n",
      "           1       0.62      0.69      0.65      1520\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.162907%\n",
      "Loss after 606432 examples: 0.545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.62      1456\n",
      "           1       0.68      0.66      0.67      1736\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.037594%\n",
      "Loss after 608032 examples: 0.484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63      1482\n",
      "           1       0.68      0.67      0.67      1710\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.350877%\n",
      "Loss after 609632 examples: 0.484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64      1548\n",
      "           1       0.66      0.68      0.67      1644\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.413534%\n",
      "Loss after 611232 examples: 0.515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63      1509\n",
      "           1       0.67      0.67      0.67      1683\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.319549%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [01:50<00:04,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 612832 examples: 0.589\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.63      1436\n",
      "           1       0.69      0.67      0.68      1756\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.66      0.65      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.476190%\n",
      "Loss after 614400 examples: 0.477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.66      0.63      1409\n",
      "           1       0.71      0.67      0.69      1783\n",
      "\n",
      "    accuracy                           0.67      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.67      0.67      0.67      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.572682%\n",
      "Loss after 616000 examples: 0.571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65      1576\n",
      "           1       0.66      0.69      0.67      1616\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.165414%\n",
      "Loss after 617600 examples: 0.519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.63      0.65      1614\n",
      "           1       0.65      0.69      0.67      1578\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 66.040100%\n",
      "Loss after 619200 examples: 0.508\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.62      1421\n",
      "           1       0.70      0.66      0.68      1771\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.507519%\n",
      "Loss after 620800 examples: 0.558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.63      1614\n",
      "           1       0.63      0.67      0.65      1578\n",
      "\n",
      "    accuracy                           0.64      3192\n",
      "   macro avg       0.64      0.64      0.64      3192\n",
      "weighted avg       0.64      0.64      0.64      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.160401%\n",
      "Loss after 622400 examples: 0.558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.62      0.63      1561\n",
      "           1       0.65      0.67      0.66      1631\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.630326%\n",
      "Loss after 624000 examples: 0.444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63      1496\n",
      "           1       0.67      0.67      0.67      1696\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.037594%\n",
      "Loss after 625600 examples: 0.632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.64      1527\n",
      "           1       0.67      0.67      0.67      1665\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.319549%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [01:52<00:02,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 627168 examples: 0.626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.63      0.62      1462\n",
      "           1       0.68      0.66      0.67      1730\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.912281%\n",
      "Loss after 628768 examples: 0.474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65      1671\n",
      "           1       0.62      0.69      0.65      1521\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.006266%\n",
      "Loss after 630368 examples: 0.523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.65      0.63      1427\n",
      "           1       0.70      0.67      0.68      1765\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.883459%\n",
      "Loss after 631968 examples: 0.527\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63      1461\n",
      "           1       0.69      0.67      0.68      1731\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.65      0.66      0.65      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.632832%\n",
      "Loss after 633568 examples: 0.445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.64      1530\n",
      "           1       0.67      0.68      0.67      1662\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.538847%\n",
      "Loss after 635168 examples: 0.539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.62      0.63      1553\n",
      "           1       0.65      0.67      0.66      1639\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.818296%\n",
      "Loss after 636768 examples: 0.570\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.63      1575\n",
      "           1       0.65      0.67      0.66      1617\n",
      "\n",
      "    accuracy                           0.65      3192\n",
      "   macro avg       0.65      0.65      0.65      3192\n",
      "weighted avg       0.65      0.65      0.65      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 64.692982%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:55<00:00,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 638368 examples: 0.597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64      1554\n",
      "           1       0.66      0.68      0.67      1638\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.789474%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64      1530\n",
      "           1       0.67      0.68      0.67      1662\n",
      "\n",
      "    accuracy                           0.66      3192\n",
      "   macro avg       0.66      0.66      0.66      3192\n",
      "weighted avg       0.66      0.66      0.66      3192\n",
      "\n",
      "Accuracy of the model on the 3192 test matches: 65.852130%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66      1969\n",
      "           1       0.67      0.69      0.68      2021\n",
      "\n",
      "    accuracy                           0.67      3990\n",
      "   macro avg       0.67      0.67      0.67      3990\n",
      "weighted avg       0.67      0.67      0.67      3990\n",
      "\n",
      "Accuracy of the model on the 3990 test matches: 66.791980%\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▇▅▃▇▆▅█▅▃▆▅▄▄▅▅█▆▇▇▇▂▅▂▄▃▅▂▅█▄▆▄▂▃▃▄▁▅▃▇</td></tr><tr><td>test_accuracy</td><td>▄▇██▇▇▇▇█▆▅▅▅▅▆▄▃▄▅▃▃▄▂▄▄▂▃▃▂▂▁▂▁▄▄▂▁▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>0.5968</td></tr><tr><td>test_accuracy</td><td>0.66792</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">rose-thunder-9459</strong> at: <a href='https://wandb.ai/moritz-palm/leaguify/runs/bpme26xw' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify/runs/bpme26xw</a><br/> View job at <a href='https://wandb.ai/moritz-palm/leaguify/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwNTk5NjA5Nw==/version_details/v64' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwNTk5NjA5Nw==/version_details/v64</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20231106_101808-bpme26xw\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = model_pipeline(config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:20:13.723135500Z",
     "start_time": "2023-11-06T09:18:08.634410Z"
    }
   },
   "id": "63223f3b223d001a"
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:20:13.738189Z",
     "start_time": "2023-11-06T09:20:13.723135500Z"
    }
   },
   "id": "7797f9f08cbc4ded"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
