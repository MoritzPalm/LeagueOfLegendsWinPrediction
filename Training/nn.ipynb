{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-13T07:28:53.433041400Z",
     "start_time": "2023-10-13T07:28:47.726760300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mmoritz-palm\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import Tensor, optim, nn\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"architecture\": \"NN\",\n",
    "    \"dataset\": \"static_1.0\",\n",
    "    \"epochs\": 10,\n",
    "    \"classes\": 2,\n",
    "    \"batch_size\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"hidden_size\": 64,\n",
    "    \"dropout_prob\": 0.2,\n",
    "    \"input_size\": 229,\n",
    "    \"output_size\": 2,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"loss\": \"CrossEntropyLoss\",\n",
    "    \"activation\": \"ReLU\",\n",
    "    \"initializer\": \"Xavier\",\n",
    "    \"regularization\": \"L2\",\n",
    "    \"regularization_lambda\": 0.01,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T07:28:53.434040800Z",
     "start_time": "2023-10-13T07:28:53.431511200Z"
    }
   },
   "id": "e13812e0d04c772b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def model_pipeline(hyperparameters):\n",
    "    with wandb.init(project=\"leaguify\", config=hyperparameters):\n",
    "        # access all HPs through wandb.config, so logging matches execution!\n",
    "        config = wandb.config\n",
    "\n",
    "        # make the model, data, and optimization problem\n",
    "        model, train_loader, test_loader, criterion, optimizer = make(config)\n",
    "        print(model)\n",
    "\n",
    "        # and use them to train the model\n",
    "        train(model, train_loader, criterion, optimizer, config)\n",
    "\n",
    "        # and test its final performance\n",
    "        test(model, test_loader)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T07:28:53.443139200Z",
     "start_time": "2023-10-13T07:28:53.435040700Z"
    }
   },
   "id": "bbb0d7d96615b112"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class StaticDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None, target_transform=None):\n",
    "        self.data = torch.tensor(np.load(data_dir)[:, :-1], dtype=torch.float32, device=device)\n",
    "        self.labels = torch.tensor(np.load(data_dir)[:, -1], dtype=torch.int64, device=device)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx, 1:]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return sample, label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T07:28:53.475246600Z",
     "start_time": "2023-10-13T07:28:53.443139200Z"
    }
   },
   "id": "c843eaf2d2fe8be7"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def make(config):\n",
    "    train, test = get_data(train=True), get_data(train=False)\n",
    "    train_loader = make_loader(train, batch_size=config.batch_size)\n",
    "    test_loader = make_loader(test, batch_size=config.batch_size)\n",
    "\n",
    "    model = NeuralNetwork(config.input_size, config.hidden_size, config.num_layers, config.dropout_prob,\n",
    "                          config.classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "    return model, train_loader, test_loader, criterion, optimizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T07:28:53.490246200Z",
     "start_time": "2023-10-13T07:28:53.449156300Z"
    }
   },
   "id": "3ccb742896a9db03"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_data(slice=1, train=True):\n",
    "    if train:\n",
    "        full_dataset = StaticDataset('../data/train_static.npy')\n",
    "    else:\n",
    "        full_dataset = StaticDataset('../data/test_static.npy')\n",
    "    sub_dataset = torch.utils.data.Subset(full_dataset, range(0, len(full_dataset), slice))\n",
    "    return sub_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T07:28:53.490246200Z",
     "start_time": "2023-10-13T07:28:53.455120600Z"
    }
   },
   "id": "7a0d955b1c217921"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def make_loader(dataset, batch_size=64):\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T07:28:53.490246200Z",
     "start_time": "2023-10-13T07:28:53.460647200Z"
    }
   },
   "id": "7feb26d9fd1afd97"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.0\n",
      "**********\n",
      "_CUDA version: \n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Tue_Jun_13_19:42:34_Pacific_Daylight_Time_2023\n",
      "Cuda compilation tools, release 12.2, V12.2.91\n",
      "Build cuda_12.2.r12.2/compiler.32965470_0\n",
      "**********\n",
      "CUDNN version: 8801\n",
      "Available GPU devices: 1\n",
      "Device Name: NVIDIA GeForce RTX 2080\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "if torch.cuda.is_available():\n",
    "    print(f'PyTorch version: {torch.__version__}')\n",
    "    print('*' * 10)\n",
    "    print(f'_CUDA version: ')\n",
    "    !nvcc --version\n",
    "    print('*' * 10)\n",
    "    print(f'CUDNN version: {torch.backends.cudnn.version()}')\n",
    "    print(f'Available GPU devices: {torch.cuda.device_count()}')\n",
    "    print(f'Device Name: {torch.cuda.get_device_name()}')\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T07:28:54.234152600Z",
     "start_time": "2023-10-13T07:28:53.465247Z"
    }
   },
   "id": "aace44d3e59a63c3"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout_prob, classes=2):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T07:28:54.234152600Z",
     "start_time": "2023-10-13T07:28:54.230827300Z"
    }
   },
   "id": "3a87d27c212fc895"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer, config):\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "\n",
    "    total_batches = len(loader) * config.epochs\n",
    "    example_count = 0\n",
    "    batch_count = 0\n",
    "    for epoch in tqdm(range(config.epochs)):\n",
    "        for _, (matches, labels) in enumerate(loader):\n",
    "            loss = train_batch(matches, labels, model, optimizer, criterion)\n",
    "            example_count += len(matches)\n",
    "            batch_count += 1\n",
    "            if (batch_count + 1) % 25 == 0:\n",
    "                train_log(loss, example_count, epoch)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T07:28:54.244151200Z",
     "start_time": "2023-10-13T07:28:54.238152100Z"
    }
   },
   "id": "8639047e162f0756"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def train_batch(matches, labels, model, optimizer, criterion):\n",
    "    output = model(matches)\n",
    "    loss = criterion(output, labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T07:28:54.252313900Z",
     "start_time": "2023-10-13T07:28:54.243152700Z"
    }
   },
   "id": "8d1908015ffa8f78"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def train_log(loss, example_count, epoch):\n",
    "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_count)\n",
    "    print(f\"Loss after {str(example_count).zfill(5)} examples: {loss:.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T07:28:54.253314500Z",
     "start_time": "2023-10-13T07:28:54.248303Z"
    }
   },
   "id": "1d4afe9b0efd101a"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    # Run the model on some test examples\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        for matches, labels in test_loader:\n",
    "            matches, labels = matches.to(device), labels.to(device)\n",
    "            outputs = model(matches)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f\"Accuracy of the model on the {total} \" +\n",
    "              f\"test matches: {correct / total:%}\")\n",
    "\n",
    "        wandb.log({\"test_accuracy\": correct / total})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T07:28:54.262594200Z",
     "start_time": "2023-10-13T07:28:54.252313900Z"
    }
   },
   "id": "7e2790071f2ec71e"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.12"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Users\\morit\\Documents\\Informatik\\Projekte\\LeagueOfLegendsWinPrediction\\Training\\wandb\\run-20231013_092854-54206joi</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/moritz-palm/leaguify/runs/54206joi' target=\"_blank\">sage-water-26</a></strong> to <a href='https://wandb.ai/moritz-palm/leaguify' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/moritz-palm/leaguify' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/moritz-palm/leaguify/runs/54206joi' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify/runs/54206joi</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=229, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=2, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:07,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 01536 examples: 0.676\n",
      "Loss after 03136 examples: 0.623\n",
      "Loss after 04732 examples: 0.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:01<00:03,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 06332 examples: 0.576\n",
      "Loss after 07928 examples: 0.567\n",
      "Loss after 09528 examples: 0.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:01<00:01,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 11124 examples: 0.565\n",
      "Loss after 12724 examples: 0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:01<00:01,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 14320 examples: 0.494\n",
      "Loss after 15920 examples: 0.533\n",
      "Loss after 17516 examples: 0.619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:01<00:00,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 19116 examples: 0.607\n",
      "Loss after 20712 examples: 0.526\n",
      "Loss after 22312 examples: 0.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:02<00:00,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 23908 examples: 0.464\n",
      "Loss after 25508 examples: 0.490\n",
      "Loss after 27104 examples: 0.681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:02<00:00,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 28704 examples: 0.604\n",
      "Loss after 30304 examples: 0.645\n",
      "Loss after 31900 examples: 0.459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 33500 examples: 0.530\n",
      "Accuracy of the model on the 847 test matches: 64.698937%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a2b7f78c6f54f49af3774e32b74a710"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▆▇▇██</td></tr><tr><td>loss</td><td>█▆▅▅▄▆▄▅▂▃▆▆▃▂▁▂█▆▇▁▃</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.52952</td></tr><tr><td>test_accuracy</td><td>0.64699</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">sage-water-26</strong> at: <a href='https://wandb.ai/moritz-palm/leaguify/runs/54206joi' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify/runs/54206joi</a><br/> View job at <a href='https://wandb.ai/moritz-palm/leaguify/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwNTk5NjA5Nw==/version_details/v9' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwNTk5NjA5Nw==/version_details/v9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20231013_092854-54206joi\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = model_pipeline(config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T07:29:10.915532400Z",
     "start_time": "2023-10-13T07:28:54.258594Z"
    }
   },
   "id": "63223f3b223d001a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
