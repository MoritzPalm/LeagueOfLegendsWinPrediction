{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-12T13:17:50.686685800Z",
     "start_time": "2023-12-12T13:17:45.663259800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mmoritz-palm\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import Tensor, optim, nn\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid',\n",
    "    'metric': {\n",
    "        'name': 'val_accuracy',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'learning_rate': {\n",
    "            'values': [0.01, 0.02, 0.05, 0.1, 0.2]\n",
    "        },\n",
    "        'epochs': {\n",
    "            'values': [50, 100, 200]\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [32, 64, 128]\n",
    "        },\n",
    "        'num_layers': {\n",
    "            'values': [1, 2, 3, 4]\n",
    "        },\n",
    "        'hidden_size': {\n",
    "            'values': [32, 64, 128]\n",
    "        },\n",
    "        'dropout_prob': {\n",
    "            'values': [0.0, 0.1, 0.2, 0.3]\n",
    "        },\n",
    "        'regularization_lambda': {\n",
    "            'values': [0.0, 0.01, 0.1, 1.0]\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values': ['adam', 'sgd']\n",
    "        },\n",
    "        'loss': {\n",
    "            'values': ['CrossEntropyLoss']\n",
    "        },\n",
    "        'activation': {\n",
    "            'values': ['ReLU']\n",
    "        },\n",
    "        'input_size': {\n",
    "            'value': 229\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T13:17:50.689896Z",
     "start_time": "2023-12-12T13:17:50.686685800Z"
    }
   },
   "id": "94feee4841fccb27"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'grid',\n",
      " 'metric': {'goal': 'maximize', 'name': 'val_accuracy'},\n",
      " 'parameters': {'activation': {'values': ['ReLU']},\n",
      "                'batch_size': {'values': [32, 64, 128]},\n",
      "                'dropout_prob': {'values': [0.0, 0.1, 0.2, 0.3]},\n",
      "                'epochs': {'values': [50, 100, 200]},\n",
      "                'hidden_size': {'values': [32, 64, 128]},\n",
      "                'input_size': {'value': 229},\n",
      "                'learning_rate': {'values': [0.01, 0.02, 0.05, 0.1, 0.2]},\n",
      "                'loss': {'values': ['CrossEntropyLoss']},\n",
      "                'num_layers': {'values': [1, 2, 3, 4]},\n",
      "                'optimizer': {'values': ['adam', 'sgd']},\n",
      "                'regularization_lambda': {'values': [0.0, 0.01, 0.1, 1.0]}}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(sweep_config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T13:17:50.696751600Z",
     "start_time": "2023-12-12T13:17:50.689896Z"
    }
   },
   "id": "4158e7b2a8e1678b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 2y5yfp2v\n",
      "Sweep URL: https://wandb.ai/moritz-palm/leaguify/sweeps/2y5yfp2v\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project='leaguify')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T13:17:52.143421400Z",
     "start_time": "2023-12-12T13:17:50.696751600Z"
    }
   },
   "id": "19cd87e5f9b3433c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.0+cu121\n",
      "**********\n",
      "_CUDA version: \n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Tue_Aug_15_22:09:35_Pacific_Daylight_Time_2023\n",
      "Cuda compilation tools, release 12.2, V12.2.140\n",
      "Build cuda_12.2.r12.2/compiler.33191640_0\n",
      "**********\n",
      "CUDNN version: 8801\n",
      "Available GPU devices: 1\n",
      "Device Name: NVIDIA GeForce RTX 2080\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "if torch.cuda.is_available():\n",
    "    print(f'PyTorch version: {torch.__version__}')\n",
    "    print('*' * 10)\n",
    "    print(f'_CUDA version: ')\n",
    "    !nvcc --version\n",
    "    print('*' * 10)\n",
    "    print(f'CUDNN version: {torch.backends.cudnn.version()}')\n",
    "    print(f'Available GPU devices: {torch.cuda.device_count()}')\n",
    "    print(f'Device Name: {torch.cuda.get_device_name()}')\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T13:17:52.287349300Z",
     "start_time": "2023-12-12T13:17:52.146419600Z"
    }
   },
   "id": "f9ecdb3fa1251867"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class StaticDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None, target_transform=None):\n",
    "        self.data = torch.tensor(np.load(data_dir)[:, :-1], dtype=torch.float32, device=device)\n",
    "        self.labels = torch.tensor(np.load(data_dir)[:, -1], dtype=torch.int64, device=device)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx, 1:]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return sample, label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T13:17:52.287349300Z",
     "start_time": "2023-12-12T13:17:52.257863700Z"
    }
   },
   "id": "71e7eedbba180217"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_train_data(slice=1):\n",
    "    full_dataset = StaticDataset('../data/processed/train_static.npy')\n",
    "    sub_dataset = torch.utils.data.Subset(full_dataset, range(0, len(full_dataset), slice))\n",
    "    train_data = torch.utils.data.Subset(sub_dataset, range(0, int(len(sub_dataset) * 0.8)))\n",
    "    val_data = torch.utils.data.Subset(sub_dataset, range(int(len(sub_dataset) * 0.8), len(sub_dataset)))\n",
    "    return train_data, val_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T13:17:52.288352Z",
     "start_time": "2023-12-12T13:17:52.261634Z"
    }
   },
   "id": "b40b40fd68fb47c9"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def get_test_data():\n",
    "    return StaticDataset('../data/processed/test_static.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T13:17:52.288352Z",
     "start_time": "2023-12-12T13:17:52.266116Z"
    }
   },
   "id": "c9b249c7618fe07d"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def make_loader(dataset, batch_size=64):\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T13:17:52.288352Z",
     "start_time": "2023-12-12T13:17:52.270362800Z"
    }
   },
   "id": "284e831adefba497"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout_prob, num_classes=2):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            if i == 0:\n",
    "                self.linear_relu_stack.append(nn.Linear(input_size, hidden_size))\n",
    "            else:\n",
    "                self.linear_relu_stack.append(nn.Linear(hidden_size, hidden_size))\n",
    "            self.linear_relu_stack.append(nn.ReLU())\n",
    "            self.linear_relu_stack.append(self.dropout)\n",
    "        self.linear_relu_stack.append(nn.Linear(hidden_size, num_classes))\n",
    "        self.linear_relu_stack.append(nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T13:17:52.288352Z",
     "start_time": "2023-12-12T13:17:52.276267400Z"
    }
   },
   "id": "e633f9552c595b6c"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def build_optimizer(network, optimizer, learning_rate):\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = optim.SGD(network.parameters(),\n",
    "                              lr=learning_rate, momentum=0.9)\n",
    "    elif optimizer == \"adam\":\n",
    "        optimizer = optim.Adam(network.parameters(),\n",
    "                               lr=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(\"Optimizer not supported\")\n",
    "    return optimizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T13:17:52.289996300Z",
     "start_time": "2023-12-12T13:17:52.282651600Z"
    }
   },
   "id": "5d234e24eadde248"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def train_batch(matches, labels, model, optimizer, criterion):\n",
    "    output = model(matches)\n",
    "    loss = criterion(output, labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T13:17:52.308911500Z",
     "start_time": "2023-12-12T13:17:52.289350600Z"
    }
   },
   "id": "a531c53d8459b38b"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def train_log(loss, example_count, epoch):\n",
    "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_count)\n",
    "    print(f\"Loss after {str(example_count).zfill(5)} examples: {loss:.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T13:17:52.310912400Z",
     "start_time": "2023-12-12T13:17:52.292515Z"
    }
   },
   "id": "19667c857a530a54"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def train(config=None):\n",
    "    with wandb.init(config=config):\n",
    "\n",
    "        config = wandb.config  #\n",
    "        train_data, val_data = get_train_data(slice=1)\n",
    "        train_loader = make_loader(train_data, batch_size=config.batch_size)\n",
    "        val_loader = make_loader(val_data, batch_size=config.batch_size)\n",
    "        model = NeuralNetwork(config.input_size, config.hidden_size, config.num_layers, config.dropout_prob).to(device)\n",
    "        optimizer = build_optimizer(model, config.optimizer, config.learning_rate)\n",
    "        print(f'optimizer: {optimizer}')\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "\n",
    "        total_batches = len(train_loader) * config.epochs\n",
    "        example_count = 0\n",
    "        batch_count = 0\n",
    "        for epoch in tqdm(range(config.epochs)):\n",
    "            for _, (matches, labels) in enumerate(train_loader):\n",
    "                loss = train_batch(matches, labels, model, optimizer, criterion)\n",
    "                example_count += len(matches)\n",
    "                batch_count += 1\n",
    "                if (batch_count + 1) % 25 == 0:\n",
    "                    train_log(loss, example_count, epoch)\n",
    "        test(model, val_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T13:17:52.310912400Z",
     "start_time": "2023-12-12T13:17:52.299042600Z"
    }
   },
   "id": "dfc648103a9c4193"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    # Run the model on some test examples\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        for matches, labels in test_loader:\n",
    "            matches, labels = matches.to(device), labels.to(device)\n",
    "            outputs = model(matches)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f\"Accuracy of the model on the {total} \" +\n",
    "              f\"test matches: {correct / total:%}\")\n",
    "\n",
    "        wandb.log({\"val_accuracy\": correct / total})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T13:17:52.310912400Z",
     "start_time": "2023-12-12T13:17:52.304076Z"
    }
   },
   "id": "f724f460828fcf88"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Agent Starting Run: ty6igv93 with config:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tactivation: ReLU\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tbatch_size: 32\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tdropout_prob: 0\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tepochs: 50\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \thidden_size: 32\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tinput_size: 229\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tlearning_rate: 0.01\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tloss: CrossEntropyLoss\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tnum_layers: 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \toptimizer: adam\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tregularization_lambda: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.16.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.12"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Users\\morit\\Documents\\Informatik\\Projekte\\LeagueOfLegendsWinPrediction\\Training\\wandb\\run-20231212_141754-ty6igv93</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/moritz-palm/leaguify/runs/ty6igv93' target=\"_blank\">polar-sweep-1</a></strong> to <a href='https://wandb.ai/moritz-palm/leaguify' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/moritz-palm/leaguify/sweeps/2y5yfp2v' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify/sweeps/2y5yfp2v</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/moritz-palm/leaguify' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View sweep at <a href='https://wandb.ai/moritz-palm/leaguify/sweeps/2y5yfp2v' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify/sweeps/2y5yfp2v</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/moritz-palm/leaguify/runs/ty6igv93' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify/runs/ty6igv93</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\morit\\AppData\\Local\\Temp\\ipykernel_25376\\1221278742.py\", line 19, in train\n",
      "    loss = train_batch(matches, labels, model, optimizer, criterion)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\morit\\AppData\\Local\\Temp\\ipykernel_25376\\3104205212.py\", line 2, in train_batch\n",
      "    output = model(matches)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\morit\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\leaguify-VaCbhr8h-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\morit\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\leaguify-VaCbhr8h-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1568, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\morit\\AppData\\Local\\Temp\\ipykernel_25376\\885893011.py\", line 22, in forward\n",
      "    logits = self.linear_relu_stack(x)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\morit\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\leaguify-VaCbhr8h-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\morit\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\leaguify-VaCbhr8h-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\morit\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\leaguify-VaCbhr8h-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 215, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\morit\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\leaguify-VaCbhr8h-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\morit\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\leaguify-VaCbhr8h-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\morit\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\leaguify-VaCbhr8h-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (32x329 and 229x32)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91f90958b4c34350bf10dcb8783b0487"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">polar-sweep-1</strong> at: <a href='https://wandb.ai/moritz-palm/leaguify/runs/ty6igv93' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify/runs/ty6igv93</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20231212_141754-ty6igv93\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run ty6igv93 errored: RuntimeError('mat1 and mat2 shapes cannot be multiplied (32x329 and 229x32)')\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[32m\u001B[41mERROR\u001B[0m Run ty6igv93 errored: RuntimeError('mat1 and mat2 shapes cannot be multiplied (32x329 and 229x32)')\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Agent Starting Run: 5sbfwqqz with config:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tactivation: ReLU\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tbatch_size: 32\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tdropout_prob: 0\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tepochs: 50\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \thidden_size: 32\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tinput_size: 229\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tlearning_rate: 0.01\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tloss: CrossEntropyLoss\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tnum_layers: 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \toptimizer: adam\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tregularization_lambda: 0.01\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.16.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.12"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Users\\morit\\Documents\\Informatik\\Projekte\\LeagueOfLegendsWinPrediction\\Training\\wandb\\run-20231212_141805-5sbfwqqz</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/moritz-palm/leaguify/runs/5sbfwqqz' target=\"_blank\">upbeat-sweep-2</a></strong> to <a href='https://wandb.ai/moritz-palm/leaguify' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/moritz-palm/leaguify/sweeps/2y5yfp2v' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify/sweeps/2y5yfp2v</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/moritz-palm/leaguify' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View sweep at <a href='https://wandb.ai/moritz-palm/leaguify/sweeps/2y5yfp2v' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify/sweeps/2y5yfp2v</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/moritz-palm/leaguify/runs/5sbfwqqz' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify/runs/5sbfwqqz</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\morit\\AppData\\Local\\Temp\\ipykernel_25376\\1221278742.py\", line 19, in train\n",
      "    loss = train_batch(matches, labels, model, optimizer, criterion)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\morit\\AppData\\Local\\Temp\\ipykernel_25376\\3104205212.py\", line 2, in train_batch\n",
      "    output = model(matches)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\morit\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\leaguify-VaCbhr8h-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\morit\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\leaguify-VaCbhr8h-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1568, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\morit\\AppData\\Local\\Temp\\ipykernel_25376\\885893011.py\", line 22, in forward\n",
      "    logits = self.linear_relu_stack(x)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\morit\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\leaguify-VaCbhr8h-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\morit\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\leaguify-VaCbhr8h-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\morit\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\leaguify-VaCbhr8h-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 215, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\morit\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\leaguify-VaCbhr8h-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\morit\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\leaguify-VaCbhr8h-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\morit\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\leaguify-VaCbhr8h-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (32x329 and 229x32)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">upbeat-sweep-2</strong> at: <a href='https://wandb.ai/moritz-palm/leaguify/runs/5sbfwqqz' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify/runs/5sbfwqqz</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20231212_141805-5sbfwqqz\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train, count=50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T13:18:13.201312700Z",
     "start_time": "2023-12-12T13:17:52.307911800Z"
    }
   },
   "id": "35466bb8f1f9cfcb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
