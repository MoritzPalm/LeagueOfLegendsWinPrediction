{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-17T13:30:45.589999Z",
     "start_time": "2023-10-17T13:30:30.416765Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mmoritz-palm\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import Tensor, optim, nn\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"architecture\": \"GRU\",\n",
    "    \"dataset\": \"timeline_1.0\",\n",
    "    \"epochs\": 100,\n",
    "    \"classes\": 2,\n",
    "    \"batch_size\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"hidden_size\": 64,\n",
    "    \"dropout_prob\": 0.2,\n",
    "    \"input_size\": 229,\n",
    "    \"output_size\": 2,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"loss\": \"CrossEntropyLoss\",\n",
    "    \"activation\": \"ReLU\",\n",
    "    \"initializer\": \"Xavier\",\n",
    "    \"regularization\": \"L2\",\n",
    "    \"regularization_lambda\": 0.01,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T13:30:45.620685Z",
     "start_time": "2023-10-17T13:30:45.577315Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def model_pipeline(hyperparameters):\n",
    "    with wandb.init(project=\"leaguify\", config=hyperparameters):\n",
    "        # access all HPs through wandb.config, so logging matches execution!\n",
    "        config = wandb.config\n",
    "\n",
    "        # make the model, data, and optimization problem\n",
    "        model, train_loader, test_loader, criterion, optimizer = make(config)\n",
    "        print(model)\n",
    "\n",
    "        # and use them to train the model\n",
    "        train(model, train_loader, criterion, optimizer, config)\n",
    "\n",
    "        # and test its final performance\n",
    "        test(model, test_loader)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T13:30:45.633985Z",
     "start_time": "2023-10-17T13:30:45.586768Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class StaticDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None, target_transform=None):\n",
    "        self.data = torch.tensor(np.load(data_dir)[:, :-1], dtype=torch.float32, device=device)\n",
    "        self.labels = torch.tensor(np.load(data_dir)[:, -1], dtype=torch.int64, device=device)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx, 1:]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return sample, label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T13:30:45.825790Z",
     "start_time": "2023-10-17T13:30:45.619817Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def make(config):\n",
    "    train, test = get_data(train=True), get_data(train=False)\n",
    "    train_loader = make_loader(train, batch_size=config.batch_size)\n",
    "    test_loader = make_loader(test, batch_size=config.batch_size)\n",
    "\n",
    "    model = GRU(config.input_size, config.hidden_size, config.num_layers, config.dropout_prob,\n",
    "                          config.classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "    return model, train_loader, test_loader, criterion, optimizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T13:30:45.910326Z",
     "start_time": "2023-10-17T13:30:45.621380Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_data(slice=1, train=True):\n",
    "    if train:\n",
    "        full_dataset = StaticDataset('../data/processed/train_timeline.npy')\n",
    "    else:\n",
    "        full_dataset = StaticDataset('../data/processed/test_timeline.npy')\n",
    "    sub_dataset = torch.utils.data.Subset(full_dataset, range(0, len(full_dataset), slice))\n",
    "    return sub_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T13:30:45.913833Z",
     "start_time": "2023-10-17T13:30:45.627322Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def make_loader(dataset, batch_size=64):\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T13:30:45.914614Z",
     "start_time": "2023-10-17T13:30:45.645607Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "if torch.cuda.is_available():\n",
    "    print(f'PyTorch version: {torch.__version__}')\n",
    "    print('*' * 10)\n",
    "    print(f'_CUDA version: ')\n",
    "    !nvcc --version\n",
    "    print('*' * 10)\n",
    "    print(f'CUDNN version: {torch.backends.cudnn.version()}')\n",
    "    print(f'Available GPU devices: {torch.cuda.device_count()}')\n",
    "    print(f'Device Name: {torch.cuda.get_device_name()}')\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T13:30:45.929026Z",
     "start_time": "2023-10-17T13:30:45.667783Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob = 0.2):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        out, h = self.gru(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        return hidden"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T13:30:45.929542Z",
     "start_time": "2023-10-17T13:30:45.684023Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer, config):\n",
    "    wandb.watch(model, criterion, log='all', log_freq=10)\n",
    "\n",
    "    total_batches = len(loader) * config.epochs\n",
    "    example_count = 0\n",
    "    batch_count = 0\n",
    "    for epoch in tqdm(range(config.epochs)):\n",
    "        for _, (matches, labels) in enumerate(loader):\n",
    "            loss = train_batch(matches, labels, model, optimizer, criterion)\n",
    "            example_count += len(matches)\n",
    "            batch_count +=1\n",
    "            if (batch_count + 1) % 25 == 0:\n",
    "                train_log(loss, example_count, epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T13:30:45.930044Z",
     "start_time": "2023-10-17T13:30:45.703172Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def train_batch(matches, labels, model, optimizer, criterion):\n",
    "    output = model(matches)\n",
    "    loss = criterion(output, labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T13:30:45.930776Z",
     "start_time": "2023-10-17T13:30:45.712411Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def train_log(loss, example_count, epoch):\n",
    "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_count)\n",
    "    print(f\"Loss after {str(example_count).zfill(5)} examples: {loss:.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T13:30:45.932766Z",
     "start_time": "2023-10-17T13:30:45.719907Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    # Run the model on some test examples\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        for matches, labels in test_loader:\n",
    "            matches, labels = matches.to(device), labels.to(device)\n",
    "            outputs = model(matches)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f\"Accuracy of the model on the {total} \" +\n",
    "              f\"test matches: {correct / total:%}\")\n",
    "\n",
    "        wandb.log({\"test_accuracy\": correct / total})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T13:30:45.933393Z",
     "start_time": "2023-10-17T13:30:45.730461Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.12"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/Users/admin/Documents/Informatik/Studium/Bachelorarbeit/LeagueOfLegendsWinPrediction/Training/wandb/run-20231017_153045-szk9r5j5</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/moritz-palm/leaguify/runs/szk9r5j5' target=\"_blank\">still-capybara-28</a></strong> to <a href='https://wandb.ai/moritz-palm/leaguify' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/moritz-palm/leaguify' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/moritz-palm/leaguify/runs/szk9r5j5' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify/runs/szk9r5j5</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/ww/zccj65710l313xpntj6vpnth0000gn/T/ipykernel_87678/31012391.py\", line 7, in model_pipeline\n",
      "    model, train_loader, test_loader, criterion, optimizer = make(config)\n",
      "  File \"/var/folders/ww/zccj65710l313xpntj6vpnth0000gn/T/ipykernel_87678/1853932103.py\", line 2, in make\n",
      "    train, test = get_data(train=True), get_data(train=False)\n",
      "  File \"/var/folders/ww/zccj65710l313xpntj6vpnth0000gn/T/ipykernel_87678/2199354146.py\", line 3, in get_data\n",
      "    full_dataset = StaticDataset('../data/processed/train_timeline.npy')\n",
      "  File \"/var/folders/ww/zccj65710l313xpntj6vpnth0000gn/T/ipykernel_87678/1704340242.py\", line 3, in __init__\n",
      "    self.data = torch.tensor(np.load(data_dir)[:, :-1], dtype=torch.float32, device=device)\n",
      "  File \"/Users/admin/opt/miniconda3/envs/Leaguify/lib/python3.10/site-packages/numpy/lib/npyio.py\", line 427, in load\n",
      "    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '../data/processed/train_timeline.npy'\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">still-capybara-28</strong> at: <a href='https://wandb.ai/moritz-palm/leaguify/runs/szk9r5j5' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify/runs/szk9r5j5</a><br/> View job at <a href='https://wandb.ai/moritz-palm/leaguify/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwNzQ0ODcwNg==/version_details/v0' target=\"_blank\">https://wandb.ai/moritz-palm/leaguify/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwNzQ0ODcwNg==/version_details/v0</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20231017_153045-szk9r5j5/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/processed/train_timeline.npy'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_pipeline\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[3], line 7\u001B[0m, in \u001B[0;36mmodel_pipeline\u001B[0;34m(hyperparameters)\u001B[0m\n\u001B[1;32m      4\u001B[0m config \u001B[38;5;241m=\u001B[39m wandb\u001B[38;5;241m.\u001B[39mconfig\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# make the model, data, and optimization problem\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m model, train_loader, test_loader, criterion, optimizer \u001B[38;5;241m=\u001B[39m \u001B[43mmake\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(model)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# and use them to train the model\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[5], line 2\u001B[0m, in \u001B[0;36mmake\u001B[0;34m(config)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmake\u001B[39m(config):\n\u001B[0;32m----> 2\u001B[0m     train, test \u001B[38;5;241m=\u001B[39m \u001B[43mget_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m, get_data(train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m      3\u001B[0m     train_loader \u001B[38;5;241m=\u001B[39m make_loader(train, batch_size\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mbatch_size)\n\u001B[1;32m      4\u001B[0m     test_loader \u001B[38;5;241m=\u001B[39m make_loader(test, batch_size\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mbatch_size)\n",
      "Cell \u001B[0;32mIn[6], line 3\u001B[0m, in \u001B[0;36mget_data\u001B[0;34m(slice, train)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_data\u001B[39m(\u001B[38;5;28mslice\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m train:\n\u001B[0;32m----> 3\u001B[0m         full_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mStaticDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m../data/processed/train_timeline.npy\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m      5\u001B[0m         full_dataset \u001B[38;5;241m=\u001B[39m StaticDataset(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../data/processed/test_timeline.npy\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[0;32mIn[4], line 3\u001B[0m, in \u001B[0;36mStaticDataset.__init__\u001B[0;34m(self, data_dir, transform, target_transform)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, data_dir, transform\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, target_transform\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m----> 3\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_dir\u001B[49m\u001B[43m)\u001B[49m[:, :\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32, device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabels \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(np\u001B[38;5;241m.\u001B[39mload(data_dir)[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mint64, device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;241m=\u001B[39m transform\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/Leaguify/lib/python3.10/site-packages/numpy/lib/npyio.py:427\u001B[0m, in \u001B[0;36mload\u001B[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001B[0m\n\u001B[1;32m    425\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    426\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 427\u001B[0m     fid \u001B[38;5;241m=\u001B[39m stack\u001B[38;5;241m.\u001B[39menter_context(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mos_fspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    428\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    430\u001B[0m \u001B[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001B[39;00m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../data/processed/train_timeline.npy'"
     ]
    }
   ],
   "source": [
    "model = model_pipeline(config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T13:31:02.672026Z",
     "start_time": "2023-10-17T13:30:45.737829Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
